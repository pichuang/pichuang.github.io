
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Open Knowledge, Open Source, Open Mind">
      
      
        <meta name="author" content="Phil Huang">
      
      
        <link rel="canonical" href="https://blog.pichuang.com.tw/category/kubernetes/">
      
      
        <link rel="prev" href="../homecloud/">
      
      
        <link rel="next" href="../linux/">
      
      
        
      
      
      <link rel="icon" href="../../favicon.ico">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.3+insiders-4.49.2">
    
    
      
        <title>kubernetes - Phil's Workspace</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.67c3bdf0.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:300,300i,400,400i,700,700i%7COverpass+Mono+SemiBold:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans";--md-code-font:"Overpass Mono SemiBold"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-8MQRY98QB2"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-8MQRY98QB2",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-8MQRY98QB2",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#kubernetes" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
              </button>
            
            
  <a href="https://www.youtube.com/@pichuang-tw" style="color:white;">
    For updates follow <strong>@pichuang-tw</strong> on
    <strong>YouTube Channel 🎥 </strong>
  </a>

          </div>
          
            <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script>
          
        </aside>
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Phil&#39;s Workspace" class="md-header__button md-logo" aria-label="Phil's Workspace" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.97 5.92a.967.967 0 0 0-1.18-.68l-3.4.91-4.44-4.12-1.23.33 2.66 4.59-3.19.85-1.26-.98-.93.25 1.66 2.88 10.62-2.84c.52-.15.82-.68.69-1.19M21 10l-1 2h-5l-1-2 1-1h2V7h1v2h2l1 1m1 10v2H2v-2h13v-7h5v7h2Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Phil's Workspace
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              kubernetes
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/pichuang/pichuang.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    blog.pichuang.com.tw
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../.." class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../wiki/" class="md-tabs__link">
          
  
    
  
  Wiki

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../azure-subnets/" class="md-tabs__link">
          
  
    
  
  Azure Visual Subnet Calculator

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../about/" class="md-tabs__link">
          
  
    
  
  About

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Phil&#39;s Workspace" class="md-nav__button md-logo" aria-label="Phil's Workspace" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.97 5.92a.967.967 0 0 0-1.18-.68l-3.4.91-4.44-4.12-1.23.33 2.66 4.59-3.19.85-1.26-.98-.93.25 1.66 2.88 10.62-2.84c.52-.15.82-.68.69-1.19M21 10l-1 2h-5l-1-2 1-1h2V7h1v2h2l1 1m1 10v2H2v-2h13v-7h5v7h2Z"/></svg>

    </a>
    Phil's Workspace
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pichuang/pichuang.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    blog.pichuang.com.tw
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../.." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Blog
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_2" >
        
          
          <label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    Archive
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Archive
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2023/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    2023
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2022/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    2022
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2021/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    2021
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2020/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    2020
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../archive/2019/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    2019
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_3" checked>
        
          
          <label class="md-nav__link" for="__nav_1_3" id="__nav_1_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    Categories
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Categories
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../automation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    automation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../azure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    azure
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../container/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    container
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../homecloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    homecloud
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    
      
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    
  
    kubernetes
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    
  
    kubernetes
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#azure-kubernetes-services-c1000k" class="md-nav__link">
    <span class="md-ellipsis">
      
        揪竟...Azure Kubernetes Services 的節點能不能提供 C1000K 的能力呢?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kubernetes" class="md-nav__link">
    <span class="md-ellipsis">
      
        人家都在抓神奇寶貝，而我在抓 Kubernetes 封包
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distroless-container-kubectl-debug" class="md-nav__link">
    <span class="md-ellipsis">
      
        當遇到 Distroless Container 除錯要什麼沒什麼該怎麼辦? 你的好朋友 kubectl debug
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kubernetes-probe" class="md-nav__link">
    <span class="md-ellipsis">
      
        Kubernetes Probe 類型及實作方式的使用說明與小建議
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sig-kubernetes-scability" class="md-nav__link">
    <span class="md-ellipsis">
      
        SIG Kubernetes Scability 多維度分析
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openai-kubernetes-7500" class="md-nav__link">
    <span class="md-ellipsis">
      
        看 OpenAI 使用鈔能力招喚 Kubernetes 7500 台節點!!!
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pod" class="md-nav__link">
    <span class="md-ellipsis">
      
        實現不停機的 Pod 更新方式
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-kubernetes-kubernetes" class="md-nav__link">
    <span class="md-ellipsis">
      
        我要 1 座 Kubernetes 還是要多座 Kubernetes? 還是都可以?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kubernetes" class="md-nav__link">
    <span class="md-ellipsis">
      
        為什麼我佈署的 Kubernetes 服務不會動!? 個人除錯思路分享
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kubernetes-app" class="md-nav__link">
    <span class="md-ellipsis">
      
        如何科學地估算 Kubernetes 所需的資源? App 角度篇
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../linux/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    linux
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../misc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    misc
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../networking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    networking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../o11y/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    o11y
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../openai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    openai
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../openshift/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    openshift
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../personal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    personal
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../sla/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    sla
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../sustainability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    sustainability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_4" >
        
          
          <label class="md-nav__link" for="__nav_1_4" id="__nav_1_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    Authors
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Authors
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../author/url/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Phil Huang
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../wiki/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    
  
    Wiki
  

    
  </span>
  
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Wiki
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    Azure Visual Subnet Calculator
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Azure Visual Subnet Calculator
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../azure-subnets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Visual Subnet Calculator (Azure Edition)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    
  
    About
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    About
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Who is Phil Huang?
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../recording/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Recording
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="kubernetes">kubernetes</h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-10-17 00:00:00">October 17, 2023</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              10 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="azure-kubernetes-services-c1000k"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/">揪竟...Azure Kubernetes Services 的節點能不能提供 C1000K 的能力呢?</a></h2>
<blockquote>
<p>Kubernetes is Cloud OS, Containers are Linux</p>
</blockquote>
<p><img alt="" src="/images/t2.jpg" /></p>
<p>既前篇文章 <a href="https://blog.pichuang.com.tw/20231012-sustainability-remote-capture-packets.html">永續性軟體工程: 遠端抓封包實錄</a> 有提到降低不必要網路傳輸成本可有效減少碳排放，那我繼續基於 Green Foundation 所提出的<a href="https://learn.greensoftware.foundation/hardware-efficiency#increasing-device-utilization">綠色軟體實踐者 (Green Software Practitioner)</a> 當中的原則提升設備利用率 (Increasing device utilization) 來繼續延伸這個大議題</p>
<p>盡力地提升單台節點所能服務的量體，減少資源浪費，從這個角度看，其實就是需要來探討 Azure Kuberenetes Service 預設提供的這些節點，本體到底夠不夠提供我們在大流量和高性能計算上所需的資源和調教，這邊就從經典的百萬並行連線 C1000K (Concurrent 1000K Connections) 來做為基準來探討</p>
<!--more-->

<h3 id="cncf-sustainability-week-taiwan-x-green-software-foundation"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#cncf-sustainability-week-taiwan-x-green-software-foundation">[活動宣傳] CNCF Sustainability Week - Taiwan x Green Software Foundation</a></h3>
<p><img alt="" src="/images/cnsw.png" /></p>
<p>最近的我覺得這個題目比較在考驗 Linux 高性能調教，歡迎大家報名 <a href="https://community.cncf.io/events/details/cncf-cloud-native-taiwan-user-group-presents-cncf-sustainability-week-taiwan-x-green-software-foundation/">2023/10/24 18:30-21:30</a> 來吃吃喝喝探討</p>
<h3 id="azure-kubernetes-service"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#azure-kubernetes-service">登入 Azure Kubernetes Service 當中的一個節點</a></h3>
<p>這邊使用 v1.25 後，開始可使用的 <code>kubectl debug</code> 作為使用基礎，之前有些過一篇 <a href="https://blog.pichuang.com.tw/20230713-distroless-container-debug.html">當遇到 Distroless Container 除錯要什麼沒什麼該怎麼辦? 你的好朋友 kubectl debug</a> 有專文解釋這個指令的效果，但今天比較特別是，對象是 Node 而非 Pod</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>version
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>Client<span class="w"> </span>Version:<span class="w"> </span>v1.28.1
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>Kustomize<span class="w"> </span>Version:<span class="w"> </span>v5.0.4-0.20230601165947-6ce0bf390ce3
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>Server<span class="w"> </span>Version:<span class="w"> </span>v1.27.3
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a><span class="c1"># 獲得 node 名稱</span>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>$<span class="w"> </span>kubectl<span class="w"> </span>get<span class="w"> </span>nodes
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>NAME<span class="w">                                </span>STATUS<span class="w">   </span>ROLES<span class="w">   </span>AGE<span class="w">     </span>VERSION
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>aks-agentpool-14864487-vmss000000<span class="w">   </span>Ready<span class="w">    </span>agent<span class="w">   </span>6d14h<span class="w">   </span>v1.27.3
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a><span class="c1"># kubectl debug node/&lt;node name&gt; -it --image-pull-policy=Always --quiet --image=&lt;image name&gt; -- &lt;command&gt;</span>
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>$<span class="w"> </span>kubectl<span class="w"> </span>debug<span class="w"> </span>node/aks-agentpool-14864487-vmss000000<span class="w"> </span>-it<span class="w"> </span>--image-pull-policy<span class="o">=</span>Always<span class="w"> </span>--quiet<span class="w"> </span>--image<span class="o">=</span>ghcr.io/pichuang/debug-container:master<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a>
<a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a><span class="c1"># 務必要記得使用 chroot /host 切到正確的環境去</span>
<a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a><span class="o">[</span>root@aks-agentpool-14864487-vmss000000<span class="w"> </span>/<span class="o">]</span><span class="c1"># chroot /host /bin/bash</span>
<a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a>
<a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a><span class="c1"># 確保你可以看到作業系統資訊</span>
<a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /etc/os-release</span>
<a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a><span class="nv">NAME</span><span class="o">=</span><span class="s2">&quot;Common Base Linux Mariner&quot;</span>
<a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a><span class="nv">VERSION</span><span class="o">=</span><span class="s2">&quot;2.0.20230924&quot;</span>
<a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a><span class="nv">ID</span><span class="o">=</span>mariner
<a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a><span class="nv">VERSION_ID</span><span class="o">=</span><span class="s2">&quot;2.0&quot;</span>
<a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a><span class="nv">PRETTY_NAME</span><span class="o">=</span><span class="s2">&quot;CBL-Mariner/Linux&quot;</span>
<a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a><span class="nv">ANSI_COLOR</span><span class="o">=</span><span class="s2">&quot;1;34&quot;</span>
<a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a><span class="nv">HOME_URL</span><span class="o">=</span><span class="s2">&quot;https://aka.ms/cbl-mariner&quot;</span>
<a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a><span class="nv">BUG_REPORT_URL</span><span class="o">=</span><span class="s2">&quot;https://aka.ms/cbl-mariner&quot;</span>
<a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a><span class="nv">SUPPORT_URL</span><span class="o">=</span><span class="s2">&quot;https://aka.ms/cbl-mariner&quot;</span>
</code></pre></div>
<p><img alt="" src="/images/t1.png" /></p>
<h3 id="aks-node-cbl-mariner"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#aks-node-cbl-mariner">解剖 AKS Node 裡的 CBL-Mariner 作業系統</a></h3>
<p>先聲明，下面的眾多操作都可以適用於任何一家的 Kubernetes 發行版和以 Linux 為基礎的節點，但當中的設定會隨著下列 3 個狀況有所差異，但基本上大同小異</p>
<ol>
<li>廠商不同，如 Azure 和 Red Hat</li>
<li>OS 選擇不同，如 Mariner 2.0、Red Hat CoreOS、Ubuntu 20.04</li>
<li>Kernel 版本不同，如 5.15.131、5.x.x、3.11.x</li>
</ol>
<h4 id="aks-environment"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#aks-environment">AKS Environment</a></h4>
<ul>
<li>Azure Kubernetes Service 1.27.3</li>
<li>VM Instance: Standard D4as v5 (4 vcpus, 16 GiB memory)</li>
<li>OS: <a href="https://github.com/microsoft/CBL-Mariner">CBL-Mariner 2.0</a>，這個是 Azure 親大王子，最近還有一個 Azure Linux 親小王子出來，但還沒正式用過</li>
<li>CNI: Azure CNI</li>
<li>(Azure 限定) 有使用 UDR 強制控制 Egress 方向</li>
</ul>
<h4 id="1-cpu"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#1-cpu">1. CPU 相關</a></h4>
<h5 id="a-hardware"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#a-hardware">a. Hardware</a></h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="c1">#</span>
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="c1"># CPU</span>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="c1">#</span>
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="c1"># 查詢 CPU 型號</span>
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a><span class="c1"># Standard D4as v5 (4 vcpus, 16 GiB memory)</span>
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a><span class="c1"># https://azureprice.net/vm/Standard_D4as_v5</span>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/cpuinfo | grep &quot;model name&quot; | cut -f2 -d: | uniq</span>
<a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a>AMD<span class="w"> </span>EPYC<span class="w"> </span><span class="m">7763</span><span class="w"> </span><span class="m">64</span>-Core<span class="w"> </span>Processor
<a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a>
<a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a><span class="c1"># 查詢物理 CPU 個數</span>
<a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l</span>
<a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a><span class="m">1</span>
<a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a>
<a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a><span class="c1"># 查詢每個物理 CPU 的 Core 數</span>
<a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a><span class="c1"># 若於 Azure Portal 設定 `platformsettings.host_environment.disablehyperthreading: true` 的話，則不會開啟 HT 的能力</span>
<a id="__codelineno-25-17" name="__codelineno-25-17" href="#__codelineno-25-17"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq</span>
<a id="__codelineno-25-18" name="__codelineno-25-18" href="#__codelineno-25-18"></a><span class="m">2</span>
<a id="__codelineno-25-19" name="__codelineno-25-19" href="#__codelineno-25-19"></a>
<a id="__codelineno-25-20" name="__codelineno-25-20" href="#__codelineno-25-20"></a><span class="c1"># 查詢每個邏輯 vCPUs 的個數</span>
<a id="__codelineno-25-21" name="__codelineno-25-21" href="#__codelineno-25-21"></a><span class="c1"># 邏輯 vCPUs 個數 = 物理 CPU 個數 * 每個物理 CPU 的 Core 個數 * 2 (預設 Azure VM 會開啟 HT，意旨預設狀況下，platformsettings.host_environment.disablehyperthreading: false)</span>
<a id="__codelineno-25-22" name="__codelineno-25-22" href="#__codelineno-25-22"></a><span class="c1"># https://learn.microsoft.com/en-us/azure/virtual-machines/mitigate-se#linux</span>
<a id="__codelineno-25-23" name="__codelineno-25-23" href="#__codelineno-25-23"></a><span class="c1"># 根據加總 processor 數量，故知道該 VM 為 4 vcpus</span>
<a id="__codelineno-25-24" name="__codelineno-25-24" href="#__codelineno-25-24"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l</span>
<a id="__codelineno-25-25" name="__codelineno-25-25" href="#__codelineno-25-25"></a><span class="m">4</span>
<a id="__codelineno-25-26" name="__codelineno-25-26" href="#__codelineno-25-26"></a>
<a id="__codelineno-25-27" name="__codelineno-25-27" href="#__codelineno-25-27"></a><span class="c1"># https://www.amd.com/en/products/cpu/amd-epyc-7763</span>
<a id="__codelineno-25-28" name="__codelineno-25-28" href="#__codelineno-25-28"></a><span class="c1"># Base Clock 2.45GHz, Max. Boost Clock Up to 3.5GHz</span>
<a id="__codelineno-25-29" name="__codelineno-25-29" href="#__codelineno-25-29"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/cpuinfo | grep &quot;cpu MHz&quot; | uniq</span>
<a id="__codelineno-25-30" name="__codelineno-25-30" href="#__codelineno-25-30"></a>cpu<span class="w"> </span>MHz<span class="w">         </span>:<span class="w"> </span><span class="m">2946</span>.906
<a id="__codelineno-25-31" name="__codelineno-25-31" href="#__codelineno-25-31"></a>cpu<span class="w"> </span>MHz<span class="w">         </span>:<span class="w"> </span><span class="m">2445</span>.427
<a id="__codelineno-25-32" name="__codelineno-25-32" href="#__codelineno-25-32"></a>cpu<span class="w"> </span>MHz<span class="w">         </span>:<span class="w"> </span><span class="m">2445</span>.427
<a id="__codelineno-25-33" name="__codelineno-25-33" href="#__codelineno-25-33"></a>cpu<span class="w"> </span>MHz<span class="w">         </span>:<span class="w"> </span><span class="m">2445</span>.427
</code></pre></div>
<p>主要這邊是要講有開 HT 和沒開 HT 的狀況下，vCPU 呈現會不同，而 Azure VM 預設狀況下都是會把 HT 開起來的。倘若要跑 HPC 或其他你就是要把這台機器效能榨到極限，則要把 HT 關掉，可使用 <code>platformsettings.host_environment.disablehyperthreading=true</code></p>
<h5 id="b-numa-non-uniform-memeory-acces"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#b-numa-non-uniform-memeory-acces">b. NUMA (Non-uniform memeory acces)</a></h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="c1"># numa</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># yum install numactl -y # 預設沒有，需要裝</span>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a><span class="c1"># 如下顯示，只有一個 NUMA Node，裡面有 4 個 vcpus 且被分配到 15734 MB 的 Memory</span>
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># numactl -H</span>
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>available:<span class="w"> </span><span class="m">1</span><span class="w"> </span>nodes<span class="w"> </span><span class="o">(</span><span class="m">0</span><span class="o">)</span>
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a>node<span class="w"> </span><span class="m">0</span><span class="w"> </span>cpus:<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">3</span>
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>node<span class="w"> </span><span class="m">0</span><span class="w"> </span>size:<span class="w"> </span><span class="m">15734</span><span class="w"> </span>MB
<a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a>node<span class="w"> </span><span class="m">0</span><span class="w"> </span>free:<span class="w"> </span><span class="m">7277</span><span class="w"> </span>MB
<a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a>node<span class="w"> </span>distances:
<a id="__codelineno-26-11" name="__codelineno-26-11" href="#__codelineno-26-11"></a>node<span class="w">   </span><span class="m">0</span>
<a id="__codelineno-26-12" name="__codelineno-26-12" href="#__codelineno-26-12"></a><span class="w">  </span><span class="m">0</span>:<span class="w">  </span><span class="m">10</span>
<a id="__codelineno-26-13" name="__codelineno-26-13" href="#__codelineno-26-13"></a>
<a id="__codelineno-26-14" name="__codelineno-26-14" href="#__codelineno-26-14"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># numactl --show</span>
<a id="__codelineno-26-15" name="__codelineno-26-15" href="#__codelineno-26-15"></a>policy:<span class="w"> </span>default
<a id="__codelineno-26-16" name="__codelineno-26-16" href="#__codelineno-26-16"></a>preferred<span class="w"> </span>node:<span class="w"> </span>current
<a id="__codelineno-26-17" name="__codelineno-26-17" href="#__codelineno-26-17"></a>physcpubind:<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">3</span>
<a id="__codelineno-26-18" name="__codelineno-26-18" href="#__codelineno-26-18"></a>cpubind:<span class="w"> </span><span class="m">0</span>
<a id="__codelineno-26-19" name="__codelineno-26-19" href="#__codelineno-26-19"></a>nodebind:<span class="w"> </span><span class="m">0</span>
<a id="__codelineno-26-20" name="__codelineno-26-20" href="#__codelineno-26-20"></a>membind:<span class="w"> </span><span class="m">0</span>
</code></pre></div>
<p>順便一提，雖然跟節點本身沒啥關係，針對 Kubernetes Pod 對於 CPU 的優化，除了花錢砸買更好的 CPU 以外，比較有策略或很 Kubernetes 的方式是，採用 Topology Manager 嘗試調整出最佳化 NUMA，<a href="https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/">Control Topology Management Policies on a node</a>。現行共有 4 個策略可用: none, best-effort, restricted, single-numa-node，AKS 預設是採用 <code>none</code>，該功能常見於 5G / CNF 等對於 Pod 之於 NUMA 的使用效率有特別要求的場景，如 UPF 服務會出現，可參考 <a href="https://speakerdeck.com/pichuang/qian-tan-azure-private-5g-core-he-kubernetes?slide=15">20221028 淺談 Azure Private 5G Core 和 Kubernetes</a></p>
<h4 id="2-memory"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#2-memory">2. Memory 相關</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="c1">#</span>
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="c1"># Memory</span>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a><span class="c1">#</span>
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a><span class="c1"># 依據 MemAvailable 所示，這台機器有 13479504 kB 的 Memory 可用</span>
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/meminfo</span>
<a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>MemTotal:<span class="w">       </span><span class="m">16112256</span><span class="w"> </span>kB<span class="w"> </span><span class="c1"># 所有 Memory 大小, 故為 16 GB</span>
<a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>MemFree:<span class="w">         </span><span class="m">7317172</span><span class="w"> </span>kB<span class="w"> </span><span class="c1"># 完全沒到的 Memory 大小，很顯然我這台機器開太大了，太閒</span>
<a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>MemAvailable:<span class="w">   </span><span class="m">13479504</span><span class="w"> </span>kB<span class="w"> </span><span class="c1"># 實際上可用的 Memory 大小，MemAvailable &lt;= MemFree + Active(file) + Inactive(file) + SReclaimable</span>
<a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>Active<span class="o">(</span>file<span class="o">)</span>:<span class="w">    </span><span class="m">1067108</span><span class="w"> </span>kB
<a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>Inactive<span class="o">(</span>file<span class="o">)</span>:<span class="w">  </span><span class="m">5021812</span><span class="w"> </span>kB
<a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>Slab:<span class="w">             </span><span class="m">486692</span><span class="w"> </span>kB
<a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>SReclaimable:<span class="w">     </span><span class="m">334712</span><span class="w"> </span>kB
<a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a>HugePages_Total:<span class="w">       </span><span class="m">0</span>
<a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>
<a id="__codelineno-27-16" name="__codelineno-27-16" href="#__codelineno-27-16"></a><span class="c1"># MemTotal 為 16112256 kB = 719104 kB + 15393152 kB</span>
<a id="__codelineno-27-17" name="__codelineno-27-17" href="#__codelineno-27-17"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/zoneinfo</span>
<a id="__codelineno-27-18" name="__codelineno-27-18" href="#__codelineno-27-18"></a>Node<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>zone<span class="w">    </span>DMA32
<a id="__codelineno-27-19" name="__codelineno-27-19" href="#__codelineno-27-19"></a><span class="w">  </span>pages<span class="w"> </span>free<span class="w">     </span><span class="m">179568</span>
<a id="__codelineno-27-20" name="__codelineno-27-20" href="#__codelineno-27-20"></a><span class="w">        </span>managed<span class="w">  </span><span class="m">179776</span><span class="w"> </span><span class="c1"># 給 DMA32 使用的記憶體空間為 702.25 MB = 719104 KB = 179776 * 4 KB</span>
<a id="__codelineno-27-21" name="__codelineno-27-21" href="#__codelineno-27-21"></a>Node<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>zone<span class="w">   </span>Normal
<a id="__codelineno-27-22" name="__codelineno-27-22" href="#__codelineno-27-22"></a><span class="w">  </span>pages<span class="w"> </span>free<span class="w">     </span><span class="m">1974218</span>
<a id="__codelineno-27-23" name="__codelineno-27-23" href="#__codelineno-27-23"></a><span class="w">        </span>managed<span class="w">  </span><span class="m">3848288</span><span class="w"> </span><span class="c1"># 給 Normal 使用的記憶體空間為 14.68 GB = 15393152 KB = 3848288 * 4 KB</span>
<a id="__codelineno-27-24" name="__codelineno-27-24" href="#__codelineno-27-24"></a>
<a id="__codelineno-27-25" name="__codelineno-27-25" href="#__codelineno-27-25"></a><span class="c1"># 一個 Slab page 可用空間 32768 Bytes = 4096 Bytes * pagesperslab 8</span>
<a id="__codelineno-27-26" name="__codelineno-27-26" href="#__codelineno-27-26"></a><span class="c1"># TCP 實際 Slab page 內有 31360 Bytes 被使用 = objsize 2240 Bytes * objperslab 14</span>
<a id="__codelineno-27-27" name="__codelineno-27-27" href="#__codelineno-27-27"></a><span class="c1"># Slab page 碎片 1408 Bytes = 32768 - 31360</span>
<a id="__codelineno-27-28" name="__codelineno-27-28" href="#__codelineno-27-28"></a><span class="c1"># TCP 實際占用的記憶體空間 470400 Bytes = num_objs 210 * objsize 2240 Bytes</span>
<a id="__codelineno-27-29" name="__codelineno-27-29" href="#__codelineno-27-29"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/slabinfo | grep TCP</span>
<a id="__codelineno-27-30" name="__codelineno-27-30" href="#__codelineno-27-30"></a><span class="c1"># name            &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt;</span>
<a id="__codelineno-27-31" name="__codelineno-27-31" href="#__codelineno-27-31"></a>TCP<span class="w">                  </span><span class="m">210</span><span class="w">    </span><span class="m">210</span><span class="w">   </span><span class="m">2240</span><span class="w">   </span><span class="m">14</span><span class="w">    </span><span class="m">8</span><span class="w"> </span>:<span class="w"> </span>tunables<span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w">    </span><span class="m">0</span><span class="w"> </span>:<span class="w"> </span>slabdata<span class="w">     </span><span class="m">15</span><span class="w">     </span><span class="m">15</span><span class="w">      </span><span class="m">0</span>
</code></pre></div>
<p>記憶體是不可被壓縮資源，跟 CPU 不一樣，如果 MemAvailable 真的用到 0 的狀況下，就代表你的節點記憶體真的是太小了，完全不夠分配出去，上面的 Pod 很容易有滿滿 OOM 的狀況。</p>
<p>如果你想要 Pod 有保障的資源可以用，你需要從 k8s 的角度去控制 cpu.request / cpu.limit / memory.request / memory.limit，可參考小弟舊文 <a href="https://blog.pichuang.com.tw/20211112-how-to-sizing-kubernetes-resource-and-infra-resource.html">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a>，這篇不會特別涉及，之後會講一篇由下而上的 Node 和由上而下的管理 Kubernetes 角度上的資源對照</p>
<p>順便一提，維持一個 Long Lived TCP Connection ，且不包含其他的資料傳輸，消耗的記憶體大約為 ~3.3 KB，若全部都是 Long Lived TCP Connection 且無實際資料運作或傳輸的話，大概就是消耗 3.3 GB 記憶體存這些資訊，可參考 <code>Q5: 單台 C1000K 是怎麼算出來的? 預設啥都沒做的狀況下記憶體消耗為何?</code> 的內容</p>
<h4 id="3-linux-kernel"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#3-linux-kernel">3. Linux Kernel 相關</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="c1">#</span>
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a><span class="c1"># Kernel Paraemters</span>
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a><span class="c1">#</span>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># uname -a</span>
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>Linux<span class="w"> </span>aks-agentpool-14864487-vmss000000<span class="w"> </span><span class="m">5</span>.15.131.1-2.cm2<span class="w"> </span><span class="c1">#1 SMP Sun Sep 24 03:38:45 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux</span>
<a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>
<a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a><span class="c1"># 下列都是 CBL-Mariner 的預設值</span>
<a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># sysctl -a</span>
<a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>net.ipv4.ip_local_port_range<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">32768</span><span class="w">    </span><span class="m">60999</span><span class="w"> </span><span class="c1"># 該 VM 可使用的 Port Range，預設範圍為 32768 ~ 60999，共 28232 個 Port，可調整</span>
<a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a>net.ipv4.tcp_syn_retries<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span>
<a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a>net.ipv4.tcp_synack_retries<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span>
<a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a>net.ipv4.tcp_syncookies<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="c1"># 預設可防止部分 SYN Flood 攻擊</span>
<a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a>net.ipv4.tcp_tw_reuse<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span>
<a id="__codelineno-28-14" name="__codelineno-28-14" href="#__codelineno-28-14"></a>net.ipv4.tcp_max_syn_backlog<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16384</span>
<a id="__codelineno-28-15" name="__codelineno-28-15" href="#__codelineno-28-15"></a>net.ipv4.tcp_max_tw_buckets<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">65536</span>
<a id="__codelineno-28-16" name="__codelineno-28-16" href="#__codelineno-28-16"></a>net.core.somaxconn<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16384</span>
<a id="__codelineno-28-17" name="__codelineno-28-17" href="#__codelineno-28-17"></a>fs.file-max<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9223372036854775807</span><span class="w"> </span><span class="c1"># OS Level，為 Int64.MaxValue 最大位數，十六進位0x7FFFFFFFFFFFFFFF</span>
<a id="__codelineno-28-18" name="__codelineno-28-18" href="#__codelineno-28-18"></a>fs.nr_open<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1073741816</span><span class="w"> </span><span class="c1"># Progess Level，需要比 * hard nofile (1048576) 大，不然會開不起來</span>
<a id="__codelineno-28-19" name="__codelineno-28-19" href="#__codelineno-28-19"></a>net.ipv4.tcp_congestion_control<span class="w"> </span><span class="o">=</span><span class="w"> </span>cubic
<a id="__codelineno-28-20" name="__codelineno-28-20" href="#__codelineno-28-20"></a>net.ipv4.tcp_mtu_probing<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span>
<a id="__codelineno-28-21" name="__codelineno-28-21" href="#__codelineno-28-21"></a>net.ipv4.tcp_fastopen<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span>
<a id="__codelineno-28-22" name="__codelineno-28-22" href="#__codelineno-28-22"></a>
<a id="__codelineno-28-23" name="__codelineno-28-23" href="#__codelineno-28-23"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>/<span class="w"> </span><span class="o">]</span><span class="c1"># ulimit -a</span>
<a id="__codelineno-28-24" name="__codelineno-28-24" href="#__codelineno-28-24"></a>real-time<span class="w"> </span>non-blocking<span class="w"> </span><span class="nb">time</span><span class="w">  </span><span class="o">(</span>microseconds,<span class="w"> </span>-R<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-25" name="__codelineno-28-25" href="#__codelineno-28-25"></a>core<span class="w"> </span>file<span class="w"> </span>size<span class="w">              </span><span class="o">(</span>blocks,<span class="w"> </span>-c<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-26" name="__codelineno-28-26" href="#__codelineno-28-26"></a>data<span class="w"> </span>seg<span class="w"> </span>size<span class="w">               </span><span class="o">(</span>kbytes,<span class="w"> </span>-d<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-27" name="__codelineno-28-27" href="#__codelineno-28-27"></a>scheduling<span class="w"> </span>priority<span class="w">                 </span><span class="o">(</span>-e<span class="o">)</span><span class="w"> </span><span class="m">0</span>
<a id="__codelineno-28-28" name="__codelineno-28-28" href="#__codelineno-28-28"></a>file<span class="w"> </span>size<span class="w">                   </span><span class="o">(</span>blocks,<span class="w"> </span>-f<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-29" name="__codelineno-28-29" href="#__codelineno-28-29"></a>pending<span class="w"> </span>signals<span class="w">                     </span><span class="o">(</span>-i<span class="o">)</span><span class="w"> </span><span class="m">62863</span>
<a id="__codelineno-28-30" name="__codelineno-28-30" href="#__codelineno-28-30"></a>max<span class="w"> </span>locked<span class="w"> </span>memory<span class="w">           </span><span class="o">(</span>kbytes,<span class="w"> </span>-l<span class="o">)</span><span class="w"> </span><span class="m">64</span>
<a id="__codelineno-28-31" name="__codelineno-28-31" href="#__codelineno-28-31"></a>max<span class="w"> </span>memory<span class="w"> </span>size<span class="w">             </span><span class="o">(</span>kbytes,<span class="w"> </span>-m<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-32" name="__codelineno-28-32" href="#__codelineno-28-32"></a>open<span class="w"> </span>files<span class="w">                          </span><span class="o">(</span>-n<span class="o">)</span><span class="w"> </span><span class="m">1048576</span><span class="w"> </span><span class="c1"># 同時可打開的檔案數量，Azure 提供的 CBL-Mariner 作業系統預設是 2^20 個，單台 VM 帳面預設數字是支援做到 C1000K 等級</span>
<a id="__codelineno-28-33" name="__codelineno-28-33" href="#__codelineno-28-33"></a>pipe<span class="w"> </span>size<span class="w">                </span><span class="o">(</span><span class="m">512</span><span class="w"> </span>bytes,<span class="w"> </span>-p<span class="o">)</span><span class="w"> </span><span class="m">8</span>
<a id="__codelineno-28-34" name="__codelineno-28-34" href="#__codelineno-28-34"></a>POSIX<span class="w"> </span>message<span class="w"> </span>queues<span class="w">         </span><span class="o">(</span>bytes,<span class="w"> </span>-q<span class="o">)</span><span class="w"> </span><span class="m">819200</span>
<a id="__codelineno-28-35" name="__codelineno-28-35" href="#__codelineno-28-35"></a>real-time<span class="w"> </span>priority<span class="w">                  </span><span class="o">(</span>-r<span class="o">)</span><span class="w"> </span><span class="m">0</span>
<a id="__codelineno-28-36" name="__codelineno-28-36" href="#__codelineno-28-36"></a>stack<span class="w"> </span>size<span class="w">                  </span><span class="o">(</span>kbytes,<span class="w"> </span>-s<span class="o">)</span><span class="w"> </span><span class="m">8192</span>
<a id="__codelineno-28-37" name="__codelineno-28-37" href="#__codelineno-28-37"></a>cpu<span class="w"> </span><span class="nb">time</span><span class="w">                   </span><span class="o">(</span>seconds,<span class="w"> </span>-t<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-38" name="__codelineno-28-38" href="#__codelineno-28-38"></a>max<span class="w"> </span>user<span class="w"> </span>processes<span class="w">                  </span><span class="o">(</span>-u<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-39" name="__codelineno-28-39" href="#__codelineno-28-39"></a>virtual<span class="w"> </span>memory<span class="w">              </span><span class="o">(</span>kbytes,<span class="w"> </span>-v<span class="o">)</span><span class="w"> </span>unlimited
<a id="__codelineno-28-40" name="__codelineno-28-40" href="#__codelineno-28-40"></a>file<span class="w"> </span>locks<span class="w">                          </span><span class="o">(</span>-x<span class="o">)</span><span class="w"> </span>unlimited
</code></pre></div>
<p>前陣子 CNCF 有一篇部落格 <a href="https://www.cncf.io/blog/2023/06/13/tuning-emqx-to-scale-to-one-million-concurrent-connections-on-kubernetes/">Tuning EMQX to scale to one million concurrent connections on Kubernetes</a> 就在講如何調整節點內的 Linux Kernel 參數來達到 1 百萬 Concurrent Connections</p>
<p>這邊來比對一下 CBL-Mariner 預設參數跟 <a href="https://www.emqx.io/docs/en/v4.4/tutorial/tune.html#turn-off-swap">EMQX Linux Kernel Tuning</a> 的差異</p>
<table>
<thead>
<tr>
<th style="text-align: center;">sysctl</th>
<th style="text-align: center;">CBL-Mariner 2.0</th>
<th style="text-align: center;">EMQX</th>
<th style="text-align: center;">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">fs.file-max</td>
<td style="text-align: center;">9223372036854775807</td>
<td style="text-align: center;">2097152</td>
<td style="text-align: center;">整個 OS 最大開檔數量</td>
</tr>
<tr>
<td style="text-align: center;">fs.fs.nr_open</td>
<td style="text-align: center;">1073741816</td>
<td style="text-align: center;">2097152</td>
<td style="text-align: center;">單一程序最大開檔數量</td>
</tr>
<tr>
<td style="text-align: center;">net.core.somaxconn</td>
<td style="text-align: center;">16384</td>
<td style="text-align: center;">32768</td>
<td style="text-align: center;">全連接佇列長度: min(tcp_max_syn_backlog, somaxconn)</td>
</tr>
<tr>
<td style="text-align: center;">net.ipv4.tcp_max_syn_backlog</td>
<td style="text-align: center;">16384</td>
<td style="text-align: center;">16384</td>
<td style="text-align: center;">全連接佇列長度: min(tcp_max_syn_backlog, somaxconn)</td>
</tr>
<tr>
<td style="text-align: center;">net.core.netdev_max_backlog</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">16384</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">net.ipv4.ip_local_port_range</td>
<td style="text-align: center;">32768 60999</td>
<td style="text-align: center;">1000 65535</td>
<td style="text-align: center;">VM 可用 Port 範圍，但單純以 Server 端角度來說調這個沒啥太大用處，多半都 80, 443 為主，但當 Client 來講就有效果了，譬如說你要外連 DB 還是有的沒的外部服務之類的，這個調大會比較好</td>
</tr>
<tr>
<td style="text-align: center;">net.core.rmem_default</td>
<td style="text-align: center;">212992</td>
<td style="text-align: center;">262144</td>
<td style="text-align: center;">TCP Recieve Windows</td>
</tr>
<tr>
<td style="text-align: center;">net.core.rmem_max</td>
<td style="text-align: center;">212992</td>
<td style="text-align: center;">16777216</td>
<td style="text-align: center;">TCP Recieve Windows</td>
</tr>
<tr>
<td style="text-align: center;">net.core.wmem_default</td>
<td style="text-align: center;">212992</td>
<td style="text-align: center;">262144</td>
<td style="text-align: center;">TCP Write Windows</td>
</tr>
<tr>
<td style="text-align: center;">net.core.wmem_max</td>
<td style="text-align: center;">212992</td>
<td style="text-align: center;">16777216</td>
<td style="text-align: center;">TCP Write Windows</td>
</tr>
<tr>
<td style="text-align: center;">net.core.optmem_max</td>
<td style="text-align: center;">20480</td>
<td style="text-align: center;">16777216</td>
<td style="text-align: center;">緩衝區大小</td>
</tr>
<tr>
<td style="text-align: center;">net.ipv4.tcp_rmem</td>
<td style="text-align: center;">4096 131072 6291456</td>
<td style="text-align: center;">1024 262144 16777216</td>
<td style="text-align: center;">因為 MQ，訊息量小，可以 1KB 就發送一次</td>
</tr>
<tr>
<td style="text-align: center;">net.ipv4.tcp_wmem</td>
<td style="text-align: center;">4096 16384 4194304</td>
<td style="text-align: center;">1024 262144 16777216</td>
<td style="text-align: center;">因為 MQ，訊息量小，可以 1KB 就發送一次</td>
</tr>
<tr>
<td style="text-align: center;">net.netfilter.nf_conntrack_max</td>
<td style="text-align: center;">131072</td>
<td style="text-align: center;">1000000</td>
<td style="text-align: center;">調高 nf_conntrack_max 的接受上限</td>
</tr>
<tr>
<td style="text-align: center;">net.netfilter.nf_conntrack_tcp_timeout_time_wait</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">net.ipv4.tcp_max_tw_buckets</td>
<td style="text-align: center;">65536</td>
<td style="text-align: center;">1048576</td>
<td style="text-align: center;">超過 TIME_WAIT 設定值則清除</td>
</tr>
<tr>
<td style="text-align: center;">net.ipv4.tcp_fin_timeout</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">調降 TCP 在 FIN-WAIT-2 的時間</td>
</tr>
</tbody>
</table>
<p>如果要針對上述的參數進行調整，在 AKS 裡面，你需要依循 <a href="https://learn.microsoft.com/zh-tw/azure/aks/custom-node-configuration?tabs=linux-node-pools#os-configuration">自訂 Azure Kubernetes Service (AKS) 節點集區的節點設定</a> 進行設定，而不是直接進去用 sysctl 改數值，但目前 az aks update 沒支援 --linux-os-config</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>az<span class="w"> </span>aks<span class="w"> </span>create<span class="w"> </span>--name<span class="w"> </span>myAKSCluster<span class="w"> </span>--resource-group<span class="w"> </span>myResourceGroup<span class="w"> </span>--linux-os-config<span class="w"> </span>./linuxosconfig.json
</code></pre></div>
<p>如果你是自建作業系統的話，就對 /etc/sysctl.conf 進行修改即可</p>
<h4 id="4-networking"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#4-networking">4. Networking</a></h4>
<h5 id="a-networking-hardware"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#a-networking-hardware">a. Networking Hardware</a></h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="c1">#</span>
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a><span class="c1"># Networking Hardware</span>
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="c1">#</span>
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a>
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="c1"># 顯示預設網卡 eth0 支援最大的 Channel 大小和現行設定的大小</span>
<a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># ethtool -l eth0</span>
<a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a>Channel<span class="w"> </span>parameters<span class="w"> </span><span class="k">for</span><span class="w"> </span>eth0:
<a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>Pre-set<span class="w"> </span>maximums:
<a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a>RX:<span class="w">             </span>n/a
<a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a>TX:<span class="w">             </span>n/a
<a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a>Other:<span class="w">          </span>n/a
<a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a>Combined:<span class="w">       </span><span class="m">4</span>
<a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a>Current<span class="w"> </span>hardware<span class="w"> </span>settings:
<a id="__codelineno-30-14" name="__codelineno-30-14" href="#__codelineno-30-14"></a>RX:<span class="w">             </span>n/a
<a id="__codelineno-30-15" name="__codelineno-30-15" href="#__codelineno-30-15"></a>TX:<span class="w">             </span>n/a
<a id="__codelineno-30-16" name="__codelineno-30-16" href="#__codelineno-30-16"></a>Other:<span class="w">          </span>n/a
<a id="__codelineno-30-17" name="__codelineno-30-17" href="#__codelineno-30-17"></a>Combined:<span class="w">       </span><span class="m">4</span><span class="w"> </span><span class="c1"># 用滿了，代表 RSS (Receive Side Scaling) 沒問題，在 CBL-Mariner 上已經是網路最佳化用法</span>
<a id="__codelineno-30-18" name="__codelineno-30-18" href="#__codelineno-30-18"></a>
<a id="__codelineno-30-19" name="__codelineno-30-19" href="#__codelineno-30-19"></a><span class="c1"># 下面的 interrupts 統一會由 irqbalance 自動控制，正常狀況下你不需要手動去維護下面的 /proc/irq/25,26,27,28/smp_affinity 設定</span>
<a id="__codelineno-30-20" name="__codelineno-30-20" href="#__codelineno-30-20"></a><span class="c1"># systemctl status irqbalance</span>
<a id="__codelineno-30-21" name="__codelineno-30-21" href="#__codelineno-30-21"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># cat /proc/interrupts | grep mlx5_comp</span>
<a id="__codelineno-30-22" name="__codelineno-30-22" href="#__codelineno-30-22"></a><span class="w">           </span>CPU0<span class="w">       </span>CPU1<span class="w">       </span>CPU2<span class="w">       </span>CPU3
<a id="__codelineno-30-23" name="__codelineno-30-23" href="#__codelineno-30-23"></a><span class="w"> </span><span class="m">25</span>:<span class="w">   </span><span class="m">14332354</span><span class="w">          </span><span class="m">0</span><span class="w">          </span><span class="m">0</span><span class="w">          </span><span class="m">0</span><span class="w">  </span>Hyper-V<span class="w"> </span>PCIe<span class="w"> </span>MSI<span class="w"> </span><span class="m">3758129153</span>-edge<span class="w">      </span>mlx5_comp0@pci:3ffc:00:02.0
<a id="__codelineno-30-24" name="__codelineno-30-24" href="#__codelineno-30-24"></a><span class="w"> </span><span class="m">26</span>:<span class="w">          </span><span class="m">0</span><span class="w">         </span><span class="m">14</span><span class="w">   </span><span class="m">13861183</span><span class="w">          </span><span class="m">0</span><span class="w">  </span>Hyper-V<span class="w"> </span>PCIe<span class="w"> </span>MSI<span class="w"> </span><span class="m">3758129154</span>-edge<span class="w">      </span>mlx5_comp1@pci:3ffc:00:02.0
<a id="__codelineno-30-25" name="__codelineno-30-25" href="#__codelineno-30-25"></a><span class="w"> </span><span class="m">27</span>:<span class="w">          </span><span class="m">0</span><span class="w">   </span><span class="m">17419688</span><span class="w">         </span><span class="m">12</span><span class="w">          </span><span class="m">0</span><span class="w">  </span>Hyper-V<span class="w"> </span>PCIe<span class="w"> </span>MSI<span class="w"> </span><span class="m">3758129155</span>-edge<span class="w">      </span>mlx5_comp2@pci:3ffc:00:02.0
<a id="__codelineno-30-26" name="__codelineno-30-26" href="#__codelineno-30-26"></a><span class="w"> </span><span class="m">28</span>:<span class="w">          </span><span class="m">0</span><span class="w">          </span><span class="m">0</span><span class="w">          </span><span class="m">0</span><span class="w">   </span><span class="m">10673131</span><span class="w">  </span>Hyper-V<span class="w"> </span>PCIe<span class="w"> </span>MSI<span class="w"> </span><span class="m">3758129156</span>-edge<span class="w">      </span>mlx5_comp3@pci:3ffc:00:02.0
<a id="__codelineno-30-27" name="__codelineno-30-27" href="#__codelineno-30-27"></a>...
<a id="__codelineno-30-28" name="__codelineno-30-28" href="#__codelineno-30-28"></a>
<a id="__codelineno-30-29" name="__codelineno-30-29" href="#__codelineno-30-29"></a><span class="c1"># 預設是使用 GRO 在 Linux Kernel 上把合併封包的事情給解決了，而非 LRO 在網卡上把合併封包的事情給解決了</span>
<a id="__codelineno-30-30" name="__codelineno-30-30" href="#__codelineno-30-30"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># ethtool -k eth0</span>
<a id="__codelineno-30-31" name="__codelineno-30-31" href="#__codelineno-30-31"></a>generic-receive-offload:<span class="w"> </span>on
<a id="__codelineno-30-32" name="__codelineno-30-32" href="#__codelineno-30-32"></a>large-receive-offload:<span class="w"> </span>off
</code></pre></div>
<h5 id="b-routing"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#b-routing">b. Routing</a></h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="c1">#</span>
<a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a><span class="c1"># Linux Networking</span>
<a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a><span class="c1">#</span>
<a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a>
<a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a><span class="c1"># 顯示這台節點上的路由</span>
<a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># ip route</span>
<a id="__codelineno-31-7" name="__codelineno-31-7" href="#__codelineno-31-7"></a><span class="c1"># 這邊要注意的是，其實我有設定 UDR 強制把 egress (a.k.a outbound traffic) 所有流量導到 Firewall (10.99.x.x) 上，但從路由表上會看不出來，得從 Azure Portal 上看</span>
<a id="__codelineno-31-8" name="__codelineno-31-8" href="#__codelineno-31-8"></a><span class="c1"># 以下是 Node IP 的路由 10.0.128.0/24，Default Gateway 為該網段的第一個 IP，也就是 10.0.128.1</span>
<a id="__codelineno-31-9" name="__codelineno-31-9" href="#__codelineno-31-9"></a>default<span class="w"> </span>via<span class="w"> </span><span class="m">10</span>.0.128.1<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>dhcp<span class="w"> </span>src<span class="w"> </span><span class="m">10</span>.0.128.5<span class="w"> </span>metric<span class="w"> </span><span class="m">100</span>
<a id="__codelineno-31-10" name="__codelineno-31-10" href="#__codelineno-31-10"></a><span class="m">10</span>.0.128.0/24<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>kernel<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">10</span>.0.128.5<span class="w"> </span>metric<span class="w"> </span><span class="m">100</span>
<a id="__codelineno-31-11" name="__codelineno-31-11" href="#__codelineno-31-11"></a><span class="m">10</span>.0.128.1<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>dhcp<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">10</span>.0.128.5<span class="w"> </span>metric<span class="w"> </span><span class="m">100</span>
<a id="__codelineno-31-12" name="__codelineno-31-12" href="#__codelineno-31-12"></a><span class="c1"># 以下是 Pod IP 的路由，10.0.129.0/24</span>
<a id="__codelineno-31-13" name="__codelineno-31-13" href="#__codelineno-31-13"></a><span class="m">10</span>.0.129.0/24<span class="w"> </span>via<span class="w"> </span><span class="m">10</span>.0.128.1<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-14" name="__codelineno-31-14" href="#__codelineno-31-14"></a><span class="m">10</span>.0.129.5<span class="w"> </span>dev<span class="w"> </span>azv7d24922a083<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-15" name="__codelineno-31-15" href="#__codelineno-31-15"></a><span class="m">10</span>.0.129.8<span class="w"> </span>dev<span class="w"> </span>azv9da73473eb2<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-16" name="__codelineno-31-16" href="#__codelineno-31-16"></a><span class="m">10</span>.0.129.9<span class="w"> </span>dev<span class="w"> </span>azv6f0c6f1ef57<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-17" name="__codelineno-31-17" href="#__codelineno-31-17"></a><span class="m">10</span>.0.129.10<span class="w"> </span>dev<span class="w"> </span>azvaa6ccb05bb5<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-18" name="__codelineno-31-18" href="#__codelineno-31-18"></a><span class="m">10</span>.0.129.13<span class="w"> </span>dev<span class="w"> </span>azvcdfece9bfdf<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-19" name="__codelineno-31-19" href="#__codelineno-31-19"></a><span class="m">10</span>.0.129.14<span class="w"> </span>dev<span class="w"> </span>azvf893453cbc5<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-20" name="__codelineno-31-20" href="#__codelineno-31-20"></a><span class="m">10</span>.0.129.15<span class="w"> </span>dev<span class="w"> </span>azv1f6d5d20426<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-21" name="__codelineno-31-21" href="#__codelineno-31-21"></a><span class="m">10</span>.0.129.16<span class="w"> </span>dev<span class="w"> </span>azvf85308aa314<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-22" name="__codelineno-31-22" href="#__codelineno-31-22"></a><span class="m">10</span>.0.129.17<span class="w"> </span>dev<span class="w"> </span>azva9b3f83744f<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-23" name="__codelineno-31-23" href="#__codelineno-31-23"></a><span class="m">10</span>.0.129.21<span class="w"> </span>dev<span class="w"> </span>azv224fa8c56a6<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-24" name="__codelineno-31-24" href="#__codelineno-31-24"></a><span class="m">10</span>.0.129.22<span class="w"> </span>dev<span class="w"> </span>azvbb0334487e3<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-25" name="__codelineno-31-25" href="#__codelineno-31-25"></a><span class="m">10</span>.0.129.25<span class="w"> </span>dev<span class="w"> </span>azvca12febb7ce<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-26" name="__codelineno-31-26" href="#__codelineno-31-26"></a><span class="m">10</span>.0.129.27<span class="w"> </span>dev<span class="w"> </span>azv0867699d9ac<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-27" name="__codelineno-31-27" href="#__codelineno-31-27"></a><span class="m">10</span>.0.129.28<span class="w"> </span>dev<span class="w"> </span>azva412bba2170<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-28" name="__codelineno-31-28" href="#__codelineno-31-28"></a><span class="m">10</span>.0.129.29<span class="w"> </span>dev<span class="w"> </span>azvd4c029379b6<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-29" name="__codelineno-31-29" href="#__codelineno-31-29"></a><span class="m">10</span>.0.129.30<span class="w"> </span>dev<span class="w"> </span>azv9a46f9ec6ea<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-30" name="__codelineno-31-30" href="#__codelineno-31-30"></a><span class="m">10</span>.0.129.35<span class="w"> </span>dev<span class="w"> </span>azvd96d575dd35<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-31" name="__codelineno-31-31" href="#__codelineno-31-31"></a><span class="m">10</span>.0.129.36<span class="w"> </span>dev<span class="w"> </span>azvee4ae66e969<span class="w"> </span>proto<span class="w"> </span>static
<a id="__codelineno-31-32" name="__codelineno-31-32" href="#__codelineno-31-32"></a><span class="c1"># 下面是這台節點與 Azure 平台資源 168.63.129.16 溝通用的路由</span>
<a id="__codelineno-31-33" name="__codelineno-31-33" href="#__codelineno-31-33"></a><span class="m">168</span>.63.129.16<span class="w"> </span>via<span class="w"> </span><span class="m">10</span>.0.128.1<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>dhcp<span class="w"> </span>src<span class="w"> </span><span class="m">10</span>.0.128.5<span class="w"> </span>metric<span class="w"> </span><span class="m">100</span>
<a id="__codelineno-31-34" name="__codelineno-31-34" href="#__codelineno-31-34"></a><span class="c1"># 下面是跟 Azure Instance Metadata Service 溝通用的路由</span>
<a id="__codelineno-31-35" name="__codelineno-31-35" href="#__codelineno-31-35"></a><span class="m">169</span>.254.169.254<span class="w"> </span>via<span class="w"> </span><span class="m">10</span>.0.128.1<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>dhcp<span class="w"> </span>src<span class="w"> </span><span class="m">10</span>.0.128.5<span class="w"> </span>metric<span class="w"> </span><span class="m">100</span>
</code></pre></div>
<p>看路由表主要的目的是討論 Kubernetes Egress，也就是 Pod 從節點出去的路徑是怎麼走的。因為我使用的 CNI (Container Networking Interface) 為 Azure-CNI，而非使用 kubenet 或 overlay CNI 等，所以 Pod IP 其實就是我指派的某一段 Azure Subnet 網段，按照該路由，是可以從別的 Azure Subnet 或已開啟 VNet Peering 的服務直接摸到 Pod IP。</p>
<p>若你的 kube-proxy 是走 iptables 的話，其實是可以對 Node 套 iptables rule 影響上面的 Pod 路由，譬如說拿 ansible 對所有節點直接上路由，但這已經非 Kubernetes 能管控的範圍了，所以正常狀況下都不建議在不清楚不明白的狀況下進行這件事</p>
<h3 id="_1"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#_1">後話</a></h3>
<ol>
<li>其實一開始我只是想要紀錄一下 AKS Node 上的一些預設參數，不知道為啥越寫越多。</li>
<li>如果你有看懂上面的內容，你會發現到其實研究 Kubernetes 就跟研究 Linux 作業系統是沒什麼太大區別的，不如說 Kubernetes 幫你抽象化了很多事情，讓你不用知道得太細，雖然變相你需要學習的就是 Kubernetes 的語言，從學習 shell 改成到 kubectl 的操作</li>
<li>看著上面的內容，所以我平時才會很常說，作業系統的穩定與否會直接影響 Kubernetes 的穩定性，滿滿地作業系統參數細節</li>
<li>AKS Node 是有考慮到大部分的使用者都不會去看這些參數，調教是以 C1000K 為目標基準先幫大家調好了，所以沒特殊狀況下都可以順順用，也不太會有節點硬體+作業系統效能問題，自建的就要自己加油了</li>
</ol>
<h3 id="qa"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#qa">Q&amp;A</a></h3>
<h4 id="q1-azure-vm-ht"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q1-azure-vm-ht">Q1: 如何針對 Azure VM 關閉 HT 功能?</a></h4>
<p>重開才會生效</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>az<span class="w"> </span>resource<span class="w"> </span>tag<span class="w"> </span>--ids<span class="w"> </span>/subscriptions/<span class="o">{</span>SubID<span class="o">}</span>/resourceGroups/<span class="o">{</span>ResourceGroup<span class="o">}</span>/providers/Microsoft.Compute/virtualMachines/<span class="o">{</span>VM<span class="o">}</span><span class="w"> </span>--tags<span class="w"> </span>platformsettings.host_environment.disablehyperthreading<span class="o">=</span><span class="nb">true</span>
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>az<span class="w"> </span>vm<span class="w"> </span>restart<span class="w"> </span>-g<span class="w"> </span><span class="o">{</span>ResourceGroup<span class="o">}</span><span class="w"> </span>-n<span class="w"> </span><span class="o">{</span>VM<span class="o">}</span>
</code></pre></div>
<h4 id="q2-azure-vm-instance-metadata"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q2-azure-vm-instance-metadata">Q2: 如何獲取該 Azure VM 的 Instance Metadata?</a></h4>
<p>根據此文 <a href="https://learn.microsoft.com/zh-tw/azure/virtual-network/what-is-ip-address-168-63-129-16">Azure VM Instance instance-metadata-service</a>，可透過以下方式獲取</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>root<span class="w"> </span><span class="o">[</span><span class="w"> </span>~<span class="w"> </span><span class="o">]</span><span class="c1"># curl -s -H Metadata:true --noproxy &quot;*&quot; &quot;http://169.254.169.254/metadata/instance?api-version=2021-02-01&quot; | jq</span>
</code></pre></div>
<h4 id="q3-eth0-channel"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q3-eth0-channel">Q3: 如果有要調整 eth0 的 channel 大小該怎麼做?</a></h4>
<p>如果你是用 AKS 的使用者，基本上都不用改，預設一開始都弄好了</p>
<p>暫時處理方式，因為這個是暫時性設定，如果該 AKS 節點被移除了，新增節點或既有的節點並不會有這個功能</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>$<span class="w"> </span>ethtool<span class="w"> </span>-L<span class="w"> </span>eth0<span class="w"> </span>combined<span class="w"> </span><span class="m">4</span>
</code></pre></div>
<h4 id="q4-platformsettingshost_environmentdisablehyperthreading-true"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q4-platformsettingshost_environmentdisablehyperthreading-true">Q4: 何時會選擇把 <code>platformsettings.host_environment.disablehyperthreading: true</code> 參數套上去</a></h4>
<p>跑 HPC 高效能計算類型的都蠻適合的，你會需要完整的核心計算能力，譬如說 EDA / 算圖 等</p>
<h4 id="q5-c1000k"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q5-c1000k">Q5: 單台 C1000K 是怎麼算出來的? 預設啥都沒做的狀況下記憶體消耗為何?</a></h4>
<p>Linux 開檔限制主要卡 3 個點，三者缺一不可，以 CBL-Mariner 來看的話，預設值如下所列，故單台最大可開檔數量為 1048576，約 C1000K</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Level</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Value</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">OS</td>
<td style="text-align: center;">sysctl -n fs.file-max</td>
<td style="text-align: center;">9223372036854775807</td>
<td>當前系統最大可開檔數量</td>
</tr>
<tr>
<td style="text-align: center;">Process</td>
<td style="text-align: center;">sysctl -n fs.nr_open</td>
<td style="text-align: center;">1073741816</td>
<td>單一程序可開檔最大數量，一定要比 hard nofile 大</td>
</tr>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">ulimit -n</td>
<td style="text-align: center;">1048576</td>
<td>當前使用者可開檔最大數量</td>
</tr>
</tbody>
</table>
<p>維持 1 個 TCP Connection 約略消耗 3.3 KB 的記憶體，故假設全部 1048576 都開起來的話，保持 Long Lived TCP Connection，但都沒傳輸其他東西的話，大概就 3.3 GB = 1048576 * 3.3 KB，但這是理想值，實際上會大一點，由此可知，連線數量的多寡其實還有受限於記憶體的多寡，而非僅受上述的開檔數量限制</p>
<h4 id="q6-1048576-50-tcp-connection-tcp-connection-1-kbs"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q6-1048576-50-tcp-connection-tcp-connection-1-kbs">Q6: 如果 1048576 有 50% 活躍 TCP Connection，每個 TCP Connection 需要傳 1 KB/s 的資料，這樣網卡需要多大?</a></h4>
<p>這個要算頻寬 (Bandwidth)，也就是要算水管的大小，這篇有一個小弟早期常用的表 <a href="https://blog.pichuang.com.tw/20190527-bandwidth-and-throughput.html">Bandwidth &amp; Throughput</a></p>
<p><img alt="" src="/images/throughput-bandwidth.png" /></p>
<p>[(1048576 TCP Connection * 50% * 1KB/s) / 1024] = 512 MB/s * 8 bits = 4096 Mbps = 4 Gbps</p>
<p>最少你也要有 4 Gbps Bandwidth 才能承受這個量體，而 Azure VM 的網路頻寬是基於 Instance 的選擇不同，而不是看內建網卡的設定 (ethtool eth0)，所以可從 <a href="https://learn.microsoft.com/zh-tw/azure/virtual-machines/dasv5-dadsv5-series">Dasv5 和 Dadsv5 系列</a> 中的 <code>Standard_D4as_v5</code> 的最大網路頻寬 (Max network bandwidth) 可得知為 12500 Mbps，遠大於所需的 4096 Mbps，故這台 Standard_D4as_v5 是可以支援問題所需的資料傳輸量</p>
<p>此外，如果你在 AKS 集群外面有用 UDR 丟給 Azure Firewall 的話，根據 <a href="https://learn.microsoft.com/en-us/azure/firewall/choose-firewall-sku">Choose the right Azure Firewall SKU to meet your needs</a> 的比較表，你需要選擇 SKU 最小為 Standard (30 Gbps) 或 Premium (100 Gbps)，而不能選 Basic，不然整個頻寬會卡在 250 Mbps</p>
<h4 id="q7-ulimit-n"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#q7-ulimit-n">Q7: 如何調整 ulimit -n 的值?</a></h4>
<p>如果你是用 AKS 的使用者，基本上都不用改，預設一開始都弄好了</p>
<p>如果你是自架作業系統的，就照下面的設定即可</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="c1"># 如果沒特別調過的，應該都是 1024 為主，譬如像 RHEL 9.2 和 RHEL 8.8 就是這樣</span>
<a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>$<span class="w"> </span><span class="nb">ulimit</span><span class="w"> </span>-n
<a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a><span class="m">1024</span>
<a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a>
<a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a><span class="c1"># 兩者取其低</span>
<a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a>$<span class="w"> </span>vim<span class="w"> </span>/etc/security/limits.conf
<a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a>*<span class="w"> </span>soft<span class="w"> </span>nofile<span class="w"> </span><span class="m">1048576</span>
<a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a>*<span class="w"> </span>hard<span class="w"> </span>nofile<span class="w"> </span><span class="m">1048576</span>
<a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a>
<a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a><span class="c1"># 不用 reboot，登出再登入就好</span>
<a id="__codelineno-35-11" name="__codelineno-35-11" href="#__codelineno-35-11"></a>$<span class="w"> </span>logout<span class="p">;</span><span class="w"> </span>login
<a id="__codelineno-35-12" name="__codelineno-35-12" href="#__codelineno-35-12"></a>$<span class="w"> </span><span class="nb">ulimit</span><span class="w"> </span>-n
<a id="__codelineno-35-13" name="__codelineno-35-13" href="#__codelineno-35-13"></a><span class="m">1048576</span>
</code></pre></div>
<h3 id="reference"><a class="toclink" href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/#reference">Reference</a></h3>
<ul>
<li><a href="https://lotabout.me/2021/Linux-Available-Memory/">我的内存呢？Linux MemAvailable 如何计算</a></li>
<li><a href="https://learn.microsoft.com/en-us/azure/virtual-machines/mitigate-se#linux">Guidance for mitigating silicon based micro-architectural and speculative execution side-channel vulnerabilities</a></li>
<li><a href="https://learn.microsoft.com/zh-tw/azure/virtual-network/what-is-ip-address-168-63-129-16">Azure VM Instance instance-metadata-service</a></li>
<li><a href="https://blog.pichuang.com.tw/20230713-distroless-container-debug.html">當遇到 Distroless Container 除錯要什麼沒什麼該怎麼辦? 你的好朋友 kubectl debug</a></li>
<li><a href="https://github.com/microsoft/CBL-Mariner">microsoft/CBL-Mariner</a></li>
<li><a href="https://learn.microsoft.com/zh-tw/azure/aks/custom-node-configuration?tabs=linux-node-pools#linux-kubelet-custom-configuration">自訂 Azure Kubernetes Service (AKS) 節點集區的節點設定 - Linux Kubelet 自訂設定</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/">Control Topology Management Policies on a node</a></li>
<li><a href="https://www.cncf.io/blog/2023/06/13/tuning-emqx-to-scale-to-one-million-concurrent-connections-on-kubernetes/">Tuning EMQX to scale to one million concurrent connections on Kubernetes</a></li>
<li><a href="https://www.emqx.io/docs/en/v4.4/tutorial/tune.html#turn-off-swap">EMQX Linux Kernel Tuning</a></li>
<li><a href="https://blog.pichuang.com.tw/20211112-how-to-sizing-kubernetes-resource-and-infra-resource.html">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a></li>
<li><a href="https://time.geekbang.org/column/article/262085">第315期 | 什么是C10K？如何做到C1000K？</a></li>
<li><a href="https://blog.pichuang.com.tw/20190527-bandwidth-and-throughput.html">Bandwidth &amp; Throughput</a></li>
<li><a href="https://learn.greensoftware.foundation/hardware-efficiency#increasing-device-utilization">Green Software Practitioner - Increasing device utilization</a></li>
<li><a href="https://learn.microsoft.com/en-us/azure/firewall/choose-firewall-sku">Choose the right Azure Firewall SKU to meet your needs</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2023/10/17/%E6%8F%AA%E7%AB%9Fazure-kubernetes-services-%E7%9A%84%E7%AF%80%E9%BB%9E%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BE%9B-c1000k-%E7%9A%84%E8%83%BD%E5%8A%9B%E5%91%A2/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-10-13 00:00:00">October 13, 2023</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="kubernetes"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/">人家都在抓神奇寶貝，而我在抓 Kubernetes 封包</a></h2>
<blockquote>
<p>Wireshark: Packet Don't Lie.</p>
</blockquote>
<p><img alt="" src="/images/life-is-hard.jpg" /></p>
<p>文章 <a href="https://blog.pichuang.com.tw/20231012-sustainability-remote-capture-packets.html">永續性軟體工程: 遠端抓封包實錄</a> 提到如何遠端抓單體 VM 封包，那同樣的招數可不可以去抓 Azure Kubernetes Service 特定 Pod 裡面的封包? 答案是可以，搭配 ksniff 來做就好</p>
<!--more-->

<h3 id="kubernetes_1"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#kubernetes_1">來抓 Kubernetes 封包</a></h3>
<h4 id="_1"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#_1">架構圖</a></h4>
<p><img alt="" src="/images/w9.png" /></p>
<ol>
<li>因為我不能直接從家裡連線到 Azure Kuberentes Service，所有操作都需要透過 Bastion VM 進行操作連線，所以需要先用 SSH 連線到 Bastion VM 才能做事</li>
<li>kubectl 一定要能對 Private AKS 操作，不然 ksniff 或程式你都無法部署下去</li>
<li>整張圖我沒提的部分就是 Private AKS 和 VM 的 UDR 設定，但這個太 Azure Networking 先跳過</li>
<li>一如既往，我是強烈建議人人都要有一個 debug container 好去做一些觀落陰的事情，詳見 <a href="https://blog.pichuang.com.tw/20230713-distroless-container-debug.html">當遇到 Distroless Container 除錯要什麼沒什麼該怎麼辦? 你的好朋友 kubectl debug</a>，這邊不贅述</li>
</ol>
<h4 id="0-ksniff"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#0-ksniff">0. 安裝 ksniff</a></h4>
<p>請直接參考 <a href="https://github.com/eldadru/ksniff">eldadru/ksniff</a> 文件，另外它的前置作業是要裝 <a href="https://krew.sigs.k8s.io/docs/user-guide/setup/install/">krew</a>，務必要把 krew PATH 設定好</p>
<h4 id="1-httpbin-re"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#1-httpbin-re">1. 部署 httpbin-re 服務</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c1"># 確定 kubectl 運作正常且可以連線到 Private AKS</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>cluster-info
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>Kubernetes<span class="w"> </span>control<span class="w"> </span>plane<span class="w"> </span>is<span class="w"> </span>running<span class="w"> </span>at<span class="w"> </span>https://dns-aoai.private.eastus2.azmk8s.io:443
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>CoreDNS<span class="w"> </span>is<span class="w"> </span>running<span class="w"> </span>at<span class="w"> </span>https://dns-aoai.private.eastus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>Metrics-server<span class="w"> </span>is<span class="w"> </span>running<span class="w"> </span>at<span class="w"> </span>https://dns-aoai.private.eastus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="c1"># 跑一個 http server 服務起來</span>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>$<span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>https://raw.githubusercontent.com/pichuang/httpbin-re/master/k8s/httpbin-re.yaml
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>deployment.apps/httpbin-re<span class="w"> </span>created
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>service/httpbin-re<span class="w"> </span>created
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a><span class="c1"># 確認服務有揭露出來</span>
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>$<span class="w"> </span>kubectl<span class="w"> </span>get<span class="w"> </span>svc<span class="w"> </span>httpbin-rek
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>NAME<span class="w">         </span>TYPE<span class="w">        </span>CLUSTER-IP<span class="w">     </span>EXTERNAL-IP<span class="w">   </span>PORT<span class="o">(</span>S<span class="o">)</span><span class="w">    </span>AGE
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>httpbin-re<span class="w">   </span>ClusterIP<span class="w">   </span><span class="m">10</span>.0.133.240<span class="w">   </span>&lt;none&gt;<span class="w">        </span><span class="m">8080</span>/TCP<span class="w">   </span>7h26m
</code></pre></div>
<p>主要是要部署一個 HTTP Server，待會要透過 Ksniff 去觀察這個服務的狀況，如果你有其他服務也可以自行替換，這邊就是 Demo 方便</p>
<h4 id="2-pod"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#2-pod">2. 部署陪測用 Pod</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="c1"># 部署陪測用 Pod，用順手的就好，或者是你可以考慮用 nicolaka/netshoot</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>https://raw.githubusercontent.com/pichuang/debug-container/master/debug-container.yaml
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>pod/debug-container<span class="w"> </span>created
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="c1"># 測試可以跟 httpbin-re 連線，同 namespace，不同 Pod</span>
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a><span class="c1"># kubectl exec --it &lt;debug pod&gt; -- curl http://&lt;svc name&gt;/path</span>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>$<span class="w"> </span>kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--it<span class="w"> </span>debug-container<span class="w"> </span>--<span class="w"> </span>curl<span class="w"> </span>http://httpbin-re:8080<span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span>
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>$<span class="w"> </span>kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--it<span class="w"> </span>debug-container<span class="w"> </span>--<span class="w"> </span>curl<span class="w"> </span>http://httpbin-re.default:8080<span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span>
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>$<span class="w"> </span>kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--it<span class="w"> </span>debug-container<span class="w"> </span>--<span class="w"> </span>curl<span class="w"> </span>http://httpbin-re.default.svc:8080<span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span>
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>&lt;!DOCTYPE<span class="w"> </span>html&gt;
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>&lt;html<span class="w"> </span><span class="nv">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span>&gt;
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>...omit...
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a><span class="c1"># 測試可以跟 metrics-server 連線，不同 namespace，不同 Pod</span>
<a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a><span class="c1"># kubectl exec --it &lt;debug pod&gt; -- curl --insecure https://&lt;svc name&gt;.&lt;namespace&gt;:&lt;svc port&gt;/path</span>
<a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>$<span class="w"> </span>kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--it<span class="w"> </span>debug-container<span class="w"> </span>--<span class="w"> </span>curl<span class="w"> </span>--insecure<span class="w"> </span>https://metrics-server.kube-system:443/metrics<span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span>
<a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a>$<span class="w"> </span>kubectl<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--it<span class="w"> </span>debug-container<span class="w"> </span>--<span class="w"> </span>curl<span class="w"> </span>--insecure<span class="w"> </span>https://metrics-server.kube-system.svc:443/metrics<span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span>
<a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a><span class="o">{</span>
<a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a><span class="w">  </span><span class="s2">&quot;kind&quot;</span>:<span class="w"> </span><span class="s2">&quot;Status&quot;</span>,
<a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a><span class="w">  </span><span class="s2">&quot;apiVersion&quot;</span>:<span class="w"> </span><span class="s2">&quot;v1&quot;</span>,
<a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a><span class="w">  </span><span class="s2">&quot;metadata&quot;</span>:<span class="w"> </span><span class="o">{}</span>,
<a id="__codelineno-13-22" name="__codelineno-13-22" href="#__codelineno-13-22"></a><span class="w">  </span><span class="s2">&quot;status&quot;</span>:<span class="w"> </span><span class="s2">&quot;Failure&quot;</span>,
<a id="__codelineno-13-23" name="__codelineno-13-23" href="#__codelineno-13-23"></a><span class="w">  </span><span class="s2">&quot;message&quot;</span>:<span class="w"> </span><span class="s2">&quot;forbidden: User \&quot;system:anonymous\&quot; cannot get path \&quot;/metrics\&quot;&quot;</span>,
<a id="__codelineno-13-24" name="__codelineno-13-24" href="#__codelineno-13-24"></a><span class="w">  </span><span class="s2">&quot;reason&quot;</span>:<span class="w"> </span><span class="s2">&quot;Forbidden&quot;</span>,
<a id="__codelineno-13-25" name="__codelineno-13-25" href="#__codelineno-13-25"></a><span class="w">  </span><span class="s2">&quot;details&quot;</span>:<span class="w"> </span><span class="o">{}</span>,
<a id="__codelineno-13-26" name="__codelineno-13-26" href="#__codelineno-13-26"></a><span class="w">  </span><span class="s2">&quot;code&quot;</span>:<span class="w"> </span><span class="m">403</span>
<a id="__codelineno-13-27" name="__codelineno-13-27" href="#__codelineno-13-27"></a><span class="o">}</span>%
</code></pre></div>
<p>關於這個以 Pod 為出發點，服務之間的連線議題，以前有寫過<a href="https://blog.pichuang.com.tw/20211129-kubernetes-service-troubleshoot.html">為什麼我佈署的 Kubernetes 服務不會動!? 個人除錯思路分享</a> 一文，裡面有比較仔細的說明，這邊就不贅述了</p>
<h4 id="3-httpbin-re-pod"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#3-httpbin-re-pod">3. 遠端抓 httpbin-re Pod 的封包</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="c1"># 列舉出 httpbin-re Pod 的名稱</span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>get<span class="w"> </span>pod<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>-owide
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>NAME<span class="w">                          </span>READY<span class="w">   </span>STATUS<span class="w">    </span>RESTARTS<span class="w">   </span>AGE<span class="w">     </span>IP<span class="w">            </span>NODE<span class="w">                                </span>NOMINATED<span class="w"> </span>NODE<span class="w">   </span>READINESS<span class="w"> </span>GATES
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>debug-container<span class="w">               </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>15m<span class="w">     </span><span class="sb">`</span><span class="m">10</span>.0.129.18<span class="sb">`</span><span class="w">   </span>aks-agentpool-14864487-vmss000000<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>httpbin-re-866499b564-blc95<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>7h38m<span class="w">   </span><span class="m">10</span>.0.129.6<span class="w">    </span>aks-agentpool-14864487-vmss000000<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>httpbin-re-866499b564-xl726<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>7h38m<span class="w">   </span><span class="sb">`</span><span class="m">10</span>.0.129.9<span class="sb">`</span><span class="w">    </span>aks-agentpool-14864487-vmss000000<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>ksniff-grlzn<span class="w">                  </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>82s<span class="w">     </span><span class="m">10</span>.0.129.33<span class="w">   </span>aks-agentpool-14864487-vmss000000<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>ksniff-n9ps6<span class="w">                  </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>36m<span class="w">     </span><span class="m">10</span>.0.129.29<span class="w">   </span>aks-agentpool-14864487-vmss000000<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="c1"># 透過 ksniff 來抓封包</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="c1"># ssh &lt;Target username&gt;@&lt;Target IP&gt; -p &lt;Target Port&gt; -i &lt;SSH Private Key if have&gt; &quot;/bin/bash --login -c &#39;kubectl sniff -n &lt;namespace&gt; &lt;pod name&gt; -p -o -&#39;&quot; | /mnt/c/Program\ Files/Wireshark/Wireshark.exe -k -i -</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>ssh<span class="w"> </span>pichuang@localhost.divecode.in<span class="w"> </span>-p<span class="w"> </span><span class="m">5566</span><span class="w"> </span>-i<span class="w"> </span>~/.ssh/wolala-rsa<span class="w"> </span><span class="s2">&quot;/bin/bash --login -c &#39;kubectl sniff -n default httpbin-re-866499b564-xl726 -p -o -&#39;&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>/mnt/c/Program<span class="se">\ </span>Files/Wireshark/Wireshark.exe<span class="w"> </span>-k<span class="w"> </span>-i<span class="w"> </span>-
</code></pre></div>
<p>這邊要注意的是 <code>/bin/bash --login -c</code>，因為 SSH 登入的時候吃的 $PATH 預設是不會去吃 ~/.bashrc，可以用 <code>env</code> 驗證看看，所以需要先用 <code>--login</code> 後才能正確咬到 $PATH 裡面的 krew 路徑，其餘就是 pipeline 和 I/O 的串流處理了</p>
<p><img alt="" src="/images/w8.png" /></p>
<p>此外，原先應該要填 Ethernet Header (12 bytes) 的欄位，會變成 <code>Linux cooked capture v2 (SLL_v2)</code>，按照 <a href="https://wiki.wireshark.org/SLL.md">Linux cooked-mode capture (SLL)</a> 的說明，這是一個偽造協議，對分析 Kubernetes 上的服務比較沒什麼影響，因為主要都是看 L3 / L4 層級居多，包含 Pod IP / Pod Port / Service IP / Service Port / Node Port 等，同場加映一下，<a href="https://www.hwchiu.com/docs/2021/k8s-tcpdump">
HWCHIU 學習筆記 - Kubernetes 之封包去哪兒</a></p>
<h4 id="4-ksniff-pod"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#4-ksniff-pod">4. 清除 ksniff Pod</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>get<span class="w"> </span>pod<span class="w"> </span>-l<span class="w"> </span><span class="nv">app</span><span class="o">=</span>ksniff<span class="w"> </span>-A
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>NAME<span class="w">           </span>READY<span class="w">   </span>STATUS<span class="w">    </span>RESTARTS<span class="w">   </span>AGE
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>ksniff-g4bjz<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>11m
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>ksniff-j7gnc<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>16m
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>ksniff-kxfl5<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>9m54s
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>ksniff-lb4xg<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>6m29s
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>ksniff-n9ps6<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>68m
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>ksniff-sph6l<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>9m17s
<a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a>ksniff-v2vd5<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>14m
<a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a>ksniff-vl627<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>16m
<a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a>
<a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a>$<span class="w"> </span>kubectl<span class="w"> </span>delete<span class="w"> </span>pod<span class="w"> </span>-l<span class="w"> </span><span class="nv">app</span><span class="o">=</span>ksniff<span class="w"> </span>-A
<a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-g4bjz&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-j7gnc&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-kxfl5&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-lb4xg&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-n9ps6&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-sph6l&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-v2vd5&quot;</span><span class="w"> </span>deleted
<a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a>pod<span class="w"> </span><span class="s2">&quot;ksniff-vl627&quot;</span><span class="w"> </span>deleted
</code></pre></div>
<p>退出的時候看起來是不會順便把 ksniff 的 Pod 移除掉，記得要手動移除，不然會有資源浪費的問題</p>
<h3 id="_2"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#_2">後話</a></h3>
<p>ksniff 沒有參數可以讓我去掐封包大小，沒意外的話，還需要再跳板機多一段 tcpdump pipeline 處理，但這樣就會收到一堆有的沒的封包，還沒想到怎麼用</p>
<h3 id="qa"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#qa">Q&amp;A</a></h3>
<h4 id="q1-red-hat-openshift-container-platform-azure-red-hat-openshift"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#q1-red-hat-openshift-container-platform-azure-red-hat-openshift">Q1: 如果我是 Red Hat OpenShift Container Platform 或 Azure Red Hat OpenShift 的使用者，但權限鎖超嚴的怎麼辦?</a></h4>
<p>這個只能說 Red Hat 一如既往地已經先幫妳整好到 oc 去了，你不用特別裝 ksniff，權限就是照你拿到的 kubeconfig 為主</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>$ oc version
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>Client Version: 4.12.36
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>Kustomize Version: v4.5.7
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>Kubernetes Version: v1.27.3
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>$ oc sniff
<a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>Usage:
<a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a>  sniff pod [-n namespace] [-c container] [-f filter] [-o output-file] [-l local-tcpdump-path] [-r remote-tcpdump-path] [flags]
<a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a>
<a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a>Examples:
<a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a>kubectl sniff hello-minikube-7c77b68cff-qbvsd -c hello-minikube
<a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a>
<a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a>Flags:
<a id="__codelineno-17-14" name="__codelineno-17-14" href="#__codelineno-17-14"></a>  -c, --container string                container (optional)
<a id="__codelineno-17-15" name="__codelineno-17-15" href="#__codelineno-17-15"></a>  -x, --context string                  kubectl context to work on (optional)
<a id="__codelineno-17-16" name="__codelineno-17-16" href="#__codelineno-17-16"></a>  -f, --filter string                   tcpdump filter (optional)
<a id="__codelineno-17-17" name="__codelineno-17-17" href="#__codelineno-17-17"></a>  -h, --help                            help for sniff
<a id="__codelineno-17-18" name="__codelineno-17-18" href="#__codelineno-17-18"></a>      --image string                    the privileged container image (optional)
<a id="__codelineno-17-19" name="__codelineno-17-19" href="#__codelineno-17-19"></a>  -i, --interface string                pod interface to packet capture (optional) (default &quot;any&quot;)
<a id="__codelineno-17-20" name="__codelineno-17-20" href="#__codelineno-17-20"></a>  -l, --local-tcpdump-path string       local static tcpdump binary path (optional)
<a id="__codelineno-17-21" name="__codelineno-17-21" href="#__codelineno-17-21"></a>  -n, --namespace string                namespace (optional)
<a id="__codelineno-17-22" name="__codelineno-17-22" href="#__codelineno-17-22"></a>  -o, --output-file string              output file path, tcpdump output will be redirect to this file instead of wireshark (optional) (&#39;-&#39; stdout)
<a id="__codelineno-17-23" name="__codelineno-17-23" href="#__codelineno-17-23"></a>      --pod-creation-timeout duration   the length of time to wait for privileged pod to be created (e.g. 20s, 2m, 1h). A value of zero means the creation never times out. (default 1m0s)
<a id="__codelineno-17-24" name="__codelineno-17-24" href="#__codelineno-17-24"></a>  -p, --privileged                      if specified, ksniff will deploy another pod that have privileges to attach target pod network namespace
<a id="__codelineno-17-25" name="__codelineno-17-25" href="#__codelineno-17-25"></a>  -r, --remote-tcpdump-path string      remote static tcpdump binary path (optional) (default &quot;/tmp/static-tcpdump&quot;)
<a id="__codelineno-17-26" name="__codelineno-17-26" href="#__codelineno-17-26"></a>      --socket string                   the container runtime socket path (optional)
<a id="__codelineno-17-27" name="__codelineno-17-27" href="#__codelineno-17-27"></a>      --tcpdump-image string            the tcpdump container image (optional)
<a id="__codelineno-17-28" name="__codelineno-17-28" href="#__codelineno-17-28"></a>  -v, --verbose                         if specified, ksniff output will include debug information (optional)
</code></pre></div>
<h3 id="references"><a class="toclink" href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/#references">References</a></h3>
<ul>
<li><a href="https://blog.pichuang.com.tw/20231012-sustainability-remote-capture-packets.html">永續性軟體工程: 遠端抓封包實錄</a></li>
<li><a href="https://github.com/eldadru/ksniff">eldadru/ksniff</a></li>
<li><a href="https://krew.sigs.k8s.io/docs/user-guide/setup/install/">krew</a></li>
<li><a href="https://blog.pichuang.com.tw/20211129-kubernetes-service-troubleshoot.html">為什麼我佈署的 Kubernetes 服務不會動!? 個人除錯思路分享</a></li>
<li><a href="https://www.hwchiu.com/docs/2021/k8s-tcpdump">Kubernetes 之封包去哪兒</a></li>
<li><a href="https://blog.pichuang.com.tw/20230713-distroless-container-debug.html">當遇到 Distroless Container 除錯要什麼沒什麼該怎麼辦? 你的好朋友 kubectl debug</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2023/10/13/%E4%BA%BA%E5%AE%B6%E9%83%BD%E5%9C%A8%E6%8A%93%E7%A5%9E%E5%A5%87%E5%AF%B6%E8%B2%9D%E8%80%8C%E6%88%91%E5%9C%A8%E6%8A%93-kubernetes-%E5%B0%81%E5%8C%85/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-07-13 00:00:00">July 13, 2023</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="distroless-container-kubectl-debug"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/">當遇到 Distroless Container 除錯要什麼沒什麼該怎麼辦? 你的好朋友 kubectl debug</a></h2>
<p>這篇只有 Red Hat OpenShift 為主的使用者不用看，那個早在 v3.6 好幾年前就弄了一個 <code>oc debug</code> 出來了，但你若是一般 Kubernetes 發行版的，例如 Tanzu Kubernetes Grid 或 Azure Kubernetes Service 等，則可以參考一下此篇作法。主要是會用到 <a href="https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/">Ephemeral Containers</a> 和 <a href="https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/#ephemeral-container">kubectl debug</a> 這兩個主要能力，而目前都是在 Kubernetes v1.25 標註 Stable 穩定狀態</p>
<p><img alt="" src="/images/title-kubectl-debug.png" /></p>
<!--more-->

<h3 id="_1"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#_1">典型狀況</a></h3>
<p>有時候你會遇到一個 Container Images 是採 Distroless 的方式運行，特性是除了程式本身以外，什麼 Shell 都沒有，無法登入進去，或者是你進得去看起來有問題的 Pod 想要進行一些除錯的動作，但剛好沒有裝任何工具可以使用，這時候該怎麼辦呢? 其實你需要要準備一個自己編譯好的 <a href="https://github.com/pichuang/debug-container">debug-container</a> 和學習一下 <code>kubectl debug</code> 的用法</p>
<p>這邊剛好有一個 Azure Kubernetes Service 常見的狀況，就是若想要登入到 CoreDNS Pod 裡面查看 Corefile 的內容，你會發現到它會一直噴 <code>no such file or directory: unknown</code> 之類的錯誤，其實是因為這個 Pod 裡面根本沒有 /bin/bash 或者是 /bin/cat 的指令可以用，可以算是很扎實的 Distroless Container 實務案例</p>
<p><img alt="" src="/images/coredns-error.png" /></p>
<div class="highlight"><span class="filename">before</span><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>--namespace<span class="w"> </span>kube-system<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span>-l<span class="w"> </span>k8s-app<span class="o">=</span>kube-dns
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>NAME<span class="w">                       </span>READY<span class="w">   </span>STATUS<span class="w">    </span>RESTARTS<span class="w">   </span>AGE
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>coredns-6698ddd997-gx66m<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>11s
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>coredns-6698ddd997-rxlsl<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>11s
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-ti<span class="w"> </span>coredns-6698ddd997-gx66m<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>error:<span class="w"> </span>Internal<span class="w"> </span>error<span class="w"> </span>occurred:<span class="w"> </span>error<span class="w"> </span>executing<span class="w"> </span><span class="nb">command</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>container:<span class="w"> </span>failed<span class="w"> </span>to<span class="w"> </span><span class="nb">exec</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>container:<span class="w"> </span>failed<span class="w"> </span>to<span class="w"> </span>start<span class="w"> </span><span class="nb">exec</span><span class="w"> </span><span class="s2">&quot;0f831ab9a9d243bb196e31d6578b19ea13088cdfeec57fb1953c3021a0463d12&quot;</span>:<span class="w"> </span>OCI<span class="w"> </span>runtime<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>failed:<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>failed:<span class="w"> </span>unable<span class="w"> </span>to<span class="w"> </span>start<span class="w"> </span>container<span class="w"> </span>process:<span class="w"> </span>exec:<span class="w"> </span><span class="s2">&quot;/bin/bash&quot;</span>:<span class="w"> </span>stat<span class="w"> </span>/bin/bash:<span class="w"> </span>no<span class="w"> </span>such<span class="w"> </span>file<span class="w"> </span>or<span class="w"> </span>directory:<span class="w"> </span>unknown
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-ti<span class="w"> </span>coredns-6698ddd997-gx66m<span class="w"> </span>--<span class="w"> </span>cat<span class="w"> </span>/etc/coredns/Corefile
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>error:<span class="w"> </span>Internal<span class="w"> </span>error<span class="w"> </span>occurred:<span class="w"> </span>error<span class="w"> </span>executing<span class="w"> </span><span class="nb">command</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>container:<span class="w"> </span>failed<span class="w"> </span>to<span class="w"> </span><span class="nb">exec</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>container:<span class="w"> </span>failed<span class="w"> </span>to<span class="w"> </span>start<span class="w"> </span><span class="nb">exec</span><span class="w"> </span><span class="s2">&quot;7b5e958107188e3b7748a27138774775dbcebcb8c6bd178b357d187bda720bc9&quot;</span>:<span class="w"> </span>OCI<span class="w"> </span>runtime<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>failed:<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>failed:<span class="w"> </span>unable<span class="w"> </span>to<span class="w"> </span>start<span class="w"> </span>container<span class="w"> </span>process:<span class="w"> </span>exec:<span class="w"> </span><span class="s2">&quot;cat&quot;</span>:<span class="w"> </span>executable<span class="w"> </span>file<span class="w"> </span>not<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nv">$PATH</span>:<span class="w"> </span>unknown
</code></pre></div>
<p>下面提供用 <a href="https://github.com/wagoodman/dive">dive</a> 所分析的容器映像檔內容</p>
<p><img alt="" src="/images/dive.png" /></p>
<h3 id="2"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#2">2 個前置準備</a></h3>
<ol>
<li>準備一個具備可用 Shell 跟其他除錯用工具的 Ephemeral Container Image，如我自己編譯的 <a href="https://github.com/pichuang/debug-container">pichuang/debug-container:master</a>，基於 CentOS Stream，每日更新，簡單直覺</li>
<li>使用 <code>kubectl debug</code>，確保你的 kubectl 版本是大於 v1.25，目前這個功能是內建在 kubectl 裡面，不需要額外裝 krew plugin 即可使用</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>version<span class="w"> </span>--short
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>Client<span class="w"> </span>Version:<span class="w"> </span>v1.27.3
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>Kustomize<span class="w"> </span>Version:<span class="w"> </span>v5.0.1
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>Server<span class="w"> </span>Version:<span class="w"> </span>v1.26.3
</code></pre></div>
<h3 id="2_1"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#2_1">2 個解決方式</a></h3>
<ol>
<li>使用 <code>--target</code>: 直接對 Target Container 進行操作，常見如 Pod Running 中沒什麼問題，但剛好它是 distroless images，缺少一堆可執行 bin。這時候若你只是想要做一些基本測試，譬如網路測試等，可以考慮使用 <code>--target</code> 方式把自己準備的 Ephemeral Container 掛進去使用，無須特別修改也無須重開</li>
<li>使用 <code>--copy-to</code>: Copy 一份 Pod 出去另外研究，最常見的使用方式，反舉遇到 Completed 或 CrashLoopBackOff 等無法使用 kubectl exec 方式進入的 Pod 且想要知道到底死在那裡，可以掛一個 Ephemeral Container 修改進入點或命令研究看看</li>
</ol>
<h4 id="1-target"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#1-target">1. 使用 <code>--target</code></a></h4>
<p><img alt="" src="/images/target-debug.png" /></p>
<div class="highlight"><span class="filename">target</span><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c1">#</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="c1"># kubectl -n kube-system debug -it &lt;TARGET POD NAME&gt; --image=&lt;DEBUGGER CONTAINER&gt; --target=&lt;TARGET CONTAINER NAME&gt;</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="c1">#</span>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span>debug<span class="w"> </span>-it<span class="w"> </span>coredns-6698ddd997-gx66m<span class="w"> </span>--image<span class="o">=</span>ghcr.io/pichuang/debug-container:master<span class="w"> </span>--target<span class="o">=</span>coredns
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>Targeting<span class="w"> </span>container<span class="w"> </span><span class="s2">&quot;coredns&quot;</span>.<span class="w"> </span>If<span class="w"> </span>you<span class="w"> </span>dont<span class="w"> </span>see<span class="w"> </span>processes<span class="w"> </span>from<span class="w"> </span>this<span class="w"> </span>container<span class="w"> </span>it<span class="w"> </span>may<span class="w"> </span>be<span class="w"> </span>because<span class="w"> </span>the<span class="w"> </span>container<span class="w"> </span>runtime<span class="w"> </span>doesnt<span class="w"> </span>support<span class="w"> </span>this<span class="w"> </span>feature.
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>Defaulting<span class="w"> </span>debug<span class="w"> </span>container<span class="w"> </span>name<span class="w"> </span>to<span class="w"> </span>debugger-pbsr4.
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>If<span class="w"> </span>you<span class="w"> </span>dont<span class="w"> </span>see<span class="w"> </span>a<span class="w"> </span><span class="nb">command</span><span class="w"> </span>prompt,<span class="w"> </span>try<span class="w"> </span>pressing<span class="w"> </span>enter.
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="o">[</span>root@coredns-6698ddd997-gx66m<span class="w"> </span>/<span class="o">]</span><span class="c1"># ps uax</span>
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>USER<span class="w">         </span>PID<span class="w"> </span>%CPU<span class="w"> </span>%MEM<span class="w">    </span>VSZ<span class="w">   </span>RSS<span class="w"> </span>TTY<span class="w">      </span>STAT<span class="w"> </span>START<span class="w">   </span>TIME<span class="w"> </span>COMMAND
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>root<span class="w">           </span><span class="m">1</span><span class="w">  </span><span class="m">0</span>.1<span class="w">  </span><span class="m">0</span>.2<span class="w"> </span><span class="m">762456</span><span class="w"> </span><span class="m">46012</span><span class="w"> </span>?<span class="w">        </span>Ssl<span class="w">  </span><span class="m">07</span>:24<span class="w">   </span><span class="m">0</span>:01<span class="w"> </span>/coredns<span class="w"> </span>-conf<span class="w"> </span>/etc/coredns/Corefile
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>root<span class="w">          </span><span class="m">63</span><span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">12060</span><span class="w">  </span><span class="m">3284</span><span class="w"> </span>pts/0<span class="w">    </span>Ss<span class="w">   </span><span class="m">07</span>:33<span class="w">   </span><span class="m">0</span>:00<span class="w"> </span>/bin/bash<span class="w"> </span>-l
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>root<span class="w">          </span><span class="m">88</span><span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">44708</span><span class="w">  </span><span class="m">3380</span><span class="w"> </span>pts/0<span class="w">    </span>R+<span class="w">   </span><span class="m">07</span>:35<span class="w">   </span><span class="m">0</span>:00<span class="w"> </span>ps<span class="w"> </span>uax
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a><span class="o">[</span>root@coredns-6698ddd997-gx66m<span class="w"> </span>/<span class="o">]</span><span class="c1"># cat /proc/1/root/etc/coredns/Corefile | head -n5</span>
<a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>.:53<span class="w"> </span><span class="o">{</span>
<a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a><span class="w">    </span>errors
<a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a><span class="w">    </span>ready
<a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a><span class="w">    </span>health<span class="w"> </span><span class="o">{</span>
<a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a><span class="w">      </span>lameduck<span class="w"> </span>5s
<a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>
<a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a><span class="c1">#</span>
<a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a><span class="c1"># Qeury ephemeralContainerStatuses</span>
<a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a><span class="c1">#</span>
<a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a><span class="c1"># kubectl -n kube-system get pod coredns-6698ddd997-gx66m -o jsonpath=&#39;{range .status.ephemeralContainerStatuses[*]}{.name}{&quot;\t&quot;}{.ready}{&quot;\n&quot;}{end}&#39;</span>
</code></pre></div>
<p>如果要查 Ephmeral Container 的狀態，要從 <code>.status.ephemeralContainerStatuses</code> 查詢，可以得知使用的 image 是什麼，以及是否 Ready 等資訊</p>
<h4 id="2-copy-to"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#2-copy-to">2. 使用 <code>--copy-to</code></a></h4>
<p><img alt="" src="/images/copy-to-debug.png" /></p>
<p>這邊要特別注意的是要把 <code>--share-processes</code> 勾起來，不然預設狀況下 Linux Namespace 是相互隔離的，會看不到原先的 Process</p>
<div class="highlight"><span class="filename">copy-to</span><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="c1">#</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="c1"># kubectl -n kube-system debug -it &lt;TARGET POD NAME&gt; --image=&lt;DEBUGGER CONTAINER&gt; --copy-to=&lt;NEW POD NAME&gt;</span>
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="c1">#</span>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span>debug<span class="w"> </span>-it<span class="w"> </span>coredns-6698ddd997-gx66m<span class="w"> </span>--share-processes<span class="w"> </span>--image<span class="o">=</span>ghcr.io/pichuang/debug-container:master<span class="w"> </span>--copy-to<span class="o">=</span>copy-coredns
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>Defaulting<span class="w"> </span>debug<span class="w"> </span>container<span class="w"> </span>name<span class="w"> </span>to<span class="w"> </span>debugger-lkp2m.
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>If<span class="w"> </span>you<span class="w"> </span>dont<span class="w"> </span>see<span class="w"> </span>a<span class="w"> </span><span class="nb">command</span><span class="w"> </span>prompt,<span class="w"> </span>try<span class="w"> </span>pressing<span class="w"> </span>enter.
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="o">[</span>root@copy-coredns<span class="w"> </span>/<span class="o">]</span><span class="c1"># ps uax</span>
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>USER<span class="w">         </span>PID<span class="w"> </span>%CPU<span class="w"> </span>%MEM<span class="w">    </span>VSZ<span class="w">   </span>RSS<span class="w"> </span>TTY<span class="w">      </span>STAT<span class="w"> </span>START<span class="w">   </span>TIME<span class="w"> </span>COMMAND
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="m">65535</span><span class="w">          </span><span class="m">1</span><span class="w">  </span><span class="m">0</span>.1<span class="w">  </span><span class="m">0</span>.0<span class="w">    </span><span class="m">972</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>?<span class="w">        </span>Ss<span class="w">   </span><span class="m">08</span>:27<span class="w">   </span><span class="m">0</span>:00<span class="w"> </span>/pause
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>root<span class="w">           </span><span class="m">7</span><span class="w">  </span><span class="m">1</span>.0<span class="w">  </span><span class="m">0</span>.2<span class="w"> </span><span class="m">761944</span><span class="w"> </span><span class="m">41720</span><span class="w"> </span>?<span class="w">        </span>Ssl<span class="w">  </span><span class="m">08</span>:27<span class="w">   </span><span class="m">0</span>:00<span class="w"> </span>/coredns<span class="w"> </span>-conf<span class="w"> </span>/etc/coredns/Corefile
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>root<span class="w">          </span><span class="m">21</span><span class="w">  </span><span class="m">0</span>.4<span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">12060</span><span class="w">  </span><span class="m">3328</span><span class="w"> </span>pts/0<span class="w">    </span>Ss<span class="w">   </span><span class="m">08</span>:27<span class="w">   </span><span class="m">0</span>:00<span class="w"> </span>/bin/bash<span class="w"> </span>-l
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>root<span class="w">          </span><span class="m">46</span><span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">0</span>.0<span class="w">  </span><span class="m">47656</span><span class="w">  </span><span class="m">3596</span><span class="w"> </span>pts/0<span class="w">    </span>R+<span class="w">   </span><span class="m">08</span>:27<span class="w">   </span><span class="m">0</span>:00<span class="w"> </span>ps<span class="w"> </span>uax
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a><span class="o">[</span>root@copy-coredns<span class="w"> </span>/<span class="o">]</span><span class="c1"># cat /proc/7/root/etc/coredns/Corefile | head -n5</span>
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>.:53<span class="w"> </span><span class="o">{</span>
<a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a><span class="w">    </span>errors
<a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a><span class="w">    </span>ready
<a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a><span class="w">    </span>health<span class="w"> </span><span class="o">{</span>
<a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a><span class="w">      </span>lameduck<span class="w"> </span>5s
<a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>
<a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a><span class="c1">#</span>
<a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a><span class="c1"># Reattach empeheral container</span>
<a id="__codelineno-13-22" name="__codelineno-13-22" href="#__codelineno-13-22"></a><span class="c1">#</span>
<a id="__codelineno-13-23" name="__codelineno-13-23" href="#__codelineno-13-23"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span>attach<span class="w"> </span>copy-coredns<span class="w"> </span>-c<span class="w"> </span>debugger-lkp2m<span class="w"> </span>-i<span class="w"> </span>-t
<a id="__codelineno-13-24" name="__codelineno-13-24" href="#__codelineno-13-24"></a>If<span class="w"> </span>you<span class="w"> </span>dont<span class="w"> </span>see<span class="w"> </span>a<span class="w"> </span><span class="nb">command</span><span class="w"> </span>prompt,<span class="w"> </span>try<span class="w"> </span>pressing<span class="w"> </span>enter.
<a id="__codelineno-13-25" name="__codelineno-13-25" href="#__codelineno-13-25"></a><span class="o">[</span>root@copy-coredns<span class="w"> </span>/<span class="o">]</span><span class="c1"># cat /proc/7/root/etc/coredns/Corefile | head -n5</span>
<a id="__codelineno-13-26" name="__codelineno-13-26" href="#__codelineno-13-26"></a>
<a id="__codelineno-13-27" name="__codelineno-13-27" href="#__codelineno-13-27"></a><span class="c1">#</span>
<a id="__codelineno-13-28" name="__codelineno-13-28" href="#__codelineno-13-28"></a><span class="c1"># Check copy-coredns status</span>
<a id="__codelineno-13-29" name="__codelineno-13-29" href="#__codelineno-13-29"></a><span class="c1">#</span>
<a id="__codelineno-13-30" name="__codelineno-13-30" href="#__codelineno-13-30"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span>get<span class="w"> </span>pods<span class="w"> </span><span class="p">|</span>grep<span class="w"> </span>coredns
<a id="__codelineno-13-31" name="__codelineno-13-31" href="#__codelineno-13-31"></a>copy-coredns<span class="w">                                </span><span class="m">2</span>/2<span class="w">     </span>Running<span class="w">            </span><span class="m">0</span><span class="w">                 </span>2m29s
<a id="__codelineno-13-32" name="__codelineno-13-32" href="#__codelineno-13-32"></a>coredns-6698ddd997-gx66m<span class="w">                    </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">            </span><span class="m">0</span><span class="w">                 </span>65m
<a id="__codelineno-13-33" name="__codelineno-13-33" href="#__codelineno-13-33"></a>coredns-6698ddd997-rxlsl<span class="w">                    </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">            </span><span class="m">0</span><span class="w">                 </span>65m
<a id="__codelineno-13-34" name="__codelineno-13-34" href="#__codelineno-13-34"></a>coredns-autoscaler-7dbcd7d9c8-pnqtt<span class="w">         </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">            </span><span class="m">0</span><span class="w">                 </span>17h
<a id="__codelineno-13-35" name="__codelineno-13-35" href="#__codelineno-13-35"></a>
<a id="__codelineno-13-36" name="__codelineno-13-36" href="#__codelineno-13-36"></a><span class="c1">#</span>
<a id="__codelineno-13-37" name="__codelineno-13-37" href="#__codelineno-13-37"></a><span class="c1"># Wipe out copy-coredns</span>
<a id="__codelineno-13-38" name="__codelineno-13-38" href="#__codelineno-13-38"></a><span class="c1">#</span>
<a id="__codelineno-13-39" name="__codelineno-13-39" href="#__codelineno-13-39"></a>repairman@vm-hub:~$<span class="w"> </span>kubectl<span class="w"> </span>-n<span class="w"> </span>kube-system<span class="w"> </span>delete<span class="w"> </span>pod<span class="w"> </span>copy-coredns
<a id="__codelineno-13-40" name="__codelineno-13-40" href="#__codelineno-13-40"></a>pod<span class="w"> </span><span class="s2">&quot;copy-coredns&quot;</span><span class="w"> </span>deleted
</code></pre></div>
<h3 id="microsoft-defender-for-cloud"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#microsoft-defender-for-cloud">[插花] Microsoft Defender for Cloud</a></h3>
<p>就在我對 Azure Kubernetes Service 內的 CoreDNS 上下其手的時候...我被寄了封 <code>Security Alert: CoreDNS modification in Kubernetes detected</code>，真...貼心的提醒</p>
<div class="highlight"><span class="filename">Security Alert: CoreDNS modification in Kubernetes detected</span><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>Kubernetes audit log analysis detected a modification of the CoreDNS configuration. The configuration of CoreDNS can be modified by overriding its configmap. While this activity can be legitimate, if attackers have permissions to modify the configmap, they can change the behavior of the cluster&#39;s DNS server and poison it.
</code></pre></div>
<p><img alt="" src="/images/coredns-security-alert.png" /></p>
<h3 id="refereneces"><a class="toclink" href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/#refereneces">Refereneces</a></h3>
<ul>
<li><a href="https://mcr.microsoft.com/en-us/product/cbl-mariner/distroless/base/about">CBL-Mariner Distroless Base</a></li>
<li><a href="https://github.com/pichuang/debug-container">pichuang/debug-container</a></li>
<li><a href="https://xie.infoq.cn/article/4372ef0ba18c49891b295de54">K8S 故障排错新手段：kubectl debug 实战</a></li>
<li><a href="https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/">Ephemeral Containers</a></li>
<li><a href="https://kubernetes.io/docs/tasks/debug/debug-application/debug-running-pod/#ephemeral-container">Debugging with an ephemeral debug container</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2023/07/13/%E7%95%B6%E9%81%87%E5%88%B0-distroless-container-%E9%99%A4%E9%8C%AF%E8%A6%81%E4%BB%80%E9%BA%BC%E6%B2%92%E4%BB%80%E9%BA%BC%E8%A9%B2%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BD%A0%E7%9A%84%E5%A5%BD%E6%9C%8B%E5%8F%8B-kubectl-debug/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-05-29 00:00:00">May 29, 2023</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="kubernetes-probe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/">Kubernetes Probe 類型及實作方式的使用說明與小建議</a></h2>
<p>最近看到一個很有趣的網站 <a href="https://kube-score.com/">kube-score</a>，你把你的 Kubernetes Deployment 丟進去之後，它就會各種無情地跟你說哪裡不好。當中裡面有提到針對 Kubernetes Probe 相關的建議，剛好最近案子有需要特別精算時間，故特別寫了篇文章供大家參考。順便附上一張，從 Bing Creator 提供的 DALL.E 模型所理解到的 Kubernetes livenessProbe、readinessProbe 以及 startupProbe 視覺化的樣子，很像...左納烏能源結晶</p>
<p><img alt="" src="/images/probe-k8s-bg.jpg" /></p>
<!--more-->

<h3 id="tldr"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#tldr">TL;DR</a></h3>
<ul>
<li>Kubernetse Probe 類型重要性排序: readinessProbe &gt; livenessProbe &gt; startupProbe</li>
<li>呈上，每一個 Kubernetes Probe 都有各自的 initialDelaySeconds、periodSeconds、successThreshold、failureThreshold、timeoutSeconds 以及 Probe 實作方法可以設定，並不重複</li>
<li>Probe 常見實作方法排序: HTTP Probe &gt; Exec Probe &gt; TCP Socket Probe</li>
</ul>
<h3 id="cloud-native-taiwan-user-group"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#cloud-native-taiwan-user-group">關於 Cloud Native Taiwan User Group</a></h3>
<p>基於 CNCF 治理規範，前陣子將社團拆分成兩個，分別是 <a href="https://community.cncf.io/cloud-native-taiwan-user-group/">Cloud Native Taiwan User Group</a> 和 <a href="">Kubernetes Community Days Taiwan</a></p>
<p>歡迎大家動動手加入一下 CNCF 社群會員，並且點擊加入 (Join)</p>
<p><img alt="" src="/images/cntug-membership.png" /></p>
<p>另外我們 2023/06 有社群活動 <a href="https://community.cncf.io/events/details/cncf-cloud-native-taiwan-user-group-presents-cntug-202306-meetup/">CNTUG 2023/06 Meetup</a>，需透過該系統報名，統計人數，歡迎大家參加</p>
<p>Cloud Native Taiwan User Group 2023/06</p>
<ul>
<li>Kubernetes 伸縮自如的工作負載! -  Phil Huang</li>
<li>Topic Scalable NATS architecture with JetStream - 何秉賢</li>
</ul>
<h3 id="kubernetes-3-probe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#kubernetes-3-probe">Kubernetes 能設定的 3 種 Probe 類型</a></h3>
<p>基於 Kubernetes 官方文件指出</p>
<table>
<thead>
<tr>
<th>Probe</th>
<th>功能描述</th>
<th>用途</th>
<th>使用場景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Liveness Probe (存活探針)</td>
<td>用於檢測 Pod 是否在運行狀態下</td>
<td>確保應用程序在容器內部運行，如果檢測失敗，Kubernetes 將會終止容器並重新啟動它</td>
<td>這可用於檢測應用程序的異常狀態（例如，當應用程序死掉或處於不正常狀態時），類似於電腦啟動後從外部監控 BMC 確認機器運作正常</td>
</tr>
<tr>
<td>Readiness Probe (就緒探針)</td>
<td>用於檢測 Application 是否準備好接受網路流量</td>
<td>當容器內的應用程序正在啟動或正在進行一些初始化工作時，可以使用 Readiness Probe。當應用程序就緒時，它將返回成功的應答，並且 Kubernetes 可以開始將流量路由到該容器。</td>
<td>持續性服務健康檢查，類似於作業系統運行正常</td>
</tr>
<tr>
<td>Startup Probe (啟動探針)</td>
<td>用於檢測 Pod 的啟動進度</td>
<td>Startup Probe 類似於 Readiness Probe，它用於檢測容器是否正在進行啟動過程。與 Readiness Probe 不同，Startup Probe 可以在應用程序就緒之前執行多次檢測。</td>
<td>App 初始化，類似於電腦啟動的時候會有 BIOS 檢查程序</td>
</tr>
</tbody>
</table>
<p>Liveness Probe
<img alt="" src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/google-kubernetes-probe-livenessae14.GIF" /></p>
<p>Readiness Probe
<img alt="" src="https://storage.googleapis.com/gweb-cloudblog-publish/original_images/google-kubernetes-probe-readiness6ktf.GIF" /></p>
<h3 id="probe-3"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#probe-3">每一個 Probe 可以用下列 3 種實作方式進行檢查</a></h3>
<h4 id="http-probe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#http-probe">HTTP Probe</a></h4>
<p>最大宗的檢查方式，如果 Kubernetes 收到 HTTP Status Code 200 ~ 300 的範圍，則會標註為 Health，反之則會標註為 Unhealth</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>apiVersion: v1
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>kind: Pod
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>metadata:
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>  labels:
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>    test: http-probe
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>  name: http-probe
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>spec:
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>  containers:
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>  - name: http-probe
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>    image: k8s.gcr.io/liveness
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>    args:
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>    - /server
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>    livenessProbe:
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>      httpGet:
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>        path: /healthz
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>        port: 8080
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>        httpHeaders:
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>        - name: X-Custom-Header
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>          value: Awesome
<a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>      initialDelaySeconds: 3
<a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>      periodSeconds: 10
<a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>
<a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a>    readinessProbe:
<a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a>      httpGet:
<a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a>        path: /healthz
<a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a>        port: 8080
<a id="__codelineno-8-27" name="__codelineno-8-27" href="#__codelineno-8-27"></a>        httpHeaders:
<a id="__codelineno-8-28" name="__codelineno-8-28" href="#__codelineno-8-28"></a>        - name: X-Custom-Header
<a id="__codelineno-8-29" name="__codelineno-8-29" href="#__codelineno-8-29"></a>          value: Awesome
<a id="__codelineno-8-30" name="__codelineno-8-30" href="#__codelineno-8-30"></a>      initialDelaySeconds: 3
<a id="__codelineno-8-31" name="__codelineno-8-31" href="#__codelineno-8-31"></a>      periodSeconds: 10
</code></pre></div>
<p>其實很多 Framework 或 Library 內建都有針對這個需求進行實作，可以直接使用</p>
<ul>
<li>Spring Boot: <a href="https://spring.io/blog/2020/03/25/liveness-and-readiness-probes-with-spring-boot">Liveness and Readiness Probes with Spring Boot</a></li>
<li>.NET Core: <a href="https://learn.microsoft.com/en-us/aspnet/core/host-and-deploy/health-checks">Health checks in ASP.NET Core</a></li>
<li>Python3: <a href="https://pypi.org/project/flask-healthz/">flask-healthz</a></li>
</ul>
<h4 id="exec-probe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#exec-probe">Exec Probe</a></h4>
<p>如果 Kubernetes 收到 Exit Code 為 0，則會標註為 Health，反之則會標註為 Unhealth</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>apiVersion: v1
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>kind: Pod
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>metadata:
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>  labels:
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>    test: exec-probe
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>  name: exec-probe
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>spec:
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>  containers:
<a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>  - name: exec-probe
<a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>    image: k8s.gcr.io/busybox
<a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>    args:
<a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>    - /bin/sh
<a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>    - -c
<a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
<a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>    livenessProbe:
<a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a>      exec:
<a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a>        command:
<a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a>        - cat
<a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>        - /tmp/healthy
<a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>      initialDelaySeconds: 5
<a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>      periodSeconds: 10
<a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>    readinessProbe:
<a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>      exec:
<a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>        command:
<a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a>        - cat
<a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a>        - /tmp/healthy
<a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a>      initialDelaySeconds: 5
<a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a>      periodSeconds: 10
</code></pre></div>
<h4 id="tcp-socket-probe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#tcp-socket-probe">TCP Socket Probe</a></h4>
<p>如果 Kubernetes 能建立 TCP Establish connection，則會標註為 Health，反之則會標註為 Unhealth</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>apiVersion: v1
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>kind: Pod
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>metadata:
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>  name: goproxy
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>  labels:
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>    app: goproxy
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>spec:
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>  containers:
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>  - name: goproxy
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>    image: k8s.gcr.io/goproxy:0.1
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>    ports:
<a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a>    - containerPort: 8080
<a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a>    readinessProbe:
<a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a>      tcpSocket:
<a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a>        port: 8080
<a id="__codelineno-10-16" name="__codelineno-10-16" href="#__codelineno-10-16"></a>      initialDelaySeconds: 5
<a id="__codelineno-10-17" name="__codelineno-10-17" href="#__codelineno-10-17"></a>      periodSeconds: 10
<a id="__codelineno-10-18" name="__codelineno-10-18" href="#__codelineno-10-18"></a>
<a id="__codelineno-10-19" name="__codelineno-10-19" href="#__codelineno-10-19"></a>    livenessProbe:
<a id="__codelineno-10-20" name="__codelineno-10-20" href="#__codelineno-10-20"></a>      tcpSocket:
<a id="__codelineno-10-21" name="__codelineno-10-21" href="#__codelineno-10-21"></a>        port: 8080
<a id="__codelineno-10-22" name="__codelineno-10-22" href="#__codelineno-10-22"></a>      initialDelaySeconds: 15
<a id="__codelineno-10-23" name="__codelineno-10-23" href="#__codelineno-10-23"></a>      periodSeconds: 20
</code></pre></div>
<h3 id="use-cases"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#use-cases">Use Cases</a></h3>
<table>
<thead>
<tr>
<th>參數</th>
<th>描述</th>
<th>kubernetes 預設值</th>
<th><a href="https://github.com/nats-io/k8s/blob/main/helm/charts/nats-operator/README.md">NATS-Operator</a></th>
<th><a href="https://github.com/strimzi/strimzi-kafka-operator/blob/main/helm-charts/helm3/strimzi-kafka-operator/README.md">Strimzi Kafka Operator</a></th>
<th><a href="https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/cloud/deploy.yaml#L448-L478">kubernetes/ingress-nginx</a></th>
<th><a href="https://github.com/mysql/mysql-operator/blob/trunk/helm/mysql-operator/templates/deployment.yaml#LL60C1-L66C29">mysql/mysql-operator</a></th>
<th><a href="https://github.com/mariadb-operator/mariadb-operator/blob/main/deploy/charts/mariadb-operator/templates/webhook-deployment.yaml#L67-L72">mariadb-operator/mariadb-operator</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>livenessProbe.enabled</code></td>
<td>啟用 Liveness probe</td>
<td>N/A</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>livenessProbe.initialDelaySeconds</code></td>
<td>初始化 Liveness Probe 前的延遲時間</td>
<td>0</td>
<td>30</td>
<td>10</td>
<td>10</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>livenessProbe.periodSeconds</code></td>
<td>多久量測一次</td>
<td>10</td>
<td>10</td>
<td>30</td>
<td>10</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>livenessProbe.timeoutSeconds</code></td>
<td>多久會超時</td>
<td>1</td>
<td>5</td>
<td>N/A</td>
<td>1</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>livenessProbe.failureThreshold</code></td>
<td>成功後被視為失敗的探測的最小連續失敗次數</td>
<td>3</td>
<td>6</td>
<td>N/A</td>
<td>5</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>livenessProbe.successThreshold</code></td>
<td>探測失敗後被視為成功的最少連續成功次數</td>
<td>1</td>
<td>1</td>
<td>N/A</td>
<td>1</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>livenessProbe HealthCheck</td>
<td>Liveness Probe 探針方式</td>
<td>N/A</td>
<td>httpGet</td>
<td>httpGet</td>
<td>httpGet</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>readinessProbe.enabled</code></td>
<td>啟用 Readiness Probe</td>
<td>N/A</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
<td>true</td>
</tr>
<tr>
<td><code>readinessProbe.initialDelaySeconds</code></td>
<td>初始化 Readiness Probe 前的延遲時間</td>
<td>0</td>
<td>5</td>
<td>10</td>
<td>10</td>
<td>1</td>
<td>5</td>
</tr>
<tr>
<td><code>readinessProbe.periodSeconds</code></td>
<td>多久量測一次</td>
<td>10</td>
<td>10</td>
<td>30</td>
<td>10</td>
<td>3</td>
<td>10</td>
</tr>
<tr>
<td><code>readinessProbe.timeoutSeconds</code></td>
<td>多久會超時</td>
<td>1</td>
<td>5</td>
<td>N/A</td>
<td>1</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>readinessProbe.failureThreshold</code></td>
<td>成功後被視為失敗的探測的最小連續失敗次數</td>
<td>3</td>
<td>6</td>
<td>N/A</td>
<td>3</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td><code>readinessProbe.successThreshold</code></td>
<td>探測失敗後被視為成功的最少連續成功次數</td>
<td>1</td>
<td>1</td>
<td>N/A</td>
<td>1</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>readinessProbe HealthCheck</td>
<td>Readiness Probe 探針方式</td>
<td>N/A</td>
<td>httpGet</td>
<td>httpGet</td>
<td>httpGet</td>
<td>exec</td>
<td>httpGet</td>
</tr>
</tbody>
</table>
<h4 id="nats-operator"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#nats-operator">以 <a href="https://github.com/nats-io/k8s/blob/main/helm/charts/nats-operator/README.md">NATS-Operator</a> 為例</a></h4>
<p>基於 <a href="https://github.com/nats-io/k8s/blob/main/helm/charts/nats-operator/templates/deployment.yaml#L67-L87">NATS-Operator Deployment</a> 和 <a href="https://github.com/nats-io/k8s/blob/main/helm/charts/nats-operator/README.md">NATS-Operator</a> 預設值，這邊因畫圖解釋方便，有調整了一下參數。故可得以下截取設定</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>        livenessProbe:
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>          httpGet:
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>            path: /readyz
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>            port: readyz
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>          initialDelaySeconds: 30
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>          periodSeconds: 10
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>          timeoutSeconds: 5
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>          successThreshold: 6
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>          failureThreshold: 3
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>        readinessProbe:
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>          httpGet:
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>            path: /readyz
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>            port: readyz
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>          initialDelaySeconds: 5
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>          periodSeconds: 10
<a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>          timeoutSeconds: 5
<a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>          successThreshold: 6
<a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>          failureThreshold: 2
</code></pre></div>
<h4 id="q1-kubernetes-pod-pod-restarted-unhealthy"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#q1-kubernetes-pod-pod-restarted-unhealthy">Q1: 如果程式運行一段時間，然後 Kubernetes 發現 Pod 要 Pod Restarted 或者是標註 Unhealthy 最短時間為何?</a></h4>
<p><img alt="" src="/images/probe-k8s-1.png" /></p>
<p>首先因為程式已經運行一段時間了，所以可以省略 initialDelaySeconds 的時間</p>
<p>故正確的算式為</p>
<ul>
<li>最短重啟 Pod 時間 = (<code>livenessProbe.failureThreshold</code> - 1) * <code>livenessProbe.periodSeconds</code> + <code>livenessProbe.timeoutSeconds</code> =  ( 3 - 1 ) * 10 + 5 = 25</li>
<li>最短移除 Endpoint List 時間 = (<code>readinessProbe.failureThreshold</code> - 1) * <code>readinessProbe.periodSeconds</code> + <code>readinessProbe.timeoutSeconds</code> =  ( 2 - 1 ) * 10 + 5 = 15</li>
</ul>
<h4 id="q2-pod-restart"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#q2-pod-restart">Q2: 如果程式初始運行，然後因為程式裡面沒寫好，導致 Pod Restart 開始執行的最短和最長時間為何?</a></h4>
<p>需要把 <code>livenessProbe.initialDelaySeconds</code> 時間放進去評估</p>
<ul>
<li>最短重啟 Pod 時間 = <code>livenessProbe.initialDelaySeconds</code> + (<code>livenessProbe.failureThreshold</code> - 1) * <code>livenessProbe.periodSeconds</code> + <code>livenessProbe.timeoutSeconds</code> =  30 + ( 3 - 1 ) * 10 + 5 = 55</li>
<li>最長重啟 Pod 時間 = <code>livenessProbe.initialDelaySeconds</code> + <code>livenessProbe.failureThreshold</code> * <code>livenessProbe.periodSeconds</code> + <code>livenessProbe.timeoutSeconds</code> =  30 + 3 * 10 + 5 = 65</li>
</ul>
<p>兩者時間差其實就是差一個 livenessProbe.periodSeconds 時間</p>
<h4 id="q3-pod-endpoint-list-endponit-list-kubernetes"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#q3-pod-endpoint-list-endponit-list-kubernetes">Q3: 如果 Pod 從 Endpoint list 移除了一段時間後，當程式正確運行時，最短需花多少時間可以加回到 Endponit list 加回到 Kubernetes 服務的行列內?</a></h4>
<p><img alt="" src="/images/probe-k8s-2.png" /></p>
<p>主要要看 <code>readinessProbe.successThreshold</code></p>
<ul>
<li>最短恢復服務時間 = <code>readinessProbe.successThreshold</code> * <code>readinessProbe.periodSeconds</code> + <code>readinessProbe.timeoutSeconds</code> = 6 * 10 + 5 = 65</li>
</ul>
<h4 id="q4-readinessprobe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#q4-readinessprobe">Q4: 如果沒設定 readinessProbe 會怎樣嗎?</a></h4>
<p>有可能會在 Pod 還沒啟動的時候，流量就 Kubernetes 判斷可以被推進去，或者是 Pod 正在跑停止程序的時候，流量還是被推進去</p>
<h4 id="q5-livenessprobe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#q5-livenessprobe">Q5: 如果沒設定 livenessProbe 會怎樣嗎?</a></h4>
<p>不會怎樣，如果你不知道要設定什麼，不用特別設定，kubelet 會根據 Pod 的 restartPolicy 進行正確的動作。如果有設定的話，盡量不要跟 readinessProbe 檢查同一個地方</p>
<h4 id="q6-startupprobe"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#q6-startupprobe">Q6: 如果沒設定 startupProbe 會怎樣嗎?</a></h4>
<p>不會怎樣，如果你不知道要設定什麼，不用特別設定，可以用拉長 <code>livenessProbe.initialDelaySeconds</code> 互換，startupProbe 的特性是只要成功一次就會換手給 livenessProbe 或 readinessProbe 進行探測</p>
<p>公式為 <code>livenessProbe.initialDelaySeconds</code> 大約等於 <code>startupProbe.initialDelaySeconds</code> + <code>startupProbe.periodSeconds</code> * <code>startupProbe.failureThreshold</code>，可以盡早再初始階段發現服務啟動不了</p>
<h3 id="_1"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#_1">個人小建議</a></h3>
<ul>
<li>
<p>關於 initialDelaySeconds</p>
<ul>
<li>針對 livenessProbe.initialDelaySeconds 特別有用</li>
<li>採用 P99 的啟動時間為主，主要是因為這個數字類同於開機需要多久時間，基本上都相當固定</li>
<li>多數有用 Framework、JVM 等都會有啟動時間的統計可以參考</li>
<li>如果真的抓不準的話，建議上 startupProbe，而不要用 livenessProbe.initialDelaySeconds</li>
</ul>
</li>
<li>
<p>關於 periodSeconds</p>
<ul>
<li>絕大部分的狀況下 10s 相當足夠</li>
<li>如果設定太短，有可能 Pod 只是暫時性很忙來不及回應，他就被歸類在 Failure 的狀態，如果在整體系統都是很忙的狀況下，會導致螺旋式效能下降，能者過勞</li>
<li>如果設定太長，Pod 真的有事情的時候，要很久才會有反應</li>
</ul>
</li>
<li>
<p>關於 timeoutSeconds</p>
<ul>
<li>最大多數抓 periodSeconds/2 或低於的數字</li>
<li>最小為 1s</li>
</ul>
</li>
<li>
<p>關於 failureThreshold</p>
<ul>
<li>建議 3</li>
<li>設定太高，Pod 真的壞掉的時候，導致真的要重啟或移出的時間拉的太長</li>
<li>設定太短，Pod 可能只是暫時很忙的時候，就會過早的重啟或移出，導致螺旋式效能下降，能者過勞</li>
</ul>
</li>
<li>
<p>關於 successThreshold</p>
<ul>
<li>建議 1</li>
<li>針對 readinessProbe.successThreshold 特別有用，livenessProbe.successThreshold 沒什麼特別效果，因為後者會把 Pod 整個重啟掉，故沒有回來的機會</li>
<li>如果 Pod 與其他服務相關服務多的話，可以數字拉大一點，</li>
</ul>
</li>
<li>
<p>關於 livenessProbe</p>
<ul>
<li>因為涉及到重啟 Pod 的能力，故需要保守的設定該項目</li>
<li>檢查僅需僅查自身即可，不應該涉及檢查外部相依性服務</li>
</ul>
</li>
<li>
<p>關於 readinessProbe</p>
<ul>
<li>因為比較偏向服務的 healthcheck，故可以比較寬鬆一點的設定</li>
</ul>
</li>
</ul>
<h3 id="references"><a class="toclink" href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/#references">References</a></h3>
<ul>
<li><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">配置存活、就绪和启动探针</a></li>
<li><a href="https://cloud.redhat.com/blog/liveness-and-readiness-probes">Liveness and Readiness Probes</a></li>
<li><a href="https://opensource.com/article/18/3/kubernetes-liveness-readiness-probes">Creating Kubernetes liveness and readiness probes</a></li>
<li><a href="https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-setting-up-health-checks-with-readiness-and-liveness-probes">Kubernetes best practices: Setting up health checks with readiness and liveness probes</a></li>
<li><a href="https://blog.pichuang.com.tw/20221005-k8s-gracefulrestart-pod.html?h=term">實現不停機的 Pod 更新方式</a></li>
<li><a href="https://github.com/zegl/kube-score/blob/master/README_PROBES.md">Readiness and Liveness Probes</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2023/05/29/kubernetes-probe-%E9%A1%9E%E5%9E%8B%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AA%AA%E6%98%8E%E8%88%87%E5%B0%8F%E5%BB%BA%E8%AD%B0/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-05-15 00:00:00">May 15, 2023</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="sig-kubernetes-scability"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/">SIG Kubernetes Scability 多維度分析</a></h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/bxY5Q5Eoj0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<p>前陣子剛好 Kubecon EU 2023 剛辦完，相關的影片也釋出到 <a href="https://www.youtube.com/playlist?list=PLj6h78yzYM2PyrvCoOii4rAopBswfz1p7">YouTube - KubeCon + CloudNativeCon Europe 2023</a> 上，共計 314 部，在當災厄林克破壞海拉魯大陸的同時，記得也要不忘持續學習</p>
<!--more-->

<h3 id="kubernetes-communtiy-day-taiwan-2023"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#kubernetes-communtiy-day-taiwan-2023">Kubernetes Communtiy Day Taiwan 2023 剩下一周可以投稿!!!</a></h3>
<p>COSCUP 2023 將至，Cloud Native Taiwan User Group 跟歷年一樣我們也會於 2023/07/29 ~ 2023/07/30 內，舉辦 Kubernetes Communtiy Day Taiwan 2023</p>
<p>目前僅剩一周關閉徵稿，可於  <a href="https://pretalx.coscup.org/coscup-2023/cfp">COSCUP 投稿系統</a> 進行投稿</p>
<ul>
<li>正式投稿開始日期：2023 年 04 月 14 日</li>
<li><code>正式投稿截止日期：2023 年 05 月 22 日</code></li>
<li>通知講者社群軌投稿結果：2023 年 06 月 23 日</li>
</ul>
<p>此外基於 CNCF 社群治理規範，從 KCD Taiwan 將 Communtiy Group 單獨拆分出來，</p>
<ul>
<li>Kubernetes Community Days Taiwan (KCD Taiwan), 基於 <a href="https://github.com/cncf/kubernetes-community-days">Kubernetes Community Days</a> 治理規範，網站為 <a href="https://community.cncf.io/kcd-taiwan/">https://community.cncf.io/kcd-taiwan/</a>，為年度地區活動</li>
<li>Cloud Native Taiwan User Group (CNTUG), 基於 <a href="https://github.com/cncf/communitygroups">CNCF Community groups</a> 治理規範，網站為 <a href="https://community.cncf.io/cloud-native-taiwan-user-group/">https://community.cncf.io/cloud-native-taiwan-user-group/</a>，為例行社群活動</li>
</ul>
<p>歡迎有想要贊助、演講的個人或廠商可以依需求各別討論</p>
<h3 id="kubernetes-scability"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#kubernetes-scability">Kubernetes Scability 多維度分析</a></h3>
<p><img alt="" src="/images/scale-1.png" /></p>
<p>Kubernetes Scalabilty 是一個多維度的問題，不單單只是用節點個數來做為衡量唯一基礎，建議參閱 <a href="https://docs.google.com/presentation/d/1aWjxpY4YJ4KJQUTqaVHdR4sbhwqDiW30EF4_hGCc-gI/edit#slide=id.p3">Kubecon 2018 NA - Kubernetes Scalability: A multi-dimensional analysis</a></p>
<p>這邊提幾個我覺得比較重要的</p>
<ul>
<li><code># Nodes v.s. # Pods/node</code>: Nodes 越多、Pod 於單一 Node 上越少，節點越多、Pod 於單一節點上可以越多。個人建議，通常 <code># Pods/Node</code> 是固定的，能動的都是以 <code># Nodes</code> 居多，所以可以固定 <code># Pods/Node</code> 再換算總數</li>
<li><code># Services v.s. # Endpoints/Service</code>: Service 越多、Endpoints/svc 越少，Service 越少，Endpoint/svc 可以越多。個人建議，<code># Endpoints/Service</code> 這個不要超過 250 或不要超過 <code># Pods/node</code> 的上限</li>
<li><code># Service/ns</code>: Service 越多、Namespace 越少，Service 越少、Namespace 可以越多。個人建議，<code># Service/ns</code> 這個不要超過 5000，會有 Pod Crash 的狀況發生</li>
</ul>
<h3 id="2023-slisslos"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#2023-slisslos">2023 SLIs/SLOs 的變化</a></h3>
<p>當年 2015 的其中一條針對 API 呼叫的定義 "99% of all our API calls return in less than 1 second" 因為這句話看的人有各種不一樣的解讀，所以到了今年 2023 就換成下列 2 個更為實際的 SLI / SLO 定義，詳細可以參考這個 <a href="https://github.com/kubernetes/community/commit/6f1cc290b977b1a1f45c5cb7c15132a152e40b8d">Git Diff</a></p>
<details class="info" open="open">
<summary>SLI</summary>
<p>"Latency of processing mutating API calls for single objects for every (resource, verb) pair, measured as 99th percentile over last 5 minutes"
"針對單一物件處理變更 API 呼叫的延遲，對於每一個（資源、動作）配對，以過去 5 分鐘內的第 99 百分位進行測量。"</p>
</details>
<p>這條主要有排除請求在 Queue 中的等待時間，因為沒有辦法預估 Control Plane 的負載狀況，故不考慮這部分的時間消耗</p>
<details class="info" open="open">
<summary>SLO</summary>
<p>"In default Kubernetes installation, for every (resource, verb) pair, excluding virtual and aggregated resources, 99th perccentile per cluster-day &lt;=1s"
"在預設的 Kubernetes 安裝中，對於每一個（資源、動作）配對，排除虛擬和聚合資源，每個集群每天的第 99 百分位延遲應該小於等於 1 秒。"</p>
</details>
<p>其實還有額外官方承認和正在被討論的 SLIs/SLOs，可參考 <a href="https://github.com/kubernetes/community/blob/master/sig-scalability/slos/slos.md#steady-state-slisslos">Steady state SLIs/SLOs</a></p>
<ol>
<li>API call latency SLIs/SLOs details</li>
<li>API call extension points latency SLIs details</li>
<li>In-cluster dns latency SLIs/SLOs details</li>
<li>DNS programming latency SLIs/SLOs details</li>
<li>In-cluster network latency SLIs/SLOs details</li>
<li>Network programming latency SLIs/SLOs details</li>
<li>Pod startup latency SLI/SLO details</li>
<li>Watch latency SLI details</li>
</ol>
<h3 id="_1"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#_1">可擴展性的已測試範圍</a></h3>
<p><img alt="" src="https://raw.githubusercontent.com/kubernetes/community/master/sig-scalability/configs-and-limits/scalability-envelope.png" /></p>
<p>想要精確地定義可擴展性範圍 (Scalability envelope) 是不可能的，但可以抓到大約且合理的範圍，譬如 <a href="https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md">Kubernetes Scalability thresholds</a> 所列的範圍，裡面將 scope 拆分成 2 個維度: namespace 和 cluster</p>
<p>依我個人理解，一般來說架構師會關心的都是下列這幾個範圍，主要會扯到網路，其他選項要爆掉的機會其實蠻低的，至於各別數字的解讀就因人而異了</p>
<table>
<thead>
<tr>
<th>Quantity</th>
<th>Threshold scope=namespace</th>
<th>Threshold: scope=cluster</th>
</tr>
</thead>
<tbody>
<tr>
<td>#Nodes</td>
<td>n/a</td>
<td>5000</td>
</tr>
<tr>
<td>#Namespaces</td>
<td>n/a</td>
<td>10000</td>
</tr>
<tr>
<td>#Pods</td>
<td>3000</td>
<td>150000</td>
</tr>
<tr>
<td>#Pods per node</td>
<td>min(110, 10*#cores)</td>
<td>min(110, 10*#cores)</td>
</tr>
<tr>
<td>#Services</td>
<td>5000</td>
<td>10000</td>
</tr>
<tr>
<td>#All service endpoints</td>
<td>TBD</td>
<td>TBD</td>
</tr>
<tr>
<td>#Endpoints per service</td>
<td>250</td>
<td>n/a</td>
</tr>
<tr>
<td>#Deployments</td>
<td>2000</td>
<td>TBD</td>
</tr>
</tbody>
</table>
<p>個人經驗上，上面的數字如 Nodes / Pods / Pods per node / Services 都跟要計算出網段要切多少、節點要多少個，可承載多少工作負載量很有關係，所以在規畫的時候務必要相當清楚。</p>
<h3 id="_2"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#_2">實際壓測方式</a></h3>
<p>主要壓測工具會用 <a href="https://github.com/kubernetes/perf-tests/">kubernetes/perf-tests</a> 裡面的工具:</p>
<ul>
<li><a href="https://github.com/kubernetes/perf-tests/tree/master/clusterloader2">ClusterLoader2</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd/kubemark">Kubemark</a></li>
</ul>
<p>而跑完測試則會產生測試報表可以觀察現況</p>
<p><img alt="" src="/images/scale-2.png" /></p>
<p>每次 Kubernetes Release 都要通過 Peformance 100 nodes / 500 nodes / Correctness 5000 nodes，測試內容都是由 <a href="https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/sig-scalability/sig-scalability-periodic-jobs.yaml">kubernetes/sig-scalability/sig-scalability-periodic-jobs.yaml</a> 來定義，而報表可以從 <a href="https://testgrid.k8s.io/sig-scalability-kubemark#Summary">https://testgrid.k8s.io</a> 這邊獲得。今年因為各家預算緊縮，現在送 Kubernetes Code 上去，預設只會跑 Performance 100 Nodes 而已，而大部分的擴展性議題都會出現在規模在超過以後 <a href="https://github.com/kubernetes/community/blob/master/sig-scalability/governance/scalability-regressions-case-studies.md">100 Nodes</a></p>
<h3 id="_3"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#_3">預期改進方向</a></h3>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/cluster-administration/flow-control/">Kubernetes v1.20 beta - API Priority &amp; Faireness</a></li>
<li><a href="https://github.com/kubernetes/enhancements/issues/3157">API Streaming Lists</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/114925">Gracefule shutdown</a></li>
<li>Kube-apiserver improvements</li>
<li>Improvements towards supporting higher throughput</li>
</ul>
<h3 id="qa"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#qa">Q&amp;A</a></h3>
<h4 id="q1-kubernetes-sig-autoscaling"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#q1-kubernetes-sig-autoscaling">Q1: 與 Kubernetes SIG Autoscaling 差異是?</a></h4>
<details class="note" open="open">
<summary>Note</summary>
<p>Not to confuse with SIG Autoscaling!</p>
</details>
<p>SIG Scalabilty 關心 Kubernetes 整體系統的極限，如果你是負責提供 Kubernetes 安裝建置的或需要基於以 OSS Kubernetes 為基礎的自行維護版本，會需要關心 Scalability 議題
SIG Autoscaling 關心 Horizontal Pod Autoscaling / Vertical Pod Autoscaling / Cluster Autoscaling，如果你只是需要 Kubernetes 上面的程式部署，則僅需要關心 Autoscaling 議題</p>
<h4 id="q2-kubernetes-sig-scalability"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#q2-kubernetes-sig-scalability">Q2: Kubernetes SIG Scalability 的主要任務是?</a></h4>
<p>主要頁面於 <a href="https://github.com/kubernetes/community/tree/master/sig-scalability">Scalability SIG (Special Interest Group)</a></p>
<p>5 個主要的工作領域:</p>
<ol>
<li>定義和驅動 (Define &amp; Drive): 定義和驅動可擴展性目標</li>
<li>協調和貢獻 (Coordinate &amp; Contribute): 改進 Performance 更接近目標</li>
<li>監控和量測 (Montior &amp; Measure): 透過監控和量測來確保實際系統行為接近目標</li>
<li>保持和保護 (Preserve &amp; Protect): 確保系統免受可擴展性回歸 (Scalability regressions) 的影響</li>
<li>諮詢和教學 (Consult &amp; Coach): 透過社群協作獲得更多的使用案例和回饋經驗</li>
</ol>
<h4 id="q3-kubernetes"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#q3-kubernetes">Q3: Kubernetes 整體壓力測試最大的點在哪裡?</a></h4>
<p>Control Plane</p>
<h4 id="q4-5000"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#q4-5000">Q4: 測試節點 5000 是不是上限?</a></h4>
<p>不是，講者說主要卡在測試成本太高，此外多數使用者對此沒有什麼特別期待，正常規畫可以以 100 Nodes 為基礎設計就好</p>
<p>關於用 Azure Kubernetes Service 計算 5000 個節點的計算方式，可以參考之前寫的拙作 <a href="https://blog.pichuang.com.tw/20230214-openai-scaling-kubernetes-to-7500-nodes.html#azure-cni">看 OpenAI 使用鈔能力招喚 Kubernetes 7500 台節點!!!</a>，有詳細的計算過程</p>
<h4 id="q5-kubernetes"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#q5-kubernetes">Q5: 如何量測 Kubernetes 整體的效能? 第一步是?</a></h4>
<p>上 Grafana + Prometheus 會是很好的起步，或者是可以從 <a href="https://landscape.cncf.io/card-mode?category=observability-and-analysis">CNCF Observability</a> 挑出適合的工具。
若想要針對 Observability 有更深入的了解，建議可以參加 <a href="https://github.com/cncf/tag-observability">CNCF TAG (Technical Advisory Group) Observability 🔭⚙️</a></p>
<h3 id="references"><a class="toclink" href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/#references">References</a></h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=bxY5Q5Eoj0s">Intro + Deep Dive: Kubernetes SIG Scalability - Wojciech Tyczynski, Google</a></li>
<li><a href="https://www.youtube.com/watch?v=VTFmsD9odZ4">Intro + Deep Dive: SIG Scalability - Marcel Zięba &amp; Wojciech Tyczyński, Google</a></li>
<li><a href="https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md">Kubernetes Scalability thresholds</a></li>
<li><a href="https://github.com/kubernetes/community/tree/master/sig-scalability">Scalability Special Interest Group</a></li>
<li><a href="https://github.com/kubernetes/community/blob/master/sig-scalability/slos/slos.md#steady-state-slisslos">Steady state SLIs/SLOs</a></li>
<li><a href="https://github.com/kubernetes/perf-tests/tree/master/clusterloader2">ClusterLoader2</a></li>
<li><a href="https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/sig-scalability/sig-scalability-periodic-jobs.yaml">kubernetes/sig-scalability/sig-scalability-periodic-jobs.yaml</a></li>
<li><a href="https://testgrid.k8s.io/sig-scalability-kubemark#Summary">testgrid.k8s.io</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLj6h78yzYM2PyrvCoOii4rAopBswfz1p7">YouTube - KubeCon + CloudNativeCon Europe 2023</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2023/05/15/sig-kubernetes-scability-%E5%A4%9A%E7%B6%AD%E5%BA%A6%E5%88%86%E6%9E%90/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2023-02-14 00:00:00">February 14, 2023</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              5 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="openai-kubernetes-7500"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/">看 OpenAI 使用鈔能力招喚 Kubernetes 7500 台節點!!!</a></h2>
<p><img alt="" src="/images/OpenAI_Logo.png" /></p>
<details class="quote" open="open">
<summary>Quote</summary>
<p>從 2018 起，OpenAI 所採用的 Kubernetes 節點數量於 3 年內成長 300%</p>
</details>
<ul>
<li>2017 <a href="https://kubernetes.io/case-studies/openai/">Kubernetes Case Study - OpenAI</a></li>
<li>2018/01/18 OpenAI 發布 <a href="https://openai.com/blog/scaling-kubernetes-to-2500-nodes/">Scaling Kubernetes to 2500 Nodes</a></li>
<li>2021/01/18 OpenAI 發布 <a href="https://openai.com/blog/scaling-kubernetes-to-7500-nodes/">Scaling Kubernetes to 7500 Nodes</a></li>
</ul>
<!--more-->

<h3 id="_1"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#_1">前言</a></h3>
<p>OpenAI 於 2021 年的時候已經來到 7,500 節點數量規模了，更何況現在 2023 年有超快速、更誇張的全球總體使用量，根本是 HPC/AI/ML on Kubernetes 於一身最佳架構典範，如果你對這種超大規模的 Kubernetes 有興趣的話，務必要把上面的文章都看過好幾遍，可以避免踩到地雷，畢竟...那些都是 OpenAI 用鈔能力換來的血淚經驗啊...</p>
<p>雖然沒有特別提及，但就文章裡面描述的內容，應該是用 Azure Kubernetes Service (with Azure CNI) 作為基底，下面會有一個章節專門講 Azure Kubernetes Service 的關鍵資訊，教大家怎麼算 Pod / Node / Subnet 數量大小</p>
<h3 id="tldr-openai-kubernetes-3"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#tldr-openai-kubernetes-3">TL;DR: OpenAI 採用 Kubernetes 主要 3 大效益</a></h3>
<ol>
<li>易搬遷 (Portability): 基於基礎架構即代碼 (Infrastructure as Code, IaC)、Kubernetes 一致的且聲明式 API (Consistent &amp; Declarative API)、容器映像檔不可變動性 (Container Immutable Image) 3 個特性，讓你可以在不同的雲端平台上運行你的雲原生程式</li>
<li>省成本 (Cost Savings): 在不同開發情境的時候，可以容易移動你的資源，例如：在開發階段可以使用本地的 Kubernetes 環境，如 minikube, kind, kubeadm, Docker Desktop 等，而在生產階段則可以使用大規模且受支援的 Kubernetes 環境，如 Azure Kubernetes Service 等，和 Kubernetes Cluster Autoscaler (CA) 自動調整集群大小．透過彈性選擇適當的環境，降低整體成本，提升利用率，獲得更多硬體計算資源</li>
<li>增效率 (Improved Efficiency): 一名開發分散式系統系統的研究員，可以在 2 ~ 3 天內讓他的程式正確的運行，1 ~ 2 週後就可以擴張到好幾百個 GPU 節點，相較於以前則是需要以月為單位的工作時間，保持開發快速迭代的效益</li>
</ol>
<h3 id="openai-2500"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#openai-2500">看 OpenAI 使用鈔能力: 2,500 節點規模</a></h3>
<p>基於 <a href="https://openai.com/blog/scaling-kubernetes-to-2500-nodes/">Scaling Kubernetes to 2500 Nodes</a>，建議可以參考 <a href="https://www.evanlin.com/til-openai-5000/">Evan Lin - Scaling Kubernetes to 2,500 Nodes</a> 的文章整理</p>
<h3 id="openai-7500"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#openai-7500">看 OpenAI 使用鈔能力: 7,500 節點規模</a></h3>
<p>下面由我個人基於 <a href="https://openai.com/blog/scaling-kubernetes-to-7500-nodes/">Scaling Kubernetes to 7500 Nodes</a> 的文章整理了下列可以參考的學習點，另外聲明，這不是用 ChatGPT 幫我整理的</p>
<ul>
<li>
<p>計算相關</p>
<ul>
<li>運行 MPI Jobs: 以 MPI 作為調度基礎，而非大量利用 Kubernetes 內建之 Scheduler</li>
<li>最常見錯誤為 Uncorrectable ECC error</li>
</ul>
</li>
<li>
<p>GPU 相關</p>
<ul>
<li>GPU 間通訊強化: 利用 <a href="https://www.nvidia.com/zh-tw/data-center/nvlink/">NVIDIA NVlink</a> 交叉通訊和 <a href="https://docs.nvidia.com/cuda/gpudirect-rdma/">GPUDirect RDMA</a> 與 NIC 直接通訊使整體系統輸送量極大化</li>
<li>多數 1 個節點放 1 個 Pod: 因 CPU / NUMA / PCI-E / Physical Server / Bandwidth 並非調度資源的主因，調度壓力極低，主要是 GPU 資源</li>
</ul>
</li>
<li>
<p>網路相關</p>
<ul>
<li>簡化網路複雜性: Pod 可以直接透過 SSH 連線到 Pod IP 進行連線，而非 Service Endpoint</li>
<li>Flannel CNI 在大規模上使用會有 Throughput 問題</li>
<li>大量採用 iptables mangle 規則: 對流量方向進行標記，以便進行流量控制，而非採用一條一條路由規則管理</li>
<li>採用 Prometheus 的 iptables-exporter 作為網路流量追蹤基礎</li>
<li>採用 Hub and Spoke 網路架構: 研究人員可以從 Hub 服務訪問到任何 Spoke 的服務，如 AKS 等，但任意 2 個 Spoke 裡的 AKS 服務則因 Azure Virtual Network 原生不具備跨 VNet Transit 能力，則無法互相連接，保持故障隔離原則 (Break Failure Isolation)</li>
<li>採用自建 NAT 服務處理 inbound DNAT 流量</li>
<li>個別 Pod 網路流量加總起來相當驚人</li>
</ul>
</li>
<li>
<p>儲存相關</p>
<ul>
<li>採用 Azure Blob Storage 作為主要儲存系統: 因為 Azure Blob Storage 易於擴展，且不需要 slow detach/attach 的額外操作</li>
</ul>
</li>
<li>
<p>Kubernetes 相關</p>
<ul>
<li>無進行過 etcd self-healing automation，最大的集群單獨運行 5 個 API Server 和 5 個 etcd 節點</li>
<li>節點數量多，導致 API Server 記憶體吃重: 基於 7500 台節點集群，每個 API Servers 需要 70GB 的記憶體</li>
<li>API Server 壓力最大來源是 Endpoints 上的 WATCH</li>
<li>Cluster Autoscaler 情境減少，因為集群已經很大了</li>
<li>針對團隊資源分配實做 team-resource-manager</li>
<li>採用 CPU &amp; GPU Balloons 讓 Cluster Autoscaler 不會認為節點閒置而進行移除，避免產生不必要的調度壓力</li>
<li>採用 <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity">Pod Anti-affinity</a> 確保 Pod 最終會被平均地分佈到各個節點上</li>
<li>採用 <a href="https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/pkg/coscheduling/README.md">Coscheduling</a> 批次處理，避免 all or nothing 的情況</li>
</ul>
</li>
<li>
<p>Monitoring 相關</p>
<ul>
<li>採用 Promeheus 和 Grafana 作為監控系統</li>
<li>採用 <a href="https://github.com/coreos/kube-prometheus">kube-prometheus</a>: 對於 HTTP 429 (Too Many Requests) 和 5XX (Server Error) 發送警報相當有效果</li>
<li>採用 <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config">Prometheus relabel</a> 功能，避免收集到不必要的 Metrics，降低壓力</li>
<li>採用 GOMAXPROCS=24 減緩 WAL (Write-Ahead Log) 重新執行次數</li>
<li>採用 <a href="https://github.com/NVIDIA/gpu-monitoring-tools#dcgm-exporter">dcgm-exporter</a>，設定 DCGM_FI_DEV_XID_ERRORS，抓取 XID Errors，並發送警報</li>
<li>採用 <a href="https://docs.nvidia.com/deploy/nvml-api/group__nvmlDeviceQueries.html#group__nvmlDeviceQueries">NVMLDevice Query API</a>: 提供有關 GPU 的健康情況和操作的更詳細信息</li>
<li>並非所有 GPU 錯誤都可以從 DCGM 看到 Error Code</li>
<li>Promtheus 自帶的 TSDB (Time Series Database) 並非最佳選擇，速度很慢，重啟需要很長時間重新執行 WAL</li>
</ul>
</li>
</ul>
<h3 id="_2"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#_2">個人觀點</a></h3>
<ol>
<li>毫無疑問 Kubernetes 架構設計的確適合做為大規模計算需求的基礎平台</li>
<li>採用 Kubernetes 依然會需要處理不少技術問題，如網路、監控、資源調度等，並不是原生設計就能解決所有問題</li>
<li>除特定產業以外，台灣大多數企業單座 Kubernetes 多半都是低於 25 台節點這個數量級距，若是有選擇特定廠商支援的 Kubernetes 多半不太會遇到上面的問題，如果擔心估算不夠的話，個人建議 Control Plane 的節點大小計算可以以 100 台節點承載量做為基準，不用以 7,500 這個規模當作基礎參考</li>
<li>Control Plane 顧得好，晚上睡覺睡得著</li>
<li>這文章沒特別講 Underlay Networking 設計，基於已知 Azure 機房網路規劃應該會是以 Spine-Leaf Topology 為設計基礎，但具體 Switch 是用什麼就不知道了，主要原因是因為 GPUDirect RDMA 需要 Switch 支援能力</li>
<li>批次計算處理及資源分配攪和在一起，是一個很重要的研究議題</li>
</ol>
<h3 id="azure-kubernetes-sevices"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#azure-kubernetes-sevices">Azure Kubernetes Sevices 你應該要知道的關鍵資訊</a></h3>
<details class="info" open="open">
<summary>Info</summary>
<p>2023/02/14 更新</p>
</details>
<p>基於 <a href="https://learn.microsoft.com/en-us/azure/aks/quotas-skus-regions">Quotas, virtual machine size restrictions, and region availability in Azure Kubernetes Service (AKS)</a> 提供關鍵資訊如下:</p>
<p>以採用 Azure Standard Load Balancer 及 Standard Tier 為主,</p>
<table>
<thead>
<tr>
<th>Resource</th>
<th>Limit</th>
</tr>
</thead>
<tbody>
<tr>
<td>於單一集群內之最大節點數</td>
<td>上限 5000 台節點，系統預設 1000 台節點</td>
</tr>
<tr>
<td>於單一節點內之最大 Pod 數 （CNI 採用 kubenet)</td>
<td>最大 250 個，系統預設 110 個</td>
</tr>
<tr>
<td>於單一節點內之最大 Pod 數 （CNI 採用 Azure CNI)</td>
<td>最大 250 個，系統預設 30 個</td>
</tr>
</tbody>
</table>
<h4 id="pod"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#pod">關於最大 Pod 數量</a></h4>
<p>基於上面數據可以換算出 <mark>單一 AKS 集群受支援的狀況下，最多的 Pod 數為 1,250,000 Pods</mark> （= 5000 個節點 * 250 個 Pod)，但這個數字是估算值，因為實際可用 Pod 數量會受到實際計算資源分配、Kubernetes Deployment 撰寫方式等因素影響</p>
<p>實務上，單一節點上 Pod 數量設超大，老實說沒什麼特別用處，可能一兩個 Pod 就把整個節點資源吃完了，看看 OpenAI 的用法也是一樣，1 個節點 1 個 Pod，因為關鍵瓶頸在於 GPU 資源，如果你想要精算的話，建議可參考之前的文章 <a href="https://blog.pichuang.com.tw/20211112-how-to-sizing-kubernetes-resource-and-infra-resource.html">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a> 進行精細計算</p>
<h4 id="azure-subnet"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#azure-subnet">關於 Azure Subnet 計算</a></h4>
<p>Kubernetes 設計最麻煩的就是網路規劃，因為它是部署後不能改的參數，所以在部署之前一定要先算好，避免後續擴充有問題．而採用不同 Kubernetes CNI 會影響到 Subnet 計算，下面以現行 AKS 支援的 2 種 CNI 來做計算：</p>
<ol>
<li>採用 kubenet CNI</li>
<li>採用 Azure CNI</li>
</ol>
<p>若你對於兩者 CNI 有興趣比較的話，可以參考此文 <a href="https://learn.microsoft.com/en-us/azure/aks/concepts-network#compare-network-models">AKS - 比較網路模型</a>，這邊不再贅述</p>
<h5 id="kubenet-cni"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#kubenet-cni">採用 kubenet CNI</a></h5>
<details class="note" open="open">
<summary>Note</summary>
<p>若採用 kubenet CNI 的話，Pod 不支援直接從 Azure Subnet 拿到 IP，中間會過 iptables 進行 SNAT 轉換</p>
</details>
<p>基於 <a href="https://learn.microsoft.com/en-us/azure/aks/configure-azure-cni#plan-ip-addressing-for-your-cluster">Use kubenet networking with your own IP address ranges in Azure Kubernetes Service (AKS)
 - IP address availability and exhaustion</a> 文件，因為進行 AKS 升級的時候，會採用先建後拆的方式，所以需要預留一個節點的 IP 空間供使用，所以正確的節點計算基礎會是 <code>No. of Nodes + 1</code></p>
<p>下列提供計算公式</p>
<mark class="critic block">
<p>Minimum Subnet Size = Node IP = No. of Nodes + 1</p>
</mark>
<p>試算 1：一座具備 50 個節點的 AKS 採用 kubenet CNI</p>
<p>最小可用 IP 需求為 51 個 = (50 個節點 + 1)
基於 <a href="https://blog.pichuang.com.tw/azure-subnets.html">Visual Subnet Calculator (Azure Edition)</a>，可以計算出最小 Subnet 為 /26，網段可用 IP 數量為 59 個，該數字大於需求 51</p>
<p>試算 2: 一座具備 5,000 個節點的 AKS 採用 kubenet CNI</p>
<p>最小可用 IP 需求為 5,000 個 = (4999 個節點 + 1)
基於 <a href="https://blog.pichuang.com.tw/azure-subnets.html">Visual Subnet Calculator (Azure Edition)</a>，可以計算出最小 Subnet 為 /19，網段可用 IP 數量為 8,187 個，該數字大於需求 5,000</p>
<h5 id="azure-cni"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#azure-cni">採用 Azure CNI</a></h5>
<details class="note" open="open">
<summary>Note</summary>
<p>若採用 Azure CNI 的話，每一個 Pod 都能拿到 Azure Subnet 分配到的 IP，與其它 Pod 進行溝通時不會有額外的 SNAT 轉換成本</p>
</details>
<p>基於 <a href="https://learn.microsoft.com/en-us/azure/aks/configure-azure-cni#plan-ip-addressing-for-your-cluster">Configure Azure CNI networking in Azure Kubernetes Service (AKS) - Plan IP addressing for your cluster</a> 文件，因為進行 AKS 升級的時候，會採用先建後拆的方式，所以需要預留一個節點的 IP 空間供使用，所以正確的節點計算基礎會是 <code>No. of Nodes + 1</code></p>
<p>故下列提供一個合理的計算公式</p>
<mark class="critic block">
<p>Minimum Subnet Size = Node IP + Pod IP = (No. of Nodes + 1) + ((No. of Nodes + 1) * Maximum pods per nodes that you can configure)</p>
</mark>
<p>試算 1：一座具備 50 個節點的 AKS 採用 Azure CNI</p>
<p>最小可用 IP 需求為 12,801 個 = (50 個節點 + 1) + ((50 個節點 + 1) * 250 Pods)
基於 <a href="https://blog.pichuang.com.tw/azure-subnets.html">Visual Subnet Calculator (Azure Edition)</a>，可以計算出最小 Subnet 為 /18，網段可用 IP 數量為 16379 個，該數字大於需求 12,801</p>
<p>試算 2: 一座具備 5000 個節點的 AKS 採用 Azure CNI</p>
<p>最小可用 IP 需求為 1,255,000 個 = (4999 個節點 + 1) + ((4999 個節點 + 1) * 250 Pods)
基於 <a href="https://blog.pichuang.com.tw/azure-subnets.html">Visual Subnet Calculator (Azure Edition)</a>，可以計算出最小 Subnet 為 /11，網段可用 IP 數量為 2,097,147 個，該數字大於需求 1,255,000</p>
<h4 id="azure-vm"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#azure-vm">關於 Azure VM 大小</a></h4>
<ul>
<li>Azure VM 大小不能低於 2 vCPU，低於的話會不能正常運作，詳細 Azure Siez 可參考 <a href="https://learn.microsoft.com/en-us/azure/virtual-machines/sizes">Azure Virtual Machines sizes</a></li>
<li>Container Images 大小會影響到 Kubernetes Node 的大小，當有過大的 Container Images，kubelet 會因為沒有足夠的硬碟空間而無法正常運作，這個在跑 AI 模組實驗的時候會比較常遇到，因為 AI 模組的容器映像檔通常都會很大，可參考 <a href="https://catalog.ngc.nvidia.com/containers">NVIDIA NGC Container Catalog</a> 所提供的容器映像檔大小</li>
</ul>
<h3 id="_3"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#_3">總結</a></h3>
<p>有些事情只能擁有鈔能力才會知道</p>
<h3 id="_4"><a class="toclink" href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/#_4">感謝校稿</a></h3>
<ul>
<li><a href="https://linktr.ee/hwchiu">@hwchiu</a></li>
<li><a href="https://www.evanlin.com/">@Evan Lin</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2023/02/14/%E7%9C%8B-openai-%E4%BD%BF%E7%94%A8%E9%88%94%E8%83%BD%E5%8A%9B%E6%8B%9B%E5%96%9A-kubernetes-7500-%E5%8F%B0%E7%AF%80%E9%BB%9E/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2022-10-05 00:00:00">October 5, 2022</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="pod"><a class="toclink" href="../../2022/10/05/%E5%AF%A6%E7%8F%BE%E4%B8%8D%E5%81%9C%E6%A9%9F%E7%9A%84-pod-%E6%9B%B4%E6%96%B0%E6%96%B9%E5%BC%8F/">實現不停機的 Pod 更新方式</a></h2>
<p><img alt="" src="https://learnk8s.io/a/55d21503055aaf9ef8a04d5e595ed505.png" />
Source from <a href="https://learnk8s.io/graceful-shutdown">Learnk8s - Graceful shutdown and zero downtime deployments in Kubernetes</a></p>
<!--more-->

<p>如果你有一個持續不斷的服務，如 Long-lived TCP connections 或者是應用程式關閉要跑很久的，需要 "Graceful shutdown Pod" 的話</p>
<p>不改程式的狀況下，有你可以有 2 個治標不治本的方式來達成這件事</p>
<ul>
<li>延遲 SIGTERM 的訊號發送，preStop Hook 設定久一點讓他睡一下 (wait)</li>
</ul>
<div class="highlight"><span class="filename">preStop_sample</span><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>apiVersion: v1
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>kind: Pod
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>metadata:
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>  name: lifecycle-demo
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>spec:
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>  containers:
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>  - name: lifecycle-demo-container
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    image: nginx
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    lifecycle:
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>      preStop:
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>        exec:
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="hll">          command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;nginx -s quit; while killall -0 nginx; do sleep 10; done&quot;] # (1)
</span></code></pre></div>
<ol>
<li>
<p>Sleep for 10 seconds before sending SIGTERM to the main process</p>
</li>
<li>
<p>延遲 SIGKILL 的發生，把 terminationGracePeriodSeconds (default 30s) 設定長一點，譬如下面的範例</p>
</li>
</ol>
<div class="highlight"><span class="filename">terminationGracePeriodSeconds_sample</span><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>---
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>apiVersion: v1
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>kind: Pod
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>metadata:
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>  name: pods-termination-grace-period-seconds
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>spec:
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>  containers:
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>      image: nginx
<a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>      name: pods-termination-grace-period-seconds
<a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>  terminationGracePeriodSeconds: 3600  # (1)
</code></pre></div>
<ol>
<li>Time to wait before moving from a TERM signal to the pod's main process to a KILL signal.</li>
</ol>
<p>如何選擇?</p>
<p>如果你程式關閉時不需要處理任何狀態或同步資料，那就只要設定 preStop 就好了，如果是那種已知程式關閉已知要跑很久 (&gt;30s) 的程式，建議 preStop 和 terminationGracePeriodSeconds 都要拉長一點，這樣就能確保 Pod 關閉時不會有靈異現象發生</p>
<p>治本作法是: 程式收到 SIGTERM 訊號的時候，程式要自己知道怎麼關閉服務，不要讓底下 Kubernetes 幫你硬關機</p>
<h3 id="case-study-nginx-ingress-controller"><a class="toclink" href="../../2022/10/05/%E5%AF%A6%E7%8F%BE%E4%B8%8D%E5%81%9C%E6%A9%9F%E7%9A%84-pod-%E6%9B%B4%E6%96%B0%E6%96%B9%E5%BC%8F/#case-study-nginx-ingress-controller">Case Study: Nginx Ingress Controller</a></h3>
<p>三管齊下: 使用 preStop Hook + SIGTERM + terminationGracePeriodSeconds</p>
<p>關於 preStop 的處理，節錄 <a href="https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/cloud/deploy.yaml#L456-L460">ingress-nginx/deploy/static/provider/cloud/deploy.yaml#L456-L460</a>，這邊會去呼叫 waitshutdown 這個指令，再裡面去處理 SIGTERM 的訊號</p>
<div class="highlight"><span class="filename">ingress-nginx/deploy/static/provider/cloud/deploy.yaml</span><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>        lifecycle:
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>          preStop:
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>            exec:
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>              command:
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="hll">              - /wait-shutdown
</span></code></pre></div>
<p>關於 terminationGracePeriodSeconds，節錄 <a href="https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/cloud/deploy.yaml#L512">ingress-nginx/deploy/static/provider/cloud/deploy.yaml#L512</a></p>
<div class="highlight"><span class="filename">ingress-nginx/deploy/static/provider/cloud/deploy.yaml</span><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="hll">        terminationGracePeriodSeconds: 3600
</span></code></pre></div>
<p>關於 SIGTERM 的處理，節錄 <a href="https://github.com/kubernetes/ingress-nginx/blob/main/cmd/waitshutdown/main.go#L28-L42">ingress-nginx/cmd/waitshutdown/main.go#L28-L42</a></p>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">ingress-nginx/cmd/waitshutdown/main.go</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-9-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-9-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-9-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-9-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-9-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-9-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-9-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-9-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-9-10">10</a></span>
<span class="normal"><a href="#__codelineno-9-11">11</a></span>
<span class="normal"><a href="#__codelineno-9-12">12</a></span>
<span class="normal"><a href="#__codelineno-9-13">13</a></span>
<span class="normal"><a href="#__codelineno-9-14">14</a></span>
<span class="normal"><a href="#__codelineno-9-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a>func main() {
<a id="__codelineno-9-2" name="__codelineno-9-2"></a><span class="hll">    err := exec.Command(&quot;bash&quot;, &quot;-c&quot;, &quot;pkill -SIGTERM -f nginx-ingress-controller&quot;).Run()
</span><a id="__codelineno-9-3" name="__codelineno-9-3"></a>    if err != nil {
<a id="__codelineno-9-4" name="__codelineno-9-4"></a>        klog.ErrorS(err, &quot;terminating ingress controller&quot;)
<a id="__codelineno-9-5" name="__codelineno-9-5"></a>        os.Exit(1)
<a id="__codelineno-9-6" name="__codelineno-9-6"></a>    }
<a id="__codelineno-9-7" name="__codelineno-9-7"></a>
<a id="__codelineno-9-8" name="__codelineno-9-8"></a>    // wait for the NGINX process to terminate
<a id="__codelineno-9-9" name="__codelineno-9-9"></a>    timer := time.NewTicker(time.Second * 1)
<a id="__codelineno-9-10" name="__codelineno-9-10"></a>    for range timer.C {
<a id="__codelineno-9-11" name="__codelineno-9-11"></a>        if !nginx.IsRunning() {
<a id="__codelineno-9-12" name="__codelineno-9-12"></a>            timer.Stop()
<a id="__codelineno-9-13" name="__codelineno-9-13"></a>            break
<a id="__codelineno-9-14" name="__codelineno-9-14"></a>        }
<a id="__codelineno-9-15" name="__codelineno-9-15"></a>    }
</code></pre></div></td></tr></table></div>
<h3 id="references"><a class="toclink" href="../../2022/10/05/%E5%AF%A6%E7%8F%BE%E4%B8%8D%E5%81%9C%E6%A9%9F%E7%9A%84-pod-%E6%9B%B4%E6%96%B0%E6%96%B9%E5%BC%8F/#references">References</a></h3>
<ul>
<li><a href="https://engineering.rakuten.today/post/graceful-k8s-delpoyments/">Rakuten Developer - Zero-Downtime Rolling Deployments in Kubernetes</a></li>
<li><a href="https://www.facebook.com/groups/cloudnative.tw/posts/1470137983489532/">Facebook 原文</a></li>
<li><a href="https://learnk8s.io/graceful-shutdown">Graceful shutdown and zero downtime deployments in Kubernetes</a></li>
<li><a href="https://kubernetes.io/zh-cn/docs/concepts/containers/container-lifecycle-hooks/">Kubernetes - Container Lifecycle Hooks</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2022/10/05/%E5%AF%A6%E7%8F%BE%E4%B8%8D%E5%81%9C%E6%A9%9F%E7%9A%84-pod-%E6%9B%B4%E6%96%B0%E6%96%B9%E5%BC%8F/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2022-02-16 00:00:00">February 16, 2022</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="1-kubernetes-kubernetes"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/">我要 1 座 Kubernetes 還是要多座 Kubernetes? 還是都可以?</a></h2>
<p>曾經於 <a href="https://www.youtube.com/watch?v=-y-aycTxKBA">SDN x Cloud Native Meetup #42 OPA + 單多叢集架構探討</a>、<a href="https://docs.google.com/presentation/d/1GBInjH45Vremz4_463T3Z5VK9CC_atpYSI-4yAY8QuE/edit#slide=id.p">簡報</a> 分享過 <code>Kubernetes 多叢集及單叢集架構選擇探討</code> 的題目，當中有多租戶議題還蠻受到關注的，剛好因為工作關係也有蠻多客戶在問相同的題目，這邊想用文字的方式紀錄一下，供大家參考</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-y-aycTxKBA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<!--more-->

<h3 id="q1-1-kubernetes"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q1-1-kubernetes">Q1: 何謂 1 座 Kubernetes?</a></h3>
<p><code>可單獨運行之 Kubernetes API 為最小管理單位</code>，跟該座 Kubernetes 底下有多少節點完全無關，無論是 Control Plane 或 Worker Plane。實務上，可以使用 <code>kubectl cluster-info</code> 來做判斷</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="gp">$ </span>kubectl<span class="w"> </span>cluster-info
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="go">Kubernetes control plane is running at https://192.168.100.1:8443</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="go">CoreDNS is running at https://192.168.100.1:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
</code></pre></div>
<p>如上所示，因 Kubernetes 的設計是所有的操作都需要跟 Kubernetes API Server 進行，該服務預設一定會建立在 <code>Control Plane</code> 上，也就是 <code>https://192.168.100.1:8443</code> 來進行溝通，所以如果你有 2 個以上的 Kubernetes 叢集，勢必會獲得到不一樣的 Kubernetes cluster-info 資訊</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="gp"># </span>使用叢集<span class="w"> </span>Dev-and-Staging-Cluster
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="go">kubectl config use-c context Dev-and-Staging-Cluster</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="gp"># </span>Kubernetes<span class="w"> </span>叢集<span class="w"> </span>Dev-and-Staging-Cluster
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="gp">$ </span>kubectl<span class="w"> </span>cluster-info
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="go">Kubernetes control plane is running at https://192.168.100.1:8443</span>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="go">CoreDNS is running at https://192.168.100.1:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="gp"># </span>切換至叢集<span class="w"> </span>Prod-Cluster
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="go">kubectl config use-context Prod-Cluster</span>
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="gp"># </span>Kubernetes<span class="w"> </span>叢集<span class="w"> </span>Prod-Cluster
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a><span class="gp">$ </span>kubectl<span class="w"> </span>cluster-info
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="go">Kubernetes control plane is running at https://192.168.200.1:8443</span>
<a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a><span class="go">CoreDNS is running at https://192.168.200.1:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
</code></pre></div>
<p>如上所示，透過 <code>kubectl config use-context</code> 可以切換至其他叢集進行操作，你會發現到 2 個叢集的 Control Plane 網址是不一樣的 <code>https://192.168.100.1:8443</code> 跟 <code>https://192.168.200.1:8443</code>，這代表你在跟不同的叢集在進行操作</p>
<p>上述流程若你有去考過 CNCF 3 個考試</p>
<ul>
<li>Certified Kubernetes Administrator (CKA)</li>
<li>Certified Kubernetes Application Developer (CKAD)</li>
<li>Certified Kubernetes Security Specialist (CKS)</li>
</ul>
<p>應該會覺得相當熟悉，因為考試的時候也會要你切來切去，其實就是避免不同的考題所需的環境影響到彼此，屬於實體方式隔離 Kubernetes 叢集</p>
<h3 id="q2-kubernetes"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q2-kubernetes">Q2: Kubernetes 多租戶隔離架構有多少種類型?</a></h3>
<p>匯總 <a href="https://docs.microsoft.com/zh-tw/azure/aks/operator-best-practices-cluster-isolation">AKS</a>、<a href="https://aws.github.io/aws-eks-best-practices/security/docs/multitenancy/">EKS</a>、<a href="https://docs.microsoft.com/zh-tw/azure/aks/operator-best-practices-cluster-isolation">GKE</a> 三家公有雲的實踐作法，會區分成 2 個方向，</p>
<ol>
<li>以邏輯方式隔離 Kubernetes 叢集，也就是軟多租戶 (Soft Multi-Tenancy)</li>
<li>以實體方式隔離 Kubernetes 叢集，也就是硬多租戶 (Hard Multi-Tenancy)</li>
</ol>
<p>還有一種比較特殊的硬多租戶，僅會出現在 Kubernetes 平台供應商方的軟體架構設計，因為我這篇主要是寫給單純的 Kubernetes 使用者看，所以不列入討論</p>
<h3 id="q3-soft-multi-tenancy"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q3-soft-multi-tenancy">Q3: 軟多租戶 (Soft Multi-Tenancy) 的邏輯方式隔離手段有哪一些?</a></h3>
<p>下面引用 <a href="https://docs.microsoft.com/zh-tw/azure/aks/operator-best-practices-cluster-isolation">在 Azure Kubernetes Service (AKS) 中隔離叢集的最佳做法</a> 的示意圖</p>
<p><img alt="" src="/images/logical-isolation.png" /></p>
<p>以通過 <a href="https://github.com/cncf/k8s-conformance">CNCF Conformance</a> 為主的 Kubernetes 叢集為主，邏輯方式隔離手段主要區分 4 個作法</p>
<ol>
<li>Kubernetes Namespace：單一叢集內部命名空間隔離</li>
<li>Kubernetes Network Policy：單一叢集內部網路隔離</li>
<li>Kubernetes RBAC：單一叢集權限隔離</li>
<li>Resource Quota：單一叢集內之計算資源隔離</li>
</ol>
<p>實際上就是拿到 1 座 Kubernetes 叢集後，針對該叢集進行上述 4 個作法的邏輯隔離來進行資源隔離，但最小操作單位是 <code>Kubernetes Namespace</code> 為主，而底層計算資源大家是共用的，如下所列，我這座 <code>https://192.168.100.1:8443</code> 叢集轄下的 Kubernetes Namespace 可透過 <code>kubectl create ns &lt;NAME&gt;</code> 新增 Namespace，除了系統必要的 Namespace 以外，另外還新增了 3 個面向專案或應用的 DevTeam1、DevTeam2、Staging Namespace 供各別服務使用</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="gp"># </span>以<span class="w"> </span>Dev<span class="w"> </span>and<span class="w"> </span>Staging<span class="w"> </span>Cluster<span class="w"> </span>為例
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="gp">$ </span>kubectl<span class="w"> </span>cluster-info
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="go">Kubernetes control plane is running at https://192.168.100.1:8443</span>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="go">CoreDNS is running at https://192.168.100.1:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="gp">$ </span>kubectl<span class="w"> </span>get<span class="w"> </span>namespace
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="go">NAME                        STATUS   AGE</span>
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="go">default                     Active   16h &lt;- Kubernetes 預設</span>
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="go">DevTeam1                    Active   14s &lt;- 使用者自己建的</span>
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="go">DevTeam2                    Active   14s &lt;- 使用者自己建的</span>
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="go">kube-node-lease             Active   16h &lt;- Kubernetes 預設</span>
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="go">kube-public                 Active   16h &lt;- Kubernetes 預設</span>
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="go">kube-system                 Active   16h &lt;- Kubernetes 預設</span>
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="go">local-path-storage          Active   16h &lt;- 特定廠商預設</span>
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="go">Staging                     Active   10s &lt;- 使用者自己建的</span>
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a><span class="go">tanzu-package-repo-global   Active   16h &lt;- 特定廠商預設</span>
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="go">tanzu-system-ingress        Active   10h &lt;- 特定廠商預設</span>
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a><span class="go">tkg-system                  Active   16h &lt;- 特定廠商預設</span>
</code></pre></div>
<p>這方式也是絕大部分在學 Kubernetes 的維運管理操作的時候，著墨比較多的常見角度及常見學習路徑</p>
<h3 id="q4-hard-multi-tenancy"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q4-hard-multi-tenancy">Q4: 硬多租戶 (Hard Multi-Tenancy) 的實體方式隔離手段有哪一些?</a></h3>
<p>恩...這個其實沒有什麼訣竅，就是<code>再建立 1 座 Kubernetes</code>就好，有獨立的 Kubernetes API、獨立的計算網路儲存資源，軟多租戶的邏輯方式隔離也可以完全使用</p>
<p><img alt="" src="https://docs.microsoft.com/zh-tw/azure/aks/media/operator-best-practices-cluster-isolation/physical-isolation.png" /></p>
<p>預期有這麼多的 Kubernetes 叢集被部署出來，還是要能夠被管理，以現行常見的多叢集管理作法，包括但不限於以下：
- 多叢集網路規劃，包含對外負載均衡、跨叢集網路
- 多叢集策略管理
- Single Sign On 單一登入
- 集中化日誌收集
- 集中化資源監控
- ...</p>
<h3 id="q5"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q5">Q5: 兩者可不可以混用?</a></h3>
<p>可，多建幾座 Kubernetes 裡面再用 Namespace 等軟多租戶的隔離方式切割，如圖所示</p>
<p><img alt="" src="https://docs.microsoft.com/zh-tw/azure/aks/media/operator-best-practices-cluster-isolation/logical-isolation.png" /></p>
<ul>
<li>詳細描述如下</li>
<li>2 座 Kubernetes 叢集，分別為 Dev and Staging Cluster 和 Prod Cluster</li>
<li>當中 Dev and Staging Cluster 叢集內，共有 3 個 Kubernets Namespace，分別為 DevTeam1、DevTeam2、Staging</li>
<li>當中 Prod Cluster 叢集內，共有 3 個 Kubernetes Namespace, 分別為 Team1、Team2、Team3</li>
</ul>
<h3 id="q6"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q6">Q6: 用槍時機?</a></h3>
<p>主要判斷點就是 <code>Kubernetes API 可不可以共用和資源隔離性</code>的取捨，換個角度來講，如果單座 Kubernetes 爆炸了，上面的專案你能忍受多少是掛掉的狀態，如果你不能忍受，拆，能忍受，合</p>
<p>下面舉幾個我個人遇過會建議需要建多座的例子：</p>
<ol>
<li>不同環境的網路隔離，如 DR / Staging / Dev / Prod //技術上沒得談</li>
<li>Kubernetes 合規性，如 PCI-DSS、HIPPA 等不能於同一座 Kubernetes 混用合規檢測 //技術上沒得談</li>
<li>不同專案性質，如既有對於資訊系統的法規、核心系統、以 API Gateway 為主的 MASA 設計、共享服務平台 (CI/CD)、GPU 分享、指定 Kubernetes 版本等 //技術上可以，但我個人對於純地端客戶的理解相當不建議</li>
<li>底層 CPU 架構集不同，如 x86_64、ppc 等 //技術上可以，但我個人判斷相當不建議</li>
<li>不同部門之間技術落差 / 權限 / 內帳切割議題，如談錢保證傷感情的時候 //技術上可以，但我個人對於純地端客戶的理解相當不建議</li>
</ol>
<p>上述有些說技術上可以的，建議可以嘗試把小弟的拙作 <a href="https://blog.pichuang.com.tw/20211112-how-to-sizing-kubernetes-resource-and-infra-resource/">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a> 看完之後，請所有要住在一起的服務估算一下資源使用量有評估下災害爆炸半徑 (Blast Radius)，前者跟錢有關，後者跟 SLA 有關</p>
<p>最後給張梗圖</p>
<p><img alt="" src="/images/haha.jpg" /></p>
<h3 id="q7-kubernetes"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q7-kubernetes">Q7: 如果建多座 Kubernetes 不就要耗費很多資源?</a></h3>
<blockquote>
<p>個人觀點，Kubernetes 與 Cloud OS 之於 Linux 與 OS 的相對關係</p>
</blockquote>
<p>其實把 Kubernetes 當作一個雲原生作業系統 (Cloud OS) 的角度來看，應對不同的專案需求，大家對於 Kubernetes 的資源大小也會有所不同，類同於開發人員要弄一個專案總是要提出說，需要什麼 CPU / Memory / Disk / OS 用哪家的資源申請，這是很合理的，只是 Kubernetes 架構上需要多考量一些事情，所以保有 Kubernetes 叢集資源調整彈性及選擇是架構上需要考量的地方</p>
<p>所以小弟才會提以 2 個方向的角度來協助大家去科學地評估資源，而不是丟骰子的作法，當中一篇已經寫好了，可以參照參照</p>
<ul>
<li><a href="https://blog.pichuang.com.tw/20211112-how-to-sizing-kubernetes-resource-and-infra-resource/">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a></li>
<li>如何科學地估算 Kubernetes 所需的資源? Infra 角度篇 //還沒動力寫，請某某客戶贊助一下動力</li>
</ul>
<p>另外還有一篇大概也就 VMware 才有資格寫的多叢集 Kubernetes 於虛擬化平台之效能報告書 <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/performance/vsphere-tanzu-kubernetes-perf.pdf">Performance Best Practices for Kubernetes with VMware Tanzu - Performance Study</a> 也可以參考一下，寫得相當靠譜務實</p>
<h3 id="q8-kubernetes"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#q8-kubernetes">Q8: 如果我就是僅建一座 Kubernetes 裡面服務塞好塞滿可不可以?</a></h3>
<p>可，但要確保對於 <code>Q3: 軟多租戶的邏輯方式隔離手段有哪一些?</code> 所提之邏輯隔離手段，所有參與之上的租戶都要有相同的認知，然後設計該 Kubernetes 叢集的架構師，務必要相當熟悉通盤的網路架構，無論是 Kubernetes 內部或者是外部</p>
<h3 id="references"><a class="toclink" href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/#references">References</a></h3>
<ul>
<li><a href="https://aws.github.io/aws-eks-best-practices/security/docs/multitenancy/">EKS Best Practices Guides - Tenant Isolation</a></li>
<li><a href="https://docs.microsoft.com/zh-tw/azure/aks/operator-best-practices-cluster-isolation">在 Azure Kubernetes Service (AKS) 中隔離叢集的最佳做法</a></li>
<li><a href="https://cloud.google.com/kubernetes-engine/docs/best-practices/enterprise-multitenancy#assumptions_and_requirements">GKE 企业级多租户最佳做法</a></li>
<li><a href="https://github.com/cncf/k8s-conformance">cncf/k8s-conformance</a></li>
<li><a href="https://blog.pichuang.com.tw/20211112-how-to-sizing-kubernetes-resource-and-infra-resource/">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a></li>
<li><a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/performance/vsphere-tanzu-kubernetes-perf.pdf">Performance Best Practices for Kubernetes with VMware Tanzu - Performance Study</a></li>
</ul>
    <nav class="md-post__action">
      <a href="../../2022/02/16/%E6%88%91%E8%A6%81-1-%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E8%A6%81%E5%A4%9A%E5%BA%A7-kubernetes-%E9%82%84%E6%98%AF%E9%83%BD%E5%8F%AF%E4%BB%A5/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2021-11-29 00:00:00">November 29, 2021</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              8 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="kubernetes"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/">為什麼我佈署的 Kubernetes 服務不會動!? 個人除錯思路分享</a></h2>
<p>某週，下班前臨時被 S 學姊抓去看了一個 Kubernetes 服務為何不會正常作動，故身為學弟的我出了篇技術文希望記錄一下相關除錯思路給各位參考</p>
<blockquote>
<p>友人 A：覺得比搞 Kubernetes 還難的事情，大概就是談戀愛這件事了
友人 B：Kubernetes 起碼跟他告白 (a.k.a. 聲明式宣告, Declarative)，它會最大滿足你期望狀態 (Desired State)，但跟妹子告白可能會被抓去警察局，順便送你一張跟騷法
友人 C：這樣想想 Kubernetes 好像還比較和藹可親</p>
</blockquote>
<!--more-->

<p><img alt="" src="https://learnk8s.io/a/a-visual-guide-on-troubleshooting-kubernetes-deployments/troubleshooting-kubernetes.zh_cn.v2.png" /></p>
<p>首先，很久以前 <a href="https://learnk8s.io/troubleshooting-deployments">Learnk8s A visual guide on troubleshooting Kubernetes deployments</a> 有為了廣大受到 Kubernetes 佈署(荼毒)失敗之苦的朋友出了一份 Troubleshooting Kubernetes deployments 流程圖 <a href="https://learnk8s.io/a/a-visual-guide-on-troubleshooting-kubernetes-deployments/troubleshooting-kubernetes.zh_cn.v2.pdf">簡中版</a> / <a href="https://learnk8s.io/a/a-visual-guide-on-troubleshooting-kubernetes-deployments/troubleshooting-kubernetes.en_en.v2.pdf">英文版</a>，我個人覺得很具備參考價值，內文主要 3 大階段是：</p>
<ol>
<li>確認 Pod 運作正常 (約略佔比 50%)</li>
<li>確認 Service 運作正常 (約略佔比 25%)</li>
<li>確認 Ingress 運作正常 (約略佔比 25%)</li>
</ol>
<p>除了確認 Pod 運作正常是比較偏向 App 開發及程式佈署議題，其他兩個絕大部分都跟網路脫不了太大關係，所以我這邊基於該文對於網路除錯，包含 DNS、IP、HTTP 測試方式進行一些個人補充建議</p>
<h3 id="pod"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#pod">除錯前的基礎知識: Pod</a></h3>
<p>Pod，是實際上你的容器映像檔運行在 Kubernetes 的最小單位，裡面可以是 1 個或多個 Containers 在裡面，而同一個 Pod 裡面會共享同一個 Linux Namespace 的資源，包含 PID / NID 等。於本篇文章內比較重要的是同一個 Pod 裡面的 Linux Network Namesapce 的網路共享能力，意指每 1 個 Pod ，無論有多少個 Containers 在裡面運行，都會共享於該 Kubernetes 叢集內唯一的 IP，也就是 <code>Pod IP</code></p>
<h3 id="1-debug-container"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#1-debug-container">一切的起點，1 個 Debug Container</a></h3>
<p>首先，你需要先有一個已經封裝好<code>具備除錯工具</code>的容器映像檔，後面簡稱 <code>Debug Container</code></p>
<p>這個 Debug Container 的來源，主要是 2 個來源，其一是可以是採用社群善心人士編譯好的容器映像檔，如 <code>docker.io/nicolaka/netshoot</code>等，或其二是隨自家需求，從 <code>Base Image</code> 自行安裝、打包容器映像檔，如 <code>quay.io/pichuang/debug-container</code> 等，保持容器映像檔可控、可自行維護等好處</p>
<p>本文採用 <code>docker.io/nicolaka/netshoot</code> 作為主要 Debug Container 的基礎，詳細包含之工具可參考 <a href="https://github.com/nicolaka/netshoot">nicolaka/netshoot</a></p>
<p>把這個 Debug Container 運行在 Kubernetes 上後，會以 Kubernetes Pod 的形式運作於上，所以也會有 1 個 Pod IP 可以拿來跟其他 Pod 做交叉比對使用，所以身為一個 Kubernetes 使用者，有一個好上手的 Debug Container 是一個很合理的事情</p>
<h3 id="debug-container-2"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#debug-container-2">運行 Debug Container 之 2 種方式</a></h3>
<p>至於運行方式是使用 kubectl 進行操作，以<code>指定 namespace 為角度</code>出發進行操作，主要有下列 2 種作法但不限於：</p>
<ol>
<li>
<p>於指定 Namespace 執行 Debug Container
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="c1">#</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="c1"># Running debug container within the Kubernetes Namespace on Any Nodes</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="c1">#</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--image<span class="w"> </span>docker.io/nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
</code></pre></div></p>
</li>
<li>
<p>於指定 Namespace 和指定 Node 執行 Debug Container
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>#
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a># Running debug container within the Kubernetes Namespace on Specific Node (ex: tkg-worker-1)
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>#
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a># List of all Kubernetes nodes
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>$ kubectl get nodes
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>NAME                           STATUS   ROLES                  AGE   VERSION
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>tkgm14-control-plane-pv76m     Ready    control-plane,master   38d   v1.21.2+vmware.1
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>tkgm14-md-0-66f85bf86b-wfjt7   Ready    &lt;none&gt;                 38d   v1.21.2+vmware.1
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>$ kubectl run -n default debug-container --rm -i --tty --overrides=&#39;{ &quot;apiVersion&quot;: &quot;v1&quot;, &quot;spec&quot;: {&quot;kubernetes.io/hostname&quot;:&quot;tkgm14-control-plane-pv76m&quot;}}&#39; --image docker.io/nicolaka/netshoot -- /bin/bash
</code></pre></div></p>
</li>
</ol>
<p>正常狀況下，你應該直接使用方法 1 就可以找出很多問題了，除非你懷疑特定節點怪怪的，再使用方法 2</p>
<h3 id="pod-5-5"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#pod-5-5">從 Pod 出發的 5 種流量走法，5 種除錯方向</a></h3>
<p>整體上，Kubernetes 內到外網路流量，約略可以條列成為下列 5 種流量走法但不限：</p>
<ol>
<li>Container to Container</li>
<li>Pod to Pod in the same nodes</li>
<li>Pod to Pod across different nodes</li>
<li>Pod to Service</li>
<li>Pod to Internet</li>
</ol>
<p>詳細可參考小弟於香港開源人年會之分享 <a href="https://speakerdeck.com/pichuang/how-do-i-troubleshooting-on-container-more-than-docker">20200612, How I do troubleshooting on container, more than docker?, HKOSCon 2020</a></p>
<p>因為實際上所有實際服務都是被包裝在 Pod 裡面運行，故當遇到服務不通或異常的時候，想要快速進行網路流量除錯，可以以 <code>Pod IP 角度且以 Kubernetes Service 常見分類為主</code>之 4 種除錯方向:</p>
<ol>
<li>Pod IP to Pod IP</li>
<li>Pod IP to ClusterIP</li>
<li>Pod IP to NodePort IP</li>
<li>Pod IP to LoadBalancer IP (雲端常見，或特定 LB 軟體有提供整合能力，如 AVI Networks)</li>
</ol>
<p>另外還有 1 個 Kubernetes Service 編制外但常見的 Ingress Controller</p>
<ol>
<li>Pod IP to Ingress Hosts (地端常見，如 Contour、Nginx)</li>
</ol>
<h4 id="_1"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#_1">收集除錯前之必要資訊</a></h4>
<p>要開始使用 Debug Container 進行除錯之前，務必要先收集好相關資訊 <code>kubectl get pods,svc,nodes -owide</code>，主要是要有 IP 和名字之其相關資訊，如以下操作：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>get<span class="w"> </span>pods,svc,nodes,ingress<span class="w"> </span>-owide
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>NAME<span class="w">                                    </span>READY<span class="w">   </span>STATUS<span class="w">    </span>RESTARTS<span class="w">   </span>AGE<span class="w">   </span>IP<span class="w">            </span>NODE<span class="w">                           </span>NOMINATED<span class="w"> </span>NODE<span class="w">   </span>READINESS<span class="w"> </span>GATES
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>pod/tanzu-deployment-5769f6c4df-2fl28<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>60m<span class="w">   </span><span class="m">100</span>.96.1.33<span class="w">   </span>tkgm14-md-0-66f85bf86b-wfjt7<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>pod/tanzu-deployment-5769f6c4df-8jj87<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>60m<span class="w">   </span><span class="m">100</span>.96.1.35<span class="w">   </span>tkgm14-md-0-66f85bf86b-wfjt7<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>pod/tanzu-deployment-5769f6c4df-nlcg8<span class="w">   </span><span class="m">1</span>/1<span class="w">     </span>Running<span class="w">   </span><span class="m">0</span><span class="w">          </span>60m<span class="w">   </span><span class="m">100</span>.96.1.34<span class="w">   </span>tkgm14-md-0-66f85bf86b-wfjt7<span class="w">   </span>&lt;none&gt;<span class="w">           </span>&lt;none&gt;
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>NAME<span class="w">                     </span>TYPE<span class="w">         </span>CLUSTER-IP<span class="w">      </span>EXTERNAL-IP<span class="w">     </span>PORT<span class="o">(</span>S<span class="o">)</span><span class="w">          </span>AGE<span class="w">   </span>SELECTOR
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>service/kubernetes<span class="w">       </span>ClusterIP<span class="w">    </span><span class="m">100</span>.64.0.1<span class="w">      </span>&lt;none&gt;<span class="w">          </span><span class="m">443</span>/TCP<span class="w">          </span>38d<span class="w">   </span>&lt;none&gt;
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>service/tanzu-service<span class="w">    </span>NodePort<span class="w">     </span><span class="m">100</span>.70.88.107<span class="w">   </span>&lt;none&gt;<span class="w">          </span><span class="m">3000</span>:30390/TCP<span class="w">   </span>60m<span class="w">   </span><span class="nv">app</span><span class="o">=</span>tkgm-deployment
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>service/tanzu-lb-service<span class="w"> </span>LoadBalancer<span class="w"> </span><span class="m">100</span>.70.88.108<span class="w">   </span><span class="m">172</span>.18.30.100<span class="w">   </span><span class="m">3000</span>:30340/TCP<span class="w">   </span>60m<span class="w">   </span><span class="nv">app</span><span class="o">=</span>tkgm-deployment
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>NAME<span class="w">                                </span>STATUS<span class="w">   </span>ROLES<span class="w">                  </span>AGE<span class="w">   </span>VERSION<span class="w">            </span>INTERNAL-IP<span class="w">    </span>EXTERNAL-IP<span class="w">    </span>OS-IMAGE<span class="w">             </span>KERNEL-VERSION<span class="w">     </span>CONTAINER-RUNTIME
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>node/tkgm14-control-plane-pv76m<span class="w">     </span>Ready<span class="w">    </span>control-plane,master<span class="w">   </span>38d<span class="w">   </span>v1.21.2+vmware.1<span class="w">   </span><span class="m">172</span>.18.30.38<span class="w">   </span><span class="m">172</span>.18.30.38<span class="w">   </span>Ubuntu<span class="w"> </span><span class="m">20</span>.04.2<span class="w"> </span>LTS<span class="w">   </span><span class="m">5</span>.4.0-77-generic<span class="w">   </span>containerd://1.4.6
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>node/tkgm14-md-0-66f85bf86b-wfjt7<span class="w">   </span>Ready<span class="w">    </span>&lt;none&gt;<span class="w">                 </span>38d<span class="w">   </span>v1.21.2+vmware.1<span class="w">   </span><span class="m">172</span>.18.30.39<span class="w">   </span><span class="m">172</span>.18.30.39<span class="w">   </span>Ubuntu<span class="w"> </span><span class="m">20</span>.04.2<span class="w"> </span>LTS<span class="w">   </span><span class="m">5</span>.4.0-77-generic<span class="w">   </span>containerd://1.4.6
</code></pre></div>
<h4 id="1-pod-ip-to-pod-ip-traffic"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#1-pod-ip-to-pod-ip-traffic">1. Pod IP to Pod IP Traffic</a></h4>
<p>中等難度的測試，包含 Ping / Curl 都要能獲得預期的反應，如果有問題的話，可以參閱 <a href="https://learnk8s.io/troubleshooting-deployments">Learnk8s A visual guide on troubleshooting Kubernetes deployments</a> 進行 Pod 內部運行的問題除錯，這時候下 <code>kubectl logs &lt;pod name&gt;</code> 和 <code>kubectl describe pod &lt;pod name&gt;</code> 應該都會有些蛛絲馬跡</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="c1"># Run debug container</span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--image<span class="w"> </span>docker.io/nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="c1"># List of Routing Table</span>
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>bash-5.1#<span class="w"> </span>ip<span class="w"> </span>r
<a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>default<span class="w"> </span>via<span class="w"> </span><span class="m">100</span>.96.1.1<span class="w"> </span>dev<span class="w"> </span>eth0
<a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a><span class="m">100</span>.96.1.0/24<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>kernel<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">100</span>.96.1.36
<a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>
<a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a><span class="c1">#</span>
<a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a><span class="c1"># Ping</span>
<a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a><span class="c1"># Test Connectivity</span>
<a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">100</span>.96.1.35
<a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">100</span>.96.1.34
<a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">100</span>.96.1.33
<a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>PING<span class="w"> </span><span class="m">100</span>.96.1.33<span class="w"> </span><span class="o">(</span><span class="m">100</span>.96.1.33<span class="o">)</span><span class="w"> </span><span class="m">56</span><span class="o">(</span><span class="m">84</span><span class="o">)</span><span class="w"> </span>bytes<span class="w"> </span>of<span class="w"> </span>data.
<a id="__codelineno-14-16" name="__codelineno-14-16" href="#__codelineno-14-16"></a><span class="m">64</span><span class="w"> </span>bytes<span class="w"> </span>from<span class="w"> </span><span class="m">100</span>.96.1.33:<span class="w"> </span><span class="nv">icmp_seq</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">ttl</span><span class="o">=</span><span class="m">64</span><span class="w"> </span><span class="nv">time</span><span class="o">=</span><span class="m">0</span>.875<span class="w"> </span>ms
<a id="__codelineno-14-17" name="__codelineno-14-17" href="#__codelineno-14-17"></a>
<a id="__codelineno-14-18" name="__codelineno-14-18" href="#__codelineno-14-18"></a><span class="c1"># Curl web page</span>
<a id="__codelineno-14-19" name="__codelineno-14-19" href="#__codelineno-14-19"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span><span class="m">100</span>.96.1.33:3000
<a id="__codelineno-14-20" name="__codelineno-14-20" href="#__codelineno-14-20"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span><span class="m">100</span>.96.1.34:3000
<a id="__codelineno-14-21" name="__codelineno-14-21" href="#__codelineno-14-21"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span><span class="m">100</span>.96.1.35:3000
<a id="__codelineno-14-22" name="__codelineno-14-22" href="#__codelineno-14-22"></a>Hello<span class="w"> </span>World!
</code></pre></div>
<h4 id="2-pod-ip-to-clusterip-traffic"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#2-pod-ip-to-clusterip-traffic">2. Pod IP to ClusterIP Traffic</a></h4>
<p>最核心的測試，首先你需要先對 Kubernetes Services 運作要有一定程度理解，詳細可以參考 <a href="https://www.hwchiu.com/kubernetes-service-i.html">Hwchiu - Kubernetes What Is Service?</a> 一文，在這個階段主要測試目標是，確認可以透過 Kubernetes Cluster IP 獲得 Pod 的內容</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="c1"># Run debug container</span>
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--image<span class="w"> </span>docker.io/nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="c1"># List of Routing Table</span>
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>bash-5.1#<span class="w"> </span>ip<span class="w"> </span>r
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>default<span class="w"> </span>via<span class="w"> </span><span class="m">100</span>.96.1.1<span class="w"> </span>dev<span class="w"> </span>eth0
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a><span class="m">100</span>.96.1.0/24<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>kernel<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">100</span>.96.1.37
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a><span class="c1">#</span>
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a><span class="c1"># DNS Lookup</span>
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a><span class="c1"># https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</span>
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a><span class="c1">#</span>
<a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a><span class="c1"># nslookup &lt;service name&gt;.&lt;namespace name&gt;</span>
<a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a><span class="c1"># nslookup &lt;service name&gt;.&lt;namespace name&gt;.svc.cluster.local</span>
<a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>bash-5.1#<span class="w"> </span>nslookup<span class="w"> </span>tanzu-service.default
<a id="__codelineno-15-16" name="__codelineno-15-16" href="#__codelineno-15-16"></a>bash-5.1#<span class="w"> </span>nslookup<span class="w"> </span>tanzu-service.default.svc.cluster.local
<a id="__codelineno-15-17" name="__codelineno-15-17" href="#__codelineno-15-17"></a>Server:<span class="w">     </span><span class="m">100</span>.64.0.10
<a id="__codelineno-15-18" name="__codelineno-15-18" href="#__codelineno-15-18"></a>Address:<span class="w">    </span><span class="m">100</span>.64.0.10#53
<a id="__codelineno-15-19" name="__codelineno-15-19" href="#__codelineno-15-19"></a>
<a id="__codelineno-15-20" name="__codelineno-15-20" href="#__codelineno-15-20"></a>Name:<span class="w">   </span>tanzu-service.default.svc.cluster.local
<a id="__codelineno-15-21" name="__codelineno-15-21" href="#__codelineno-15-21"></a>Address:<span class="w"> </span><span class="m">100</span>.70.88.107
<a id="__codelineno-15-22" name="__codelineno-15-22" href="#__codelineno-15-22"></a>
<a id="__codelineno-15-23" name="__codelineno-15-23" href="#__codelineno-15-23"></a><span class="c1">#</span>
<a id="__codelineno-15-24" name="__codelineno-15-24" href="#__codelineno-15-24"></a><span class="c1"># Ping (FAILED)</span>
<a id="__codelineno-15-25" name="__codelineno-15-25" href="#__codelineno-15-25"></a><span class="c1"># Ping doesn&#39;t work with service&#39;s cluster IPs like 100.70.88.107, as it is a virtual IP</span>
<a id="__codelineno-15-26" name="__codelineno-15-26" href="#__codelineno-15-26"></a><span class="c1"># You should be able to ping a specific pod, but no a service.</span>
<a id="__codelineno-15-27" name="__codelineno-15-27" href="#__codelineno-15-27"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">100</span>.70.88.107
<a id="__codelineno-15-28" name="__codelineno-15-28" href="#__codelineno-15-28"></a>PING<span class="w"> </span><span class="m">100</span>.70.88.107<span class="w"> </span><span class="o">(</span><span class="m">100</span>.70.88.107<span class="o">)</span><span class="w"> </span><span class="m">56</span><span class="o">(</span><span class="m">84</span><span class="o">)</span><span class="w"> </span>bytes<span class="w"> </span>of<span class="w"> </span>data.
<a id="__codelineno-15-29" name="__codelineno-15-29" href="#__codelineno-15-29"></a>--<span class="w"> </span>Pending<span class="w"> </span>--
<a id="__codelineno-15-30" name="__codelineno-15-30" href="#__codelineno-15-30"></a>
<a id="__codelineno-15-31" name="__codelineno-15-31" href="#__codelineno-15-31"></a><span class="c1">#</span>
<a id="__codelineno-15-32" name="__codelineno-15-32" href="#__codelineno-15-32"></a><span class="c1"># Curl</span>
<a id="__codelineno-15-33" name="__codelineno-15-33" href="#__codelineno-15-33"></a><span class="c1">#</span>
<a id="__codelineno-15-34" name="__codelineno-15-34" href="#__codelineno-15-34"></a><span class="c1"># curl &lt;service name&gt;.&lt;namespace name&gt;:&lt;svc port&gt;</span>
<a id="__codelineno-15-35" name="__codelineno-15-35" href="#__codelineno-15-35"></a><span class="c1"># curl &lt;service name&gt;.&lt;namespace name&gt;.svc.cluster.local:&lt;svc port&gt;</span>
<a id="__codelineno-15-36" name="__codelineno-15-36" href="#__codelineno-15-36"></a><span class="c1"># curl &lt;cluster ip&gt;:&lt;svc port&gt;&gt;</span>
<a id="__codelineno-15-37" name="__codelineno-15-37" href="#__codelineno-15-37"></a>
<a id="__codelineno-15-38" name="__codelineno-15-38" href="#__codelineno-15-38"></a><span class="c1"># Curl web page (OK)</span>
<a id="__codelineno-15-39" name="__codelineno-15-39" href="#__codelineno-15-39"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span>tanzu-service.default:3000
<a id="__codelineno-15-40" name="__codelineno-15-40" href="#__codelineno-15-40"></a>Hello<span class="w"> </span>World!
<a id="__codelineno-15-41" name="__codelineno-15-41" href="#__codelineno-15-41"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span>tanzu-service.default.svc.cluster.local:3000
<a id="__codelineno-15-42" name="__codelineno-15-42" href="#__codelineno-15-42"></a>Hello<span class="w"> </span>World!
<a id="__codelineno-15-43" name="__codelineno-15-43" href="#__codelineno-15-43"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span><span class="m">100</span>.70.88.107:3000
<a id="__codelineno-15-44" name="__codelineno-15-44" href="#__codelineno-15-44"></a>Hello<span class="w"> </span>World!
<a id="__codelineno-15-45" name="__codelineno-15-45" href="#__codelineno-15-45"></a>
<a id="__codelineno-15-46" name="__codelineno-15-46" href="#__codelineno-15-46"></a><span class="c1"># Curl Kubernetes API Service (OK)</span>
<a id="__codelineno-15-47" name="__codelineno-15-47" href="#__codelineno-15-47"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-s<span class="w"> </span>-w<span class="w"> </span><span class="s2">&quot;%{http_code}\n&quot;</span><span class="w"> </span>--insecure<span class="w"> </span>https://kubernetes.default:443
<a id="__codelineno-15-48" name="__codelineno-15-48" href="#__codelineno-15-48"></a><span class="m">403</span>
<a id="__codelineno-15-49" name="__codelineno-15-49" href="#__codelineno-15-49"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-s<span class="w"> </span>-w<span class="w"> </span><span class="s2">&quot;%{http_code}\n&quot;</span><span class="w"> </span>--insecure<span class="w"> </span>https://kubernetes.default.svc.cluster.local:443
<a id="__codelineno-15-50" name="__codelineno-15-50" href="#__codelineno-15-50"></a><span class="m">403</span>
<a id="__codelineno-15-51" name="__codelineno-15-51" href="#__codelineno-15-51"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-s<span class="w"> </span>-w<span class="w"> </span><span class="s2">&quot;%{http_code}\n&quot;</span><span class="w"> </span>--insecure<span class="w"> </span>https://100.64.0.1:443
<a id="__codelineno-15-52" name="__codelineno-15-52" href="#__codelineno-15-52"></a><span class="m">403</span>
</code></pre></div>
<h4 id="3-pod-ip-to-nodeport-ip"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#3-pod-ip-to-nodeport-ip">3. Pod IP to NodePort IP</a></h4>
<p>執行一次 <code>2. Pod IP to Cluster IP</code> 測試以外，還需要另外確認對外服務揭露的部份，主要以 Node IP 為基礎</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="c1"># Run debug container</span>
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--image<span class="w"> </span>docker.io/nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a><span class="c1"># List of Routing Table</span>
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>bash-5.1#<span class="w"> </span>ip<span class="w"> </span>r
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>default<span class="w"> </span>via<span class="w"> </span><span class="m">100</span>.96.1.1<span class="w"> </span>dev<span class="w"> </span>eth0
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a><span class="m">100</span>.96.1.0/24<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>kernel<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">100</span>.96.1.40
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>
<a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a><span class="c1">#</span>
<a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a><span class="c1"># Ping</span>
<a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a><span class="c1"># Test Connectivity</span>
<a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a><span class="c1"># Pod IP -&gt; Node IP</span>
<a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a><span class="c1">#</span>
<a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">172</span>.18.30.39
<a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a>PING<span class="w"> </span><span class="m">172</span>.18.30.39<span class="w"> </span><span class="o">(</span><span class="m">172</span>.18.30.39<span class="o">)</span><span class="w"> </span><span class="m">56</span><span class="o">(</span><span class="m">84</span><span class="o">)</span><span class="w"> </span>bytes<span class="w"> </span>of<span class="w"> </span>data.
<a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a><span class="m">64</span><span class="w"> </span>bytes<span class="w"> </span>from<span class="w"> </span><span class="m">172</span>.18.30.39:<span class="w"> </span><span class="nv">icmp_seq</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">ttl</span><span class="o">=</span><span class="m">64</span><span class="w"> </span><span class="nv">time</span><span class="o">=</span><span class="m">0</span>.463<span class="w"> </span>ms
<a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a>
<a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a><span class="c1">#</span>
<a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a><span class="c1"># Curl</span>
<a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a><span class="c1"># curl &lt;node ip&gt;:&lt;node port&gt;</span>
<a id="__codelineno-16-21" name="__codelineno-16-21" href="#__codelineno-16-21"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span><span class="m">172</span>.18.30.39:30390
<a id="__codelineno-16-22" name="__codelineno-16-22" href="#__codelineno-16-22"></a>Hello<span class="w"> </span>World!
</code></pre></div>
<h4 id="4-pod-ip-to-loadbalancer-ip"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#4-pod-ip-to-loadbalancer-ip">4. Pod IP to LoadBalancer IP</a></h4>
<p>執行一次 <code>2. Pod IP to Cluster IP</code> 測試以外，還需要另外確認對外服務揭露的部份，主要以 Loadbalacner IP 為基礎</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="c1"># Run debug container</span>
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--image<span class="w"> </span>docker.io/nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="c1"># List of Routing Table</span>
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>bash-5.1#<span class="w"> </span>ip<span class="w"> </span>r
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>default<span class="w"> </span>via<span class="w"> </span><span class="m">100</span>.96.1.1<span class="w"> </span>dev<span class="w"> </span>eth0
<a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a><span class="m">100</span>.96.1.0/24<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>kernel<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">100</span>.96.1.40
<a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a>
<a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a><span class="c1">#</span>
<a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a><span class="c1"># Ping</span>
<a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a><span class="c1"># Test Connectivity</span>
<a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a><span class="c1"># Pod IP -&gt; LoadBalancer IP</span>
<a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a><span class="c1">#</span>
<a id="__codelineno-17-14" name="__codelineno-17-14" href="#__codelineno-17-14"></a>
<a id="__codelineno-17-15" name="__codelineno-17-15" href="#__codelineno-17-15"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">172</span>.18.30.100
<a id="__codelineno-17-16" name="__codelineno-17-16" href="#__codelineno-17-16"></a>PING<span class="w"> </span><span class="m">172</span>.18.30.100<span class="w"> </span><span class="o">(</span><span class="m">172</span>.18.30.100<span class="o">)</span><span class="w"> </span><span class="m">56</span><span class="o">(</span><span class="m">84</span><span class="o">)</span><span class="w"> </span>bytes<span class="w"> </span>of<span class="w"> </span>data.
<a id="__codelineno-17-17" name="__codelineno-17-17" href="#__codelineno-17-17"></a><span class="m">64</span><span class="w"> </span>bytes<span class="w"> </span>from<span class="w"> </span><span class="m">172</span>.18.30.100:<span class="w"> </span><span class="nv">icmp_seq</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">ttl</span><span class="o">=</span><span class="m">64</span><span class="w"> </span><span class="nv">time</span><span class="o">=</span><span class="m">0</span>.3<span class="w"> </span>ms
<a id="__codelineno-17-18" name="__codelineno-17-18" href="#__codelineno-17-18"></a>
<a id="__codelineno-17-19" name="__codelineno-17-19" href="#__codelineno-17-19"></a><span class="c1">#</span>
<a id="__codelineno-17-20" name="__codelineno-17-20" href="#__codelineno-17-20"></a><span class="c1"># Curl</span>
<a id="__codelineno-17-21" name="__codelineno-17-21" href="#__codelineno-17-21"></a><span class="c1"># curl &lt;LoadBalancer ip&gt;:&lt;LB port&gt;</span>
<a id="__codelineno-17-22" name="__codelineno-17-22" href="#__codelineno-17-22"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span><span class="m">172</span>.18.30.100:30340
<a id="__codelineno-17-23" name="__codelineno-17-23" href="#__codelineno-17-23"></a>Hello<span class="w"> </span>World!
</code></pre></div>
<h4 id="5-pod-ip-to-ingress-hosts"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#5-pod-ip-to-ingress-hosts">5. Pod IP to Ingress Hosts</a></h4>
<p>執行一次 <code>2. Pod IP to Cluster IP</code> 測試以外，還需要另外確認對外服務揭露的部份，主要以 Ingress Hosts 為基礎</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="c1">#</span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>$<span class="w"> </span>kubectl<span class="w"> </span>get<span class="w"> </span>ingress
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>NAME<span class="w">                        </span>HOSTS<span class="w">                                                   </span>ADDRESS<span class="w">       </span>PORTS<span class="w">   </span>AGE
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>name-virtual-host-ingress<span class="w">   </span>tutum.training.boxboat.io,jwilder.training.boxboat.io<span class="w">   </span><span class="m">172</span>.17.0.58<span class="w">   </span><span class="m">80</span><span class="w">      </span>9m24s
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>path-ingress<span class="w">                </span>training.boxboat.io<span class="w">                                     </span><span class="m">172</span>.17.0.58<span class="w">   </span><span class="m">80</span><span class="w">      </span>9m2s
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>
<a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a><span class="c1"># Run debug container</span>
<a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--image<span class="w"> </span>docker.io/nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a>
<a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a><span class="c1"># List of Routing Table</span>
<a id="__codelineno-18-11" name="__codelineno-18-11" href="#__codelineno-18-11"></a>bash-5.1#<span class="w"> </span>ip<span class="w"> </span>r
<a id="__codelineno-18-12" name="__codelineno-18-12" href="#__codelineno-18-12"></a>default<span class="w"> </span>via<span class="w"> </span><span class="m">100</span>.96.1.1<span class="w"> </span>dev<span class="w"> </span>eth0
<a id="__codelineno-18-13" name="__codelineno-18-13" href="#__codelineno-18-13"></a><span class="m">100</span>.96.1.0/24<span class="w"> </span>dev<span class="w"> </span>eth0<span class="w"> </span>proto<span class="w"> </span>kernel<span class="w"> </span>scope<span class="w"> </span>link<span class="w"> </span>src<span class="w"> </span><span class="m">100</span>.96.1.40
<a id="__codelineno-18-14" name="__codelineno-18-14" href="#__codelineno-18-14"></a>
<a id="__codelineno-18-15" name="__codelineno-18-15" href="#__codelineno-18-15"></a><span class="c1">#</span>
<a id="__codelineno-18-16" name="__codelineno-18-16" href="#__codelineno-18-16"></a><span class="c1"># Ping</span>
<a id="__codelineno-18-17" name="__codelineno-18-17" href="#__codelineno-18-17"></a><span class="c1"># Test Connectivity</span>
<a id="__codelineno-18-18" name="__codelineno-18-18" href="#__codelineno-18-18"></a><span class="c1">#</span>
<a id="__codelineno-18-19" name="__codelineno-18-19" href="#__codelineno-18-19"></a>
<a id="__codelineno-18-20" name="__codelineno-18-20" href="#__codelineno-18-20"></a>bash-5.1#<span class="w"> </span>ping<span class="w"> </span><span class="m">172</span>.17.0.58
<a id="__codelineno-18-21" name="__codelineno-18-21" href="#__codelineno-18-21"></a>PING<span class="w"> </span><span class="m">172</span>.17.0.58<span class="w"> </span><span class="o">(</span><span class="m">172</span>.17.0.58<span class="o">)</span><span class="w"> </span><span class="m">56</span><span class="o">(</span><span class="m">84</span><span class="o">)</span><span class="w"> </span>bytes<span class="w"> </span>of<span class="w"> </span>data.
<a id="__codelineno-18-22" name="__codelineno-18-22" href="#__codelineno-18-22"></a><span class="m">64</span><span class="w"> </span>bytes<span class="w"> </span>from<span class="w"> </span><span class="m">172</span>.17.0.58:<span class="w"> </span><span class="nv">icmp_seq</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">ttl</span><span class="o">=</span><span class="m">63</span><span class="w"> </span><span class="nv">time</span><span class="o">=</span><span class="m">0</span>.706<span class="w"> </span>ms
<a id="__codelineno-18-23" name="__codelineno-18-23" href="#__codelineno-18-23"></a>
<a id="__codelineno-18-24" name="__codelineno-18-24" href="#__codelineno-18-24"></a><span class="c1"># Curl</span>
<a id="__codelineno-18-25" name="__codelineno-18-25" href="#__codelineno-18-25"></a><span class="c1"># curl &lt;HOSTS&gt;:&lt;PORTS&gt;</span>
<a id="__codelineno-18-26" name="__codelineno-18-26" href="#__codelineno-18-26"></a>bash-5.1#<span class="w"> </span>curl<span class="w"> </span>training.boxboat.io:80
</code></pre></div>
<h3 id="pod-to-ingress-vs-pod-to-loadbalancer"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#pod-to-ingress-vs-pod-to-loadbalancer">Pod to Ingress v.s. Pod to LoadBalancer</a></h3>
<p>如果你有仔細看，會發現 Kubernetes LoadBalacner 跟 Kubernetes Ingress 除錯起來套路很像，理由是他們都是實際上接收到 User Traffic 最前線的服務，至於想要了解兩者網路流量差異可參考 <a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0">Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what?</a>，及 <a href="https://www.hwchiu.com/ingress-1.html">Hwchiu - Introduction to Kubernetes Ingress (Nginx)</a></p>
<blockquote>
<p>Kubernetes LoadBalacner 是 Kubernetes Service 其中一種類型，外面必然會有一個獨立於 Kubernetes 容器平台外部的 External LB 存在
Kubernetes Ingress 並不是 Kubernetes Service，它受到特定 Ingress Controller 管理，建立於 Kubernetes 容器平台內部</p>
</blockquote>
<p>如果你沒有什麼特定 LB 可以提供 Kubernetes Service 呼叫使用的話，那基本上你大多數都是用 Kubernetes Ingress 作為主要使用，但兩者也可以並用就是了，盡可能不在同一個節點上即可，因為 hostNetwork 有蠻高機會會衝 Port，如 80/443 等</p>
<h3 id="_2"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#_2">常見問題</a></h3>
<h4 id="q1-deploymentyml-kubernetes-api"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#q1-deploymentyml-kubernetes-api">Q1: deployment.yml 裡的 Kubernetes API 改版了，該怎麼無縫地修正</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>deployment.yml
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>error:<span class="w"> </span>unable<span class="w"> </span>to<span class="w"> </span>recognize<span class="w"> </span><span class="s2">&quot;deployment.yml&quot;</span>:<span class="w"> </span>no<span class="w"> </span>matches<span class="w"> </span><span class="k">for</span><span class="w"> </span>kind<span class="w"> </span><span class="s2">&quot;Deployment&quot;</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>version<span class="w"> </span><span class="s2">&quot;extensions/v1beta1&quot;</span>
</code></pre></div>
<p>A1: 1. 找到正確的 API 名字
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>api-resources<span class="w"> </span><span class="p">|</span>grep<span class="w"> </span>deployments
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>deployments<span class="w">                       </span>deploy<span class="w">       </span>apps/v1<span class="w">                                              </span><span class="nb">true</span><span class="w">         </span>Deployment
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>machinedeployments<span class="w">                </span>md<span class="w">           </span>cluster.x-k8s.io/v1alpha3<span class="w">                            </span><span class="nb">true</span><span class="w">         </span>MachineDeployment
</code></pre></div>
2. 修正 deployment.yaml 內的檔案，從 <code>apiVersion: extensions/v1beta1</code> 到 <code>apiVersion: apps/v1</code>，重新執行
3. 沒意外應該還會有錯誤，再根據錯誤訊息，進行欄位的增刪修</p>
<h4 id="q2-kubernetes-platform-administrator"><a class="toclink" href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/#q2-kubernetes-platform-administrator">Q2: 如果你是 Kubernetes Platform Administrator 想要對特定節點之作業系統除錯那該怎麼辦?</a></h4>
<p>A2: 佈署的時候，多一個 <code>"hostNetwork": true</code> 參數即可</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>$<span class="w"> </span>kubectl<span class="w"> </span>run<span class="w"> </span>-n<span class="w"> </span>default<span class="w"> </span>debug-container<span class="w"> </span>--rm<span class="w"> </span>-i<span class="w"> </span>--tty<span class="w"> </span>--overrides<span class="o">=</span><span class="s1">&#39;{ &quot;apiVersion&quot;: &quot;v1&quot;, &quot;spec&quot;: {&quot;kubernetes.io/hostname&quot;:&quot;tkgm14-md-0-66f85bf86b-wfjt7&quot;, &quot;hostNetwork&quot;: true}}&#39;</span><span class="w"> </span>--image<span class="w"> </span>nicolaka/netshoot<span class="w"> </span>--<span class="w"> </span>/bin/bash
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>bash-5.1#<span class="w"> </span>ip<span class="w"> </span>a<span class="w"> </span>show<span class="w"> </span>eth0
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="m">2</span>:<span class="w"> </span>eth0:<span class="w"> </span>&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;<span class="w"> </span>mtu<span class="w"> </span><span class="m">1500</span><span class="w"> </span>qdisc<span class="w"> </span>mq<span class="w"> </span>state<span class="w"> </span>UP<span class="w"> </span>group<span class="w"> </span>default<span class="w"> </span>qlen<span class="w"> </span><span class="m">1000</span>
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="w">    </span>link/ether<span class="w"> </span><span class="m">00</span>:50:56:9e:85:bb<span class="w"> </span>brd<span class="w"> </span>ff:ff:ff:ff:ff:ff
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="w">    </span>inet<span class="w"> </span><span class="m">172</span>.18.30.39/24<span class="w"> </span>brd<span class="w"> </span><span class="m">172</span>.18.30.255<span class="w"> </span>scope<span class="w"> </span>global<span class="w"> </span>dynamic<span class="w"> </span>eth0
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a><span class="w">       </span>valid_lft<span class="w"> </span>1059832sec<span class="w"> </span>preferred_lft<span class="w"> </span>1059832sec
<a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="w">    </span>inet6<span class="w"> </span>fe80::250:56ff:fe9e:85bb/64<span class="w"> </span>scope<span class="w"> </span>link
<a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a><span class="w">       </span>valid_lft<span class="w"> </span>forever<span class="w"> </span>preferred_lft<span class="w"> </span>forever
</code></pre></div>
    <nav class="md-post__action">
      <a href="../../2021/11/29/%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E4%BD%88%E7%BD%B2%E7%9A%84-kubernetes-%E6%9C%8D%E5%8B%99%E4%B8%8D%E6%9C%83%E5%8B%95-%E5%80%8B%E4%BA%BA%E9%99%A4%E9%8C%AF%E6%80%9D%E8%B7%AF%E5%88%86%E4%BA%AB/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/5253671" alt="Phil Huang">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2021-11-12 00:00:00">November 12, 2021</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">kubernetes</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="kubernetes-app"><a class="toclink" href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/">如何科學地估算 Kubernetes 所需的資源? App 角度篇</a></h2>
<p>今年 2021 小弟上半年過度忙碌，加上換球隊打球，再加上有點遇到中年危機，導致發廢文量大幅下降，請大家多多擔待</p>
<blockquote>
<p>地上爬的我：算 Kubernetes Sizing 好累，我都以為我改行成為 Excel 架構師了呢
天上飛的學長：雲原生服務到底是要 Sizing 什麼 =_= ? 不夠不就給他加下去就對了?
地上爬的我：我們是地端...Q_Q
天上飛的學長：恩...你保重</p>
</blockquote>
<!--more-->

<h3 id="_1"><a class="toclink" href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/#_1">系列文前言</a></h3>
<p>早在本篇開始，其實早在先前 <a href="https://learnk8s.io/kubernetes-instance-calculator">Learnk8s Kubernetes Instance Calculator</a> 已經有推出過一個蠻好看的網頁資源計算機供大家參考，但這個的問題是他沒有考量到多個 Kubernetes Namespace 部署的狀況，畢竟不可能每一個 Pod 的資源都長一樣。其次，地端跟雲端不一樣，前者採購硬體需要事先準備，後者則具備<code>有限的無限資源</code>可供使用，所以只要前者一個估不準就會出事。但身為一名 Ops 人員，我又應該要如何請 App 人員提供數字給你作為參考？</p>
<p>所以為了廣大的鄉民，我提供預估資源資源作法，大概可以解決<code>八成左右</code>的狀況 (其他兩成狀況，請洽業務找我去幫忙算 XD)。故以為了要管理好多個 Kubernetes 叢集需求之下，需要在每一個 Kubernetes 所部署的程式資源 <a href="https://gist.github.com/pichuang/eb50ee49e4cdb64549df335216cc5290">Tanzu Mission Control Extension Manager</a> 的這支程式作為估算範例</p>
<p>主要分為兩個方向夾擊抓資源</p>
<ol>
<li>Top-Down：以 App 角度出發的 Kubernetes Application 資源估算</li>
<li>Bottom-Up：以 Ops 角度出發的 Hardware (or Cloud Provider) 資源估算</li>
</ol>
<h3 id="app-kubernetes-application"><a class="toclink" href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/#app-kubernetes-application">以 App 角度出發的 Kubernetes Application 資源估算</a></h3>
<p>想問問大家一個 Kubernetes 要部署一個 Application 會需要什麼東西? 是的，你需要去描述你的應用程式資源和相關資訊，並且部署在特定的 Kubernetes Namespace，如 <code>vmware-system-tmc</code>，所以身為一個 App 人員的目標就是把 <code>基於 namespace 為主的內部所需資源條列出來</code>，擷取 <a href="https://gist.github.com/pichuang/eb50ee49e4cdb64549df335216cc5290#file-sample-tmc-deployment-yaml-L880-L957">Tanzu Mission Control Extension Manager L880-L957</a> 內容，如下</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="nt">metadata</span><span class="p">:</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">  </span><span class="nt">annotations</span><span class="p">:</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="w">    </span><span class="nt">tmc.cloud.vmware.com/orphan-resource</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="w">  </span><span class="nt">labels</span><span class="p">:</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="w">    </span><span class="nt">control-plane</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="w">    </span><span class="nt">controller-tools.k8s.io</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="w">    </span><span class="nt">tmc-extension</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="w">    </span><span class="nt">tmc-extension-name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="w">    </span><span class="nt">tmc.cloud.vmware.com/managed</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;vmware-system-tmc&#39;</span>
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a><span class="nt">spec</span><span class="p">:</span>
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a><span class="w">  </span><span class="nt">minReadySeconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30</span>
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="w">  </span><span class="nt">progressDeadlineSeconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">600</span>
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a><span class="w">  </span><span class="nt">selector</span><span class="p">:</span>
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span>
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a><span class="w">      </span><span class="nt">control-plane</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a><span class="w">      </span><span class="nt">controller-tools.k8s.io</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a><span class="w">      </span><span class="nt">tmc-extension</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span>
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span>
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span>
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a><span class="w">      </span><span class="nt">maxSurge</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100%</span>
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a><span class="w">  </span><span class="nt">template</span><span class="p">:</span>
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span>
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a><span class="w">      </span><span class="nt">labels</span><span class="p">:</span>
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a><span class="w">        </span><span class="nt">control-plane</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a><span class="w">        </span><span class="nt">controller-tools.k8s.io</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span>
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a><span class="w">        </span><span class="nt">tmc-extension</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;true&quot;</span>
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a><span class="w">        </span><span class="nt">tmc-extension-name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a><span class="w">    </span><span class="nt">spec</span><span class="p">:</span>
<a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span>
<a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a><span class="w">        </span><span class="nt">nodeAffinity</span><span class="p">:</span>
<a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span>
<a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a><span class="w">            </span><span class="nt">nodeSelectorTerms</span><span class="p">:</span>
<a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a><span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">matchExpressions</span><span class="p">:</span>
<a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a><span class="w">              </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kubernetes.io/os</span>
<a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">In</span>
<a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a><span class="w">                </span><span class="nt">values</span><span class="p">:</span>
<a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a><span class="w">                </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linux</span>
<a id="__codelineno-2-44" name="__codelineno-2-44" href="#__codelineno-2-44"></a><span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">matchExpressions</span><span class="p">:</span>
<a id="__codelineno-2-45" name="__codelineno-2-45" href="#__codelineno-2-45"></a><span class="w">              </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">beta.kubernetes.io/os</span>
<a id="__codelineno-2-46" name="__codelineno-2-46" href="#__codelineno-2-46"></a><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">In</span>
<a id="__codelineno-2-47" name="__codelineno-2-47" href="#__codelineno-2-47"></a><span class="w">                </span><span class="nt">values</span><span class="p">:</span>
<a id="__codelineno-2-48" name="__codelineno-2-48" href="#__codelineno-2-48"></a><span class="w">                </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linux</span>
<a id="__codelineno-2-49" name="__codelineno-2-49" href="#__codelineno-2-49"></a><span class="w">      </span><span class="nt">containers</span><span class="p">:</span>
<a id="__codelineno-2-50" name="__codelineno-2-50" href="#__codelineno-2-50"></a><span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">command</span><span class="p">:</span>
<a id="__codelineno-2-51" name="__codelineno-2-51" href="#__codelineno-2-51"></a><span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/usr/local/bin/manager</span>
<a id="__codelineno-2-52" name="__codelineno-2-52" href="#__codelineno-2-52"></a><span class="w">        </span><span class="nt">env</span><span class="p">:</span>
<a id="__codelineno-2-53" name="__codelineno-2-53" href="#__codelineno-2-53"></a><span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">POD_NAMESPACE</span>
<a id="__codelineno-2-54" name="__codelineno-2-54" href="#__codelineno-2-54"></a><span class="w">          </span><span class="nt">valueFrom</span><span class="p">:</span>
<a id="__codelineno-2-55" name="__codelineno-2-55" href="#__codelineno-2-55"></a><span class="w">            </span><span class="nt">fieldRef</span><span class="p">:</span>
<a id="__codelineno-2-56" name="__codelineno-2-56" href="#__codelineno-2-56"></a><span class="w">              </span><span class="nt">fieldPath</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">metadata.namespace</span>
<a id="__codelineno-2-57" name="__codelineno-2-57" href="#__codelineno-2-57"></a><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;extensions.vmware-cloud.tmc.cloud.vmware.com/extensions/extension-manager/extension-manager@sha256:&#39;</span>
<a id="__codelineno-2-58" name="__codelineno-2-58" href="#__codelineno-2-58"></a><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Always</span>
<a id="__codelineno-2-59" name="__codelineno-2-59" href="#__codelineno-2-59"></a><span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-60" name="__codelineno-2-60" href="#__codelineno-2-60"></a><span class="w">        </span><span class="nt">ports</span><span class="p">:</span>
<a id="__codelineno-2-61" name="__codelineno-2-61" href="#__codelineno-2-61"></a><span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9876</span>
<a id="__codelineno-2-62" name="__codelineno-2-62" href="#__codelineno-2-62"></a><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">webhook-server</span>
<a id="__codelineno-2-63" name="__codelineno-2-63" href="#__codelineno-2-63"></a><span class="w">          </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TCP</span>
<a id="__codelineno-2-64" name="__codelineno-2-64" href="#__codelineno-2-64"></a><span class="w">        </span><span class="nt">resources</span><span class="p">:</span>
<a id="__codelineno-2-65" name="__codelineno-2-65" href="#__codelineno-2-65"></a><span class="w">          </span><span class="nt">limits</span><span class="p">:</span>
<a id="__codelineno-2-66" name="__codelineno-2-66" href="#__codelineno-2-66"></a><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100m</span>
<a id="__codelineno-2-67" name="__codelineno-2-67" href="#__codelineno-2-67"></a><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256Mi</span>
<a id="__codelineno-2-68" name="__codelineno-2-68" href="#__codelineno-2-68"></a><span class="w">          </span><span class="nt">requests</span><span class="p">:</span>
<a id="__codelineno-2-69" name="__codelineno-2-69" href="#__codelineno-2-69"></a><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100m</span>
<a id="__codelineno-2-70" name="__codelineno-2-70" href="#__codelineno-2-70"></a><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128Mi</span>
<a id="__codelineno-2-71" name="__codelineno-2-71" href="#__codelineno-2-71"></a><span class="w">        </span><span class="nt">securityContext</span><span class="p">:</span>
<a id="__codelineno-2-72" name="__codelineno-2-72" href="#__codelineno-2-72"></a><span class="w">          </span><span class="nt">runAsGroup</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span>
<a id="__codelineno-2-73" name="__codelineno-2-73" href="#__codelineno-2-73"></a><span class="w">          </span><span class="nt">runAsUser</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span>
<a id="__codelineno-2-74" name="__codelineno-2-74" href="#__codelineno-2-74"></a><span class="w">      </span><span class="nt">serviceAccountName</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">extension-manager</span>
<a id="__codelineno-2-75" name="__codelineno-2-75" href="#__codelineno-2-75"></a><span class="w">      </span><span class="nt">tolerations</span><span class="p">:</span>
<a id="__codelineno-2-76" name="__codelineno-2-76" href="#__codelineno-2-76"></a><span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Exists</span>
</code></pre></div>
<p>對於 Kubernetes Application 資源估算你應該要關心以下幾個點</p>
<ol>
<li>kind 的類型：主要先以可涵蓋大部分部署場景為主，常見有 3 大 Kind，Deployment、StatefulSet、DaemonSet，如本範例為例 <code>kind: Deployment</code></li>
<li>spec.replicas 的數字：主要是要確認待會下面的 CPU / Memory 是要乘上多少，常見應該都是以 <code>1</code> 為主，至於為什麼可參閱我於 <a href="https://speakerdeck.com/pichuang/20210812-ru-he-cai-yong-yun-yuan-sheng-zuo-fa-velero-bei-fen-huan-yuan-ni-de-kubernetes-cong-ji?slide=8">之前在 Microsoft DevDays 2021 演講的內容</a>，如果微服務能夠 Scale-Out 的話，就是 <code>2</code> 或以上的數字</li>
<li>每一個 Pod 所需要的 CPU 和 Memory 資源：主要是確定一個 Container 所需要的 CPU 及 Memory 的上下限，要留意 <code>1 個 Pod 裡面會有 1 個或多個 Containers</code>，可詳閱<a href="https://speakerdeck.com/pichuang/how-do-i-troubleshooting-on-container-more-than-docker?slide=17">之前在 HKOSCon 2020 演講內容</a>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>        resources:
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>          limits:
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>            cpu: 100m
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>            memory: 256Mi
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>          requests:
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>            cpu: 100m
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>            memory: 128Mi
</code></pre></div></li>
<li>Storage 的選型：主要是要確定是要透過 hostPath 肚子的硬碟還是使用 PV/PVC 採用基於 CSI 介面的外掛儲存服務，常用協定如 NFS、iSCSI 及 FC 等，這個主要都是以服務對於 IOPS 或其特性的考量為採用標的，但本文不深入探究</li>
</ol>
<p>所以把上面的資訊收集起來，會得到下面這張表</p>
<p><img alt="" src="/images/tmc-res.png" /></p>
<p>但實際上你填完，會注意到一些事情</p>
<ol>
<li>這樣總資源是對的嗎?</li>
<li>有些欄位沒填的怎麼辦?</li>
</ol>
<p>回應第一題，一定不對，因為你看 <code>Replicas</code> 有些是 2，所以實際上你應該要把左邊的資源全部乘上 <code>Replicas</code> 數字，身為一個 App 團隊你應該會得到下面這張表</p>
<p><img alt="" src="/images/tmc-res-1.png" /></p>
<p>這時候你把全部的資訊撈出來，可以獲得到 <code>大約</code>這支整個程式再怎麼跑，頂多 <code>vmware-system-tmc</code> 這個 namesapce，就是吃掉 <code>4700m</code> CPU 跟 <code>6382M</code> Memory，至於對於 Kubernetes 計算單位不熟的可以參考 <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">Kubernetes Managing Resources for Containers</a>，另附上 <a href="https://docs.google.com/spreadsheets/d/1zQswfXuZhpKjsmmFvCHiGt19Ej6s6hpr5yiB1wnPR70/edit?usp=sharing">Google Sheet 參考文件</a></p>
<p>回應第二題，呈上，如果你沒寫資源，這不是代表他運作不用資源，是代表這份 Yaml 沒有定義 limits / requests 兩個數字去限制他的資源使用，而是會用 BestEffort 的方式運行。在這個狀況下，如果真的寫不出來，真的是只能憑經驗先估一個數字給 requests 確保不會爆炸，再來用 Metrics 服務，如自建 Prometheus、或 SaaS 服務 Tanzu Observability 長期觀測調整數字為比較務實的作法。倘若你如果選用的程式是 Java JVM 或者是自帶程式語言虛擬機，會相當好估算，但本文不深入探究</p>
<p>那額外問題來了，如果我在資源裡面填 0 的話會怎樣?</p>
<h3 id="0"><a class="toclink" href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/#0">關於 0 的那些事</a></h3>
<blockquote>
<p>先講結論，建議還是要設定 limits 跟 requests 的值上去，最少也要有 limits</p>
</blockquote>
<p>當資源真心不足的時候，則 Kubernetes 則有內建支援 QoS 服務管理能力，且支援作業系統等級的 OOM 控制，最小計算單位為 Pod。<code>一般來說，估算計算資源 limits 比較重要，實際上運行調度則是 requests 比較重要</code></p>
<p>Kubernetes 會開始依據 QoS 三種等級（由最高到最低優先權排序）：Guranted &gt; Bursatable &gt; BestEffort 進行權重排序，通常會發生 OOM (Out-of-Memory) 也都是因為撞到資源不足，然後優先權重又低，就被幹掉了，常見如 AI/ML 容器等會吃資源的容器服務，確切的詳細內容請參閱 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/quality-service-pod/">Kubernetes - 配置 Pod 的服务质量</a></p>
<table>
<thead>
<tr>
<th style="text-align: center;">優先權</th>
<th style="text-align: center;">QoS 類型</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1 (highest)</td>
<td style="text-align: center;">Guaranted</td>
<td style="text-align: center;">Pod 裡面的每一個 Container 都要設定 requests 等於 limits (兩個值皆有設定，且不等於 0)</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">Burstable</td>
<td style="text-align: center;">Pod 裡面的任一個 Container 具有 requests 不等於 limits 數值，且不符合 Guaranted 條件</td>
</tr>
<tr>
<td style="text-align: center;">3 (lowest)</td>
<td style="text-align: center;">BestEffort</td>
<td style="text-align: center;">沒有設定任何資源請求和限制</td>
</tr>
</tbody>
</table>
<p>當然你看完上面應該會霧傻傻，所以身為 Excel 精算師的我幫大家整理了以下列舉了已知組合，供大家參考</p>
<p><img alt="" src="/images/tmc-res-4.png" /></p>
<p>你看完上面的圖應該會知道一個事實，<code>0</code> 在 Kubernetes 來說是有意義的，所以資源估算請不要亂寫，他不代表無限大資源的意思...如果真的不知道請留空，而不是寫 0</p>
<h3 id="app"><a class="toclink" href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/#app">以 App 角度出發的常見資源錯估誤區</a></h3>
<p>你是不是覺得到這邊就可以估算結束了？<code>很抱歉沒有</code>，你還少算運行 Kubernetes 所需要的服務，如 kubelet、CNI、kube-proxy、OS 本身服務等等這些不存在於 kubernetes 的資源清單上，但實際上是需要這些服務才能夠好好的運行 Kubernetes 服務，那這是什麼意思呢?</p>
<p>拿房子權狀比喻，以上所做的事情都是在算室內面積（客廳、浴室、陽台），實際上你還有公設（樓梯、電梯、健身房）要算啊！所以最終估算 1 個 Kubernetes 所需資源的結果，一定會比 App 所寫的還要來得大上一點</p>
<p><img alt="" src="https://learnk8s.io/a/5505f01f0ed678a7ac42642b4dfd7b1c.svg" /></p>
<p>而各大廠商為了要降低公設比，紛紛都推出了 Container OS 進行資源和效能上的最佳化，畢竟誰希望拿到 1 個 4c/8g 的 worker 節點，把一堆跟 kubernetes 沒關係的服務開起來就剩不到一半資源可以用，但因為各家出 Container OS 系統都不盡相同，所以會很仰賴各自廠商工程師的精算</p>
<h3 id="_2"><a class="toclink" href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/#_2">結語</a></h3>
<p>看完以上的文章，相信大家一定會覺得為啥我要個 Kubernetes 為啥要搞得這麼複雜，所以下篇會講，<code>以 Ops 角度出發的 Hardware (or Cloud Provider) 資源估算</code>，就是寫不出來的狀況下身為 Ops 到底該怎麼辦？</p>
<p>希望今年能寫得出來...希望...</p>
<p>特別感謝 Gene Kuo 和 Hwchiu 幫忙校稿 XD</p>
    <nav class="md-post__action">
      <a href="../../2021/11/12/%E5%A6%82%E4%BD%95%E7%A7%91%E5%AD%B8%E5%9C%B0%E4%BC%B0%E7%AE%97-kubernetes-%E6%89%80%E9%9C%80%E7%9A%84%E8%B3%87%E6%BA%90-app-%E8%A7%92%E5%BA%A6%E7%AF%87/">
        Continue reading
      </a>
    </nav>
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  <span class="md-pagination__current">1</span> <a class="md-pagination__link" href="page/2/">2</a>
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/pichuang" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/phil-huang-09b09895" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/@pichuang-tw" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="http://speakerdeck.com/pichuang" target="_blank" rel="noopener" title="speakerdeck.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M213.86 296H100a100 100 0 0 1 0-200h132.84a40 40 0 0 1 0 80H98c-26.47 0-26.45 40 0 40h113.82a100 100 0 0 1 0 200H40a40 40 0 0 1 0-80h173.86c26.48 0 26.46-40 0-40zM298 416a120.21 120.21 0 0 0 51.11-80h64.55a19.83 19.83 0 0 0 19.66-20V196a19.83 19.83 0 0 0-19.66-20H296.42a60.77 60.77 0 0 0 0-80h136.93c43.44 0 78.65 35.82 78.65 80v160c0 44.18-35.21 80-78.65 80z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.copy", "content.code.annotate", "navigation.instant", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.path", "navigation.sections", "navigation.indexes", "navigation.expand", "navigation.prune", "navigation.top", "toc.follow", "toc.integrate", "search.suggest", "search.highlight", "header.autohide"], "search": "../../assets/javascripts/workers/search.1e90e0fb.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.8e8db93a.min.js"></script>
      
    
  </body>
</html>